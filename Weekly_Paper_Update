https://juejin.cn/post/7593607642553892890

## 每周AI论文速递（251020-251024）

A Theoretical Study on Bridging Internal Probability and Self-Consistency for LLM Reasoning
关于桥接大语言模型推理中内部概率与自一致性的理论研究
测试时扩展旨在通过增加计算资源来提升大语言模型 (LLM) 的推理性能。该领域的流行方法包括基于采样的测试时扩展方法，其核心机制是在推理阶段为单一输入生成多条推理路径以增强性能。然而，尽管这些方法在实践中取得成功，其理论基础仍缺乏深入研究。本文首次从置信度估计的视角，建立了用于分析基于采样的测试时扩展方法的理论框架。基于此框架，我们剖析了两种主流范式——自一致性与困惑度，并揭示其关键局限：自一致性存在高估计误差，而困惑度不仅呈现显著建模误差，还可能导致估计误差收敛性退化。为克服这些局限，我们提出 RPC 混合方法，其通过两个关键组件体现理论洞见：困惑度一致性与推理剪枝。困惑度一致性融合了自一致性与困惑度的优势，在保持模型误差不变的同时，将估计误差的收敛速率从线性加速至指数级；推理剪枝则通过剔除低概率推理路径避免性能退化。在七个基准数据集上的理论分析与实证结果表明，RPC 具备显著降低推理误差的潜力。值得注意的是，RPC 在达到与自一致性相近推理性能的同时，不仅提升了置信度可靠性，还将采样成本降低了 50%。代码与资源公开于 wnjxyk.github.io/RPC。

Efficient Long-context Language Model Training by Core Attention Disaggregation
通过核心注意力解耦实现高效长上下文语言模型训练
我们提出核心注意力解耦 (CAD) 技术，通过将核心注意力计算 softmax(QK^T)V 从模型其余部分分离，并在专用设备池上执行，以提升长上下文大语言模型的训练效率。在现有系统中，核心注意力与其他组件共置；当上下文长度增加时，其计算量呈二次增长，而其他组件仅呈近线性增长，导致数据并行和流水线并行组中出现负载不均及慢节点问题。CAD 的实现基于两个关键观察：首先，核心注意力是无状态的，不含可训练参数且仅需极少量瞬态数据，因此负载均衡问题可简化为调度计算密集型任务；其次，它具有可组合性，现代注意力内核在处理任意长度的融合 token 级分片批次时仍能保持高效率。CAD 将核心注意力分解为 token 级任务，并分发至专用注意力服务器，这些服务器动态重组任务批次以实现计算均衡，同时不损失内核效率。我们在名为 DistCA 的系统中实现了 CAD，该系统采用乒乓式执行方案，完全重叠通信与计算过程，并通过注意力服务器上的原地执行来降低内存占用。在 512 个 H200 GPU 和 512k token 的上下文长度下，DistCA 将端到端训练吞吐量最高提升 1.35 倍，消除了数据并行和流水线并行中的慢节点，并实现了近乎完美的计算与内存平衡。

LightMem: Lightweight and Efficient Memory-Augmented Generation
LightMem: 轻量级高效记忆增强生成
尽管大语言模型 (LLMs) 能力卓越，但在动态复杂环境中难以有效利用历史交互信息。记忆系统通过引入持久性信息存储、检索和利用机制，使 LLMs 能够超越无状态交互。然而，现有记忆系统通常带来显著的时间和计算开销。为此，我们提出了名为 LightMem 的新型记忆系统，在系统性能与效率之间实现了平衡。受人类记忆的 Atkinson-Shiffrin 模型启发，LightMem 将记忆组织为三个互补阶段：首先，受认知启发的感官记忆通过轻量级压缩快速过滤不相关信息，并按主题对信息进行分组；其次，主题感知短期记忆对这些按主题分组的单元进行巩固，通过组织与内容摘要实现更结构化的访问；最后，采用睡眠时间更新的长期记忆通过离线处理方式，将巩固过程与在线推理解耦。在 LongMemEval 基准测试中，基于 GPT 和 Qwen 骨干网络的实验表明，LightMem 在准确率上超越强基线（最高提升 10.9%），同时将 token 使用量降低达 117 倍，API 调用次数减少达 159 倍，运行时间缩短超过 12 倍。代码发布于 github.com/zjunlp/Ligh…

Every Attention Matters: An Efficient Hybrid Architecture for Long-Context Reasoning
全注意力机制协同：面向长上下文推理的高效混合架构
本技术报告提出Ring-linear模型系列，具体包含Ring-mini-linear-2.0与Ring-flash-linear-2.0两个版本。其中Ring-mini-linear-2.0具有160亿参数和9.57亿激活量，Ring-flash-linear-2.0则具备1040亿参数和61亿激活量。该系列采用融合线性注意力与softmax注意力的混合架构，显著降低了长上下文推理场景中的I/O与计算开销。相较于320亿参数的稠密模型，本系列将推理成本降至1/10；与原始Ring系列相比，成本降幅亦超过50%。通过对混合架构中不同注意力机制配比的系统探索，我们确立了当前最优的模型结构。基于自研的高性能FP8算子库linghe，整体训练效率提升达50%。凭借训练与推理引擎算子间的高度协同，模型在强化学习阶段可实现长期稳定且高效的优化，在多项复杂推理基准测试中持续保持顶尖（SOTA）性能。

DeepAnalyze: Agentic Large Language Models for Autonomous Data Science
DeepAnalyze：面向自主数据科学的智能体大语言模型
自主数据科学，即从原始数据源生成专业分析师水平的深度研究报告，长期以来一直是一个挑战。随着强大大型语言模型（LLMs）的出现，这一目标正逐渐成为可能。近期基于工作流的数据代理在特定数据任务上展现出潜力，但由于依赖预定义工作流，在实现完全自主数据科学方面仍存在根本性局限。本文介绍DeepAnalyze-8B，这是首个专为自主数据科学设计的智能体大语言模型，能够自动执行从数据源到分析师标准深度研究报告的端到端流程。为应对高复杂度数据科学任务，我们提出一种基于课程学习的智能体训练范式，模拟人类数据科学家的学习路径，使LLM能够在真实环境中逐步获取并整合多种能力。同时，我们引入一个数据驱动的行为序列合成框架，用于构建高质量训练数据。通过智能体训练，DeepAnalyze学会执行广泛的数据任务，包括数据问答、专业分析任务以及开放式数据探索。实验表明，仅凭80亿参数，DeepAnalyze的性能已超越此前基于最先进闭源LLMs构建的工作流代理。DeepAnalyze的模型、代码及训练数据均已开源，为推进自主数据科学奠定了基础。

World-in-World: World Models in a Closed-Loop World
世界中的世界：闭环世界中的世界模型
生成式世界模型 (WMs) 现已能够以惊人的视觉真实度模拟世界，这自然引发了一个疑问：它们能否为具身智能体提供预测性感知能力以支持决策？该领域的发展受限于评估方法的碎片化：现有基准大多采用开环协议，孤立地强调视觉质量，却未解决具身实用性的核心问题——世界模型是否真能帮助智能体成功完成具身任务？为填补这一空白，我们推出了 World-in-World，这是首个在闭环世界中基准测试世界模型的开放平台，其模拟了真实的智能体-环境交互。World-in-World 提供统一的在线规划策略和标准化动作 API，使异构世界模型能够用于决策。我们构建了四个闭环环境，严格评估多种世界模型，以任务成功率作为核心指标，并突破了对视觉质量的常规关注；同时，我们首次提出了具身场景下世界模型的数据缩放定律。研究揭示了三个意外发现：(1) 仅靠视觉质量无法确保任务成功，可控性更为关键；(2) 利用动作-观察数据进行后训练缩放，比升级预训练视频生成器更有效；(3) 增加推理时计算资源可显著提升世界模型的闭环性能。

BAPO: Stabilizing Off-Policy Reinforcement Learning for LLMs via
BAPO：通过自适应裁剪的平衡策略优化稳定大语言模型的离策略强化学习
强化学习 (RL) 已成为对齐和增强大语言模型 (LLMs) 的核心方法。然而，在离策略设置中应用 RL（即使用历史策略生成的陈旧数据进行训练）虽能提高样本效率，但仍面临挑战：策略熵值急剧下降，优化过程常不稳定，甚至可能导致训练崩溃。通过理论与实证分析，我们得出两个关键发现：(i) 优化过程存在不平衡问题，负优势样本主导策略梯度，抑制有效行为并引发梯度爆炸风险；(ii) 推导出的熵裁剪规则表明，PPO 类目标中的固定裁剪机制会系统性阻碍熵增更新，从而使策略过度偏向利用而牺牲探索。基于这些发现，我们提出自适应裁剪的平衡策略优化 (BAPO)，这是一种简单有效的方法，通过动态调整裁剪边界，自适应平衡正负贡献、维持熵值并稳定 RL 优化。在多种离策略场景（包括样本回放和部分 rollout）中，BAPO 均能实现快速、稳定且数据高效的训练。在 AIME 2024 和 AIME 2025 基准测试中，我们的 7B BAPO 模型超越了开源模型如 SkyWork-OR1-7B，而 32B BAPO 模型不仅在同等规模模型中达到最优水平，还超越了领先的专有系统如 o3-mini 和 Gemini-2.5-Flash-Thinking。

OmniVinci: Enhancing Architecture and Data for Omni-Modal Understanding LLM
OmniVinci：面向全模态理解的架构与数据增强方法 LLM
提升机器智能水平需要实现跨多模态的感知能力，模拟人类认知世界的方式。本文提出 OmniVinci 项目，致力于构建一个强大的开源全模态大语言模型。我们系统性地研究了模型架构与数据构建的关键设计要素。在模型架构方面，我们提出三项核心创新：(i) OmniAlignNet 模块，用于强化视觉与音频嵌入在共享全模态潜在空间中的对齐；(ii) 时序嵌入分组机制，用于建模视觉与音频信号间的相对时序对齐关系；(iii) 约束旋转时序嵌入方法，用于在全模态嵌入中编码绝对时序信息。我们构建了一套数据构建与合成流程，生成了 2400 万条单模态及全模态交互数据。研究发现，不同模态在感知与推理过程中存在协同增强效应。我们的 OmniVinci 模型在多项基准测试中表现优异：在 DailyOmni（跨模态理解）上较 Qwen2.5-Omni 提升 19.05 分，在 MMAR（音频）上提升 1.7 分，在 Video-MME（视觉）上提升 3.9 分，而训练数据量仅需 0.2T token，较 Qwen2.5-Omni 的 1.2T token 减少了 83%。最后，我们在机器人、医疗AI和智能工厂等下游应用中验证了全模态技术的优势。
UniGenBench++: A Unified Semantic Evaluation Benchmark for Text-to-Image Generation
UniGenBench++：文本到图像生成的统一语义评估基准
文本到图像 (T2I) 生成技术的最新进展表明，需要可靠的评估基准来衡量生成图像与文本提示语义的匹配精度。然而现有基准存在两大局限：(1) 缺乏多样化的提示场景和多语言支持，而这二者对实际应用至关重要；(2) 仅对主要维度进行粗粒度评估，覆盖的子维度范围有限，且缺乏细粒度评估能力。为此，我们提出UniGenBench++——一个统一的T2I生成语义评估基准。该基准包含600个分层组织的提示词，在保证评估覆盖率与效率的同时： (1) 涵盖5大主题和20个子主题的多样化现实场景；(2) 通过10个主评估维度和27个子维度全面检验T2I模型的语义一致性，每个提示词可同时评估多个测试维度。为严格测试模型对语言类型和提示长度的适应性，所有提示均提供简/繁两种长度的中英文版本。基于闭源多模态大语言模型Gemini-2.5-Pro的通用知识库与细粒度图像理解能力，我们构建了高效的基准构建流程与标准化评估方案。此外，还训练了鲁棒的评估模型，支持对T2I模型输出进行离线评估。通过对开源与闭源T2I模型的全面测试，系统揭示了各模型在不同维度上的性能差异。

Human-Agent Collaborative Paper-to-Page Crafting for Under $0.1
人机协作的论文到网页制作，成本低于0.1美元
在科学进步的追求中，研究成果的传播与科学发现本身同等重要。然而，研究人员常因手动构建项目网页（旨在使内容密集的论文更易理解）这一重复性任务而分心。尽管自动化技术已能处理静态幻灯片和海报，但网页的动态交互特性仍是亟待解决的挑战。为弥补这一差距，我们重新审视该问题，提出解决方案并非依赖单一指令，而应通过协作式分层流程实现。我们引入AutoPage\textbf{AutoPage}AutoPage——一个体现此理念的新型多智能体系统。该系统将论文到网页的生成过程解构为从叙事规划到多模态内容生成，再到交互式渲染的由粗到精流程。为减少AI幻觉，专设"检查器"智能体逐步对照原文验证输出，同时可选的人工审核节点确保最终成果与作者意图高度一致，使系统从简单工具升级为强力协作助手。为严格验证方法，我们还构建了PageBench\textbf{PageBench}PageBench——该新兴任务的首个基准测试集。实验表明，AutoPage不仅能生成高质量、视觉吸引力强的网页，更以低于0.1美元的成本在15分钟内高效完成。代码与数据集将于\href\href{https://mqleet.github.io/AutoPage_ProjectPage/}{项目网站}\href发布。

PICABench: How Far Are We from Physically Realistic Image Editing?
PICABench：我们距离物理真实图像编辑还有多远？
图像编辑领域近期取得了显著进展。现代编辑模型已能执行复杂指令来操控原始内容。然而，除了实现编辑指令外，伴随产生的物理效应是生成真实感的关键因素。例如，移除物体时，应同时移除其阴影、反射以及与周围物体的交互效应。遗憾的是，现有模型和基准测试主要关注指令执行完成度，却忽略了这些物理效应。因此，目前我们距离实现物理真实的图像编辑还有多大差距？为回答这一问题，我们推出PICABench基准，系统评估了常见编辑操作（如添加、移除、属性修改等）在八个子维度（涵盖光学、力学和状态转换）上的物理真实感。我们进一步提出PICAEval评估协议，采用VLM-as-a-judge框架，结合逐案例的区域级人工标注与问题设计。除基准测试外，我们还通过从视频数据中学习物理规律探索有效解决方案，并构建了PICA-100K训练数据集。在对主流模型进行全面评估后，我们发现物理真实感仍是亟待解决的挑战性难题，存在广阔的研究空间。我们希望本基准及相关解决方案能为未来研究从基础内容编辑迈向物理一致性真实感提供重要基础。

Every Step Evolves: Scaling Reinforcement Learning for Trillion-Scale Thinking Model
步步演进：面向万亿规模思维模型的强化学习扩展
我们正式发布 Ring-1T——首个开源的万亿参数级尖端思维模型。该模型包含1万亿总参数，每个Token激活约500亿参数。在万亿参数规模上训练此类模型面临三大挑战：训练与推理失配、轨迹生成效率低下，以及强化学习系统瓶颈。为此我们提出三项核心创新：(1) IcePop 通过Token级差异掩码与裁剪技术稳定强化学习训练，解决训练-推理失配导致的不稳定性；(2) C3PO++ 在给定Token预算条件下，通过动态分区长轨迹实现资源优化，显著提升时间效率；(3) ASystem 作为高性能强化学习框架，专门突破阻碍万亿参数模型训练的系统瓶颈。Ring-1T 在关键基准测试中表现卓越：AIME-2025获93.4分，HMMT-2025获86.72分，CodeForces评分2088，ARC-AGI-v1达55.94分。尤为突出的是，其在IMO-2025中达到银牌水平，充分彰显卓越推理能力。通过向社区开放完整的1T参数MoE模型，我们为学术界提供了直接接触前沿推理技术的通道。这一成果标志着大规模推理智能普惠化的重要里程碑，并为开源模型性能确立了全新基准。

Glyph: Scaling Context Windows via Visual-Text Compression
Glyph：通过视觉-文本压缩扩展上下文窗口
大语言模型 (LLMs) 日益依赖长上下文建模来处理文档理解、代码分析和多步推理等任务。然而，将上下文窗口扩展至百万 token 级别会带来高昂的计算和内存成本，限制了长上下文 LLMs 的实际应用。为此，我们提出一种新视角——视觉上下文扩展——以应对这一挑战。我们开发了 Glyph 框架，该框架将长文本渲染为图像，并利用视觉语言模型 (VLMs) 进行处理，而非扩展基于 token 的序列。这种方法在保留语义信息的同时，大幅压缩文本输入；我们还设计了基于 LLM 的遗传搜索，以识别最优视觉渲染配置，平衡准确性与压缩率。大量实验表明，本方法在多种长上下文基准测试（例如 Qwen3-8B）上实现了 3-4 倍的 token 压缩，同时保持与主流 LLMs 相当的准确性。压缩还使预填充和解码速度提升约 4 倍，SFT 训练加速约 2 倍。此外，通过极端压缩，128K 上下文的 VLM 可扩展至处理 1M token 级别的文本任务。渲染的文本数据还有助于现实世界多模态任务，如文档理解。我们的代码和模型已发布于 github.com/thu-coai/Gl…

NANO3D: A Training-Free Approach for Efficient 3D Editing Without Masks
NANO3D：一种无需训练与掩码的高效3D编辑方法
3D物体编辑在游戏、动画及机器人技术的交互式内容创作中至关重要，但现有方法效率低、一致性差，且常无法保留未编辑区域。多数方法基于多视角渲染编辑后进行重建，易产生伪影并制约实际应用。为解决这些问题，我们提出Nano3D——一种无需训练即可实现无掩码精准连贯3D编辑的框架。Nano3D将FlowEdit集成至TRELLIS系统，通过前视图渲染引导局部编辑，并引入区域感知合并策略Voxel/Slat-Merge，该策略通过维护编辑区与未编辑区的一致性，自适应保障结构保真度。实验表明，Nano3D相较现有方法具有更优的3D一致性与视觉质量。基于此框架，我们构建了首个大规模3D编辑数据集Nano3D-Edit-100k，包含逾10万组高质量3D编辑样本。本工作攻克了算法设计与数据可获取性领域的长期难题，显著提升3D编辑的通用性与可靠性，为前馈式3D编辑模型发展奠定基础。项目页面：jamesyjl.github.io/Nano3D

LoongRL:Reinforcement Learning for Advanced Reasoning over Long Contexts
LoongRL：面向长上下文高级推理的强化学习
长上下文推理对大语言模型至关重要。尽管强化学习 (RL) 通过思维链激发“顿悟”时刻来提升短上下文推理能力，但长上下文推理所需的高级思维模式仍鲜有研究，且高难度 RL 数据匮乏。本文提出 LoongRL，一种数据驱动的 RL 方法，用于实现高级长上下文推理。其核心是 KeyChain 合成方法：通过插入 UUID 链将短多跳问答转换为高难度长上下文任务，这些链将真实问题隐藏于海量干扰文档中。解决此类任务要求模型逐步追踪正确链、识别真实问题、检索相关事实并进行推理以给出正确答案。基于 KeyChain 数据的 RL 训练催生了一种新兴的“规划-检索-推理-复核”推理模式，其泛化能力远超训练长度。经 16K 长度训练的模型可有效解决 128K 任务，且无需支付高昂的全程 RL 展开成本。在 Qwen2.5-7B 与 14B 模型上，LoongRL 使长上下文多跳问答准确率显著提升，绝对增益分别达 +23.5% 和 +21.1%。最终 LoongRL-14B 获得 74.2 的评分，与规模更大的前沿模型（如 o3-mini (74.5) 和 DeepSeek-R1 (74.9)）性能相当。该方法还提升了长上下文检索能力，通过全部 128K 长度“大海捞针”压力测试，并保持了短上下文推理性能。

AdaSPEC: Selective Knowledge Distillation for Efficient Speculative Decoders
AdaSPEC：面向高效推测解码器的选择性知识蒸馏
推测解码 (Speculative Decoding, SD) 通过采用小型草稿模型生成预测，再由大型目标模型进行验证，从而加速大语言模型推理。SD 的有效性依赖于草稿模型与目标模型之间的对齐度，通常通过知识蒸馏 (Knowledge Distillation, KD) 来提升。然而，传统 KD 方法旨在最小化草稿模型与目标模型在所有 token 上的 KL 散度，这一目标与 SD 的真实目标——最大化 token 接受率——存在偏差。因此，受容量限制，草稿模型往往难以完全学习目标模型的知识，导致性能不理想。为解决这一问题，我们提出 AdaSPEC，一种在 KD 过程中引入选择性 token 过滤的新方法。AdaSPEC 利用参考模型识别并滤除难以拟合的 token，从而在更简单的 token 上蒸馏出与目标模型对齐度更高的草稿模型。该方法在不降低生成质量的前提下，提高了整体 token 接受率。我们在多种任务上评估 AdaSPEC，包括算术推理、指令跟随、代码生成和文本摘要，使用参数规模为 31M/1.4B 和 350M/2.7B 的模型配置。结果表明，AdaSPEC 在所有任务中均持续优于当前最先进的 DistillSpec 方法，接受率提升最高达 15%。代码公开于 github.com/yuezhouhu/a…

DeepSeek-OCR: Contexts Optical Compression
DeepSeek-OCR：上下文光学压缩
我们提出 DeepSeek-OCR，作为通过光学二维映射压缩长上下文可行性的初步探索。DeepSeek-OCR 包含两个组件：DeepEncoder 和作为解码器的 DeepSeek3B-MoE-A570M。具体而言，DeepEncoder 作为核心引擎，旨在高分辨率输入下保持低激活值，同时实现高压缩比，以确保视觉 token 数量达到最优且可管理。实验表明，当文本 token 数量不超过视觉 token 数量的 10 倍（即压缩比 < 10 倍）时，模型可实现 97% 的解码（OCR）精度。即使在 20 倍压缩比下，OCR 准确率仍保持在约 60%。这表明在历史长上下文压缩和大语言模型记忆遗忘机制等研究领域具有巨大潜力。此外，DeepSeek-OCR 还展现出较高的实用价值：在 OmniDocBench 基准测试中，仅使用 100 个视觉 token 即超越 GOT-OCR2.0（每页 256 token），且在使用不足 800 个视觉 token 时优于 MinerU2.0（平均每页 6000+ token）。在实际应用中，DeepSeek-OCR 可基于单张 A100-40G 显卡，以每日 20 万+ 页的规模为大语言模型/视觉语言模型生成训练数据。代码和模型权重已开源，详见 github.com/deepseek-ai…

FineVision: Open Data Is All You Need
FineVision：开放数据足矣
视觉语言模型 (VLMs) 的发展因公共数据集存在不一致性与污染问题而受阻。我们推出 FineVision——一个经过精心采集、整理与标准化处理的 2400 万样本语料库，这也是目前同类开放资源中规模最大的数据集。通过半自动化的人机协同流程，我们将 200 余个数据源整合为 185 个子集：自动化流程负责批量采集与模式映射，审核人员则对映射关系进行审计，并通过抽样检查确保标注信息的准确使用、格式规范与数据多样性，同时保障数据安全性；发现的问题将引发针对性修复并重新执行流程。该工作流还实施了严格的数据源内与跨源去重操作，并针对 66 个公开基准数据集进行了数据净化处理。FineVision 还包含具有统一动作空间的智能体/GUI 任务，审核人员会验证数据模式并抽检轨迹样本以确保可执行准确性。在全面评估测试中，基于 FineVision 训练的模型表现持续优于采用现有开放混合数据集训练的模型，这充分证明了数据规模、数据质量以及人机协同的平衡自动化带来的优势。我们公开释放该语料库及数据整理工具，以推动数据驱动的 VLM 研究发展。

Chem-R: Learning to Reason as a Chemist
Chem-R：学习化学家式推理
尽管大语言模型 (LLMs) 在推动化学发现方面潜力巨大，但现有模型存在核心化学知识缺失、推理轨迹不可靠、以及在各类化学任务中性能欠佳等问题。为解决这些挑战，我们提出 Chem-R——一个具有强泛化能力的化学推理模型，其设计目标是模拟化学家的审慎推理过程。该模型通过三阶段训练框架逐步构建高级推理能力，具体包括：1) 化学基础训练，建立核心化学知识体系；2) 化学推理规程蒸馏，融入结构化专家级推理轨迹以指导系统可靠的问题求解；3) 多任务组相对策略优化，使模型在分子与反应任务中实现均衡性能。这一结构化流程使 Chem-R 在综合基准测试中达到最先进水平，在分子任务上超越包括 Gemini-2.5-Pro 和 DeepSeek-R1 在内的领先大语言模型，幅度高达 32%，在反应任务上领先幅度达 48%。同时，Chem-R 在分子与反应任务中持续领先现有化学基础模型。这些成果彰显了 Chem-R 强大的泛化能力、可解释性及其作为下一代 AI 驱动化学发现基石的潜力。代码与模型详见 github.com/davidweidaw…

Scaling Instruction-Based Video Editing with a High-Quality Synthetic Dataset
基于高质量合成数据集的指令式视频编辑规模化扩展
基于指令的视频编辑技术有望降低内容创作门槛，但其发展受到大规模高质量训练数据稀缺的严重制约。我们提出Ditto——一个解决这一根本挑战的综合性框架。该框架核心采用创新的数据生成流程，将领先图像编辑器的创意多样性与情境感知视频生成器相融合，有效突破现有模型的局限性。为实现可行性，我们通过采用高效蒸馏模型架构并集成时序增强模块，在显著降低计算开销的同时提升时序一致性，从而突破传统方案中成本与质量难以兼顾的困境。最终，通过智能体自动生成多样化指令并严格筛选输出，实现全流程规模化质量控制。基于该框架，我们投入超过12,000 GPU天构建了Ditto-1M数据集，包含百万级高保真视频编辑样本。采用课程学习策略在Ditto-1M上训练得到的Editto模型，在指令遵循能力方面表现卓越，刷新了指令式视频编辑领域的性能纪录。

Language Models are Injective and Hence Invertible
语言模型是单射的，因此是可逆的
Transformer 组件（例如非线性激活和归一化）本质上是非单射的，这意味着不同输入可能映射到相同输出，从而无法从模型表示中精确恢复输入。本文中，我们对此观点提出挑战。首先，从数学上证明，将离散输入序列映射到对应连续表示序列的 transformer 语言模型具有单射性，因此是无损的；该特性在初始化时确立并在训练过程中保持不变。其次，通过对六个前沿语言模型进行数十亿次碰撞测试，我们实证验证了这一结论，且未观察到任何碰撞。第三，我们实现了单射性的实际应用：提出 SipIt 算法，这是首个可证明且高效地从隐藏激活中重构原始输入文本的方法，具备线性时间保证，并在实践中实现了精确可逆。总体而言，本研究确立了单射性作为语言模型的基本可挖掘特性，直接影响模型透明度、可解释性及安全部署。

## 每周AI论文速递（251027-251031）

Scaling Latent Reasoning via Looped Language Models
通过循环语言模型扩展潜在推理
现代大语言模型主要通过显式文本生成（如思维链 (CoT)）来训练其“思考”能力，但这将推理过程推迟到训练后阶段，且未能充分利用预训练数据。我们提出并开源了 Ouro（取名自递归的 Ouroboros），这是一个预训练的循环语言模型 (LoopLM) 系列，它通过以下方式将推理构建到预训练阶段：(i) 在潜在空间中进行迭代计算，(ii) 采用熵正则化目标以学习深度分配，以及 (iii) 扩展到 7.7T token 的规模。Ouro 1.4B 和 2.6B 模型在广泛基准测试中表现出卓越性能，与高达 12B 参数的当前最优 (SOTA) 大语言模型结果相当。通过受控实验，我们证明这一优势并非来自知识容量的增加，而是源于更强大的知识操纵能力。我们还表明，与显式 CoT 相比，LoopLM 生成的推理轨迹与最终输出更一致。我们希望这些结果能凸显 LoopLM 作为推理时代一个新扩展方向的潜力。模型可在 ouro-llm.github.io 获取。

Concerto: Joint 2D-3D Self-Supervised Learning Emerges Spatial Representations
Concerto：联合 2D-3D 自监督学习产生空间表征
人类通过多感官协同作用学习抽象概念，一旦形成，这些表征通常可以从单一模态中提取。受此原理启发，我们提出了 Concerto，这是一种针对人类空间认知概念学习的简约模拟，它结合了 3D 模态内自蒸馏与 2D-3D 跨模态联合嵌入。尽管设计简洁，Concerto 能够学习到更连贯且信息更丰富的空间特征，零样本可视化结果验证了这一点。在 3D 场景感知的线性探测任务中，Concerto 的性能分别优于独立的 SOTA 2D 和 3D 自监督模型 14.2% 和 4.8%，同时也优于它们的特征拼接。经过完整微调后，Concerto 在多个场景理解基准测试中创下了新的 SOTA 结果（例如，在 ScanNet 上达到 80.7% mIoU）。我们还提出了一个专为基于视频的点云空间理解定制的 Concerto 变体，以及一个将 Concerto 表征线性投影到 CLIP 语言空间的翻译器，从而支持开放世界感知。这些结果表明，Concerto 能够产生具有卓越细粒度几何和语义一致性的空间表征。

ReCode: Unify Plan and Action for Universal Granularity Control
ReCode：统一规划与行动实现通用粒度控制
现实任务需要在不同粒度级别进行决策，人类通过统一的认知表征在此方面表现卓越——其中规划本质上被视为一种高层级的行动形式。然而，当前基于大语言模型 (LLM) 的智能体缺乏跨粒度流畅决策的关键能力。这一局限源于现有范式对高层规划与底层行动进行严格区分，从而削弱了动态适应性并限制了泛化能力。我们提出 ReCode (递归代码生成) 这一新范式，通过将规划与行动统一在单一代码表征中来解决此问题。在该表征中，ReCode 将高层计划视为抽象占位函数，智能体随后递归地将这些函数分解为更细粒度的子函数，直至抵达原始动作层。这种递归机制消融了规划与行动间的严格界限，使得智能体能够动态调控决策粒度。此外，递归结构会内在地生成丰富的多粒度训练数据，让模型能够学习层级化决策过程。广泛实验表明，ReCode 在推理性能上显著超越先进基线方法，并在训练中表现出卓越的数据效率，证实了我们的核心观点：通过递归代码生成统一规划与行动是实现通用粒度控制的高效路径。代码发布于 github.com/FoundationA…

InteractComp: Evaluating Search Agents With Ambiguous Queries
InteractComp：基于模糊查询的搜索代理评估
语言智能体在网络搜索和信息检索领域展现出巨大潜力。然而，现有搜索代理均假设用户查询是完整且明确的，这一假设与实际情况存在偏差——用户往往从模糊的初始查询开始，需要通过交互过程逐步澄清需求。目前大多数搜索代理缺乏交互机制，且现有评估基准无法有效检验这种交互能力。为填补这一空白，我们提出InteractComp基准，专门用于评估搜索代理在搜索过程中识别查询模糊性并主动通过交互消歧的能力。基于"易于验证、交互消歧"原则，我们采用目标-干扰物方法构建了涵盖9个领域的210个专家精编问题，这些问题具有真实的模糊性，必须通过交互才能解决。对17个模型的评估结果令人震惊：最佳模型准确率仅为13.73%，而在完整上下文条件下可达71.50%，这表明问题根源在于系统性过度自信而非推理能力不足。强制交互策略带来了显著性能提升，证明了现有策略未能激发的潜在能力。纵向分析表明，尽管搜索性能在15个月内提升七倍，但交互能力始终停滞不前，暴露出关键发展盲点。这种能力停滞与搜索任务固有的即时反馈特性，使得InteractComp成为评估和训练搜索代理交互能力的宝贵资源。代码已发布于github.com/FoundationA…

DeepAgent: A General Reasoning Agent with Scalable Toolsets
DeepAgent：具备可扩展工具集的通用推理智能体
大型推理模型已展现出强大的问题解决能力，但现实任务往往需要借助外部工具并进行长程交互。现有智能体框架通常遵循预定义工作流，这限制了任务的自主性和全局性完成。本文提出DeepAgent——一种端到端深度推理智能体，能在统一连贯的推理过程中实现自主思考、工具发现与动作执行。针对长程交互的挑战（特别是多重工具调用引发的上下文长度激增及交互历史累积），我们引入了自主记忆折叠机制，将历史交互压缩为结构化的情景记忆、工作记忆与工具记忆，在减少错误积累的同时保留关键信息。为高效稳定地训练通用工具使用能力，我们开发了端到端强化学习策略ToolPO，该策略利用大语言模型模拟API，并通过工具调用优势归因机制为工具调用token分配细粒度信用值。在八大基准测试（包括通用工具使用任务ToolBench、API-Bank、TMDB、Spotify、ToolHop及下游应用ALFWorld、WebShop、GAIA、HLE）上的实验表明，DeepAgent在标注工具和开放集工具检索场景中性能始终优于基线方法。本研究为开发适用于现实场景的通用型智能体迈出了重要一步。代码与演示详见：github.com/RUC-NLPIR/D…

JanusCoder: Towards a Foundational Visual-Programmatic Interface for Code Intelligence
JanusCoder: 构建代码智能的基础视觉-程序化接口
神经代码智能的研究范围正迅速从基于文本的源代码扩展到程序生成的丰富视觉输出。视觉维度对于高级应用（如灵活内容生成和程序驱动的精确可视化编辑）至关重要。然而，高质量多模态代码数据的稀缺阻碍了进展，这一瓶颈主要源于数据合成和质量评估的挑战。为解决这些问题，我们从数据和建模角度贡献了以下工作：首先，我们开发了一套完整的合成工具包，利用不同数据模态间的双向协同效应，高效生成大规模高质量语料库，覆盖从标准图表到复杂交互式网页UI及代码驱动动画等多种类型。基于该工具包，我们构建了JanusCode-800K——目前最大的多模态代码语料库。借此，我们训练了JanusCoder和JanusCoderV模型，建立起一个视觉-程序化接口，能够根据文本指令、视觉输入或二者组合生成代码。我们的统一模型突破了现有方法为孤立任务构建专用模型的局限。在面向文本和视觉的编码任务上进行大量实验表明，JanusCoder系列性能卓越，其7B至14B规模的模型表现接近甚至超越商业模型。此外，深入分析揭示了程序化逻辑与视觉表达协调统一的关键机制。我们的代码与模型检查点已发布于github.com/InternLM/Ja…

The End of Manual Decoding: Towards Truly End-to-End Language Models
人工解码的终结：迈向真正端到端的语言模型
大语言模型的"端到端"标签实为误称。实践中，它们依赖不可微分的解码过程，需要繁琐地手动调整温度 (temperature) 和 top-p 等超参数。本文提出 AutoDeco，一种通过学会控制自身解码策略实现真正"端到端"生成的新型架构。我们在标准 Transformer 上添加轻量级头模块，这些模块在每一步动态预测上下文相关的温度与 top-p 值，同时输出下一个 token 的 logits。该方法将解码转化为参数化的 token 级过程，使模型能在单次前向传播中自我调整采样策略。
通过在八个基准测试上的广泛实验，我们证明 AutoDeco 不仅显著优于默认解码策略，更达到了与通过"测试集过拟合"获得的 oracle 调优基线相当的性能——后者是任何静态方法的实际上限。重要的是，我们发现模型涌现出基于指令的解码控制能力：模型学会解析自然语言指令 (如"低随机性生成")，并逐 token 调整预测的温度与 top-p 值，这为可控交互式大语言模型解码开辟了新范式。

Tongyi DeepResearch Technical Report
通义深度研究技术报告
我们推出通义深度研究，这是一个面向长周期深度信息检索研究任务专门设计的智能体大语言模型。为激发自主深度研究能力，该模型通过端到端训练框架开发，融合智能体中期训练与后期训练，实现了跨复杂任务场景的可扩展推理与信息探索。我们设计了高度可扩展的全自动数据合成流水线，无需依赖昂贵的人工标注，并能支持所有训练阶段。通过为每个阶段构建定制化环境，系统确保了全流程交互的稳定性与一致性。通义深度研究模型总参数量达305亿，每个token仅激活33亿参数，在多项智能体深度研究基准测试中取得了最先进的性能表现，包括Humanity's Last Exam、BrowseComp、BrowseComp-ZH、WebWalkerQA、xbench-DeepSearch、FRAMES以及xbench-DeepSearch-2510。我们已开源模型、框架及完整解决方案，以促进社区发展。

Video-Thinker: Sparking "Thinking with Videos" via Reinforcement Learning
Video-Thinker：通过强化学习实现“用视频思考”
图像推理方法（尤其是“用图像思考”）的最新进展，在多模态大语言模型 (MLLMs) 中取得了显著成功；然而，这种动态推理范式尚未延伸至视频推理任务。本文提出 Video-Thinker，通过自主利用模型固有的“定位” (grounding) 和“字幕” (captioning) 能力，在推理过程中生成推理提示，从而赋能 MLLMs 实现视频思考。为激发此能力，我们构建了 Video-Thinker-10K 数据集，其中包含思维链推理序列中的自主工具使用案例。训练策略首先采用监督微调 (SFT) 学习推理格式，再通过组相对策略优化 (GRPO) 强化推理能力。该方法使 MLLMs 能自主处理视频推理中的定位和字幕任务，无需构建和调用外部工具。大量实验表明，Video-Thinker 在领域内任务及挑战性领域外视频推理基准（包括 Video-Holmes、CG-Bench-Reasoning 和 VRBench）上均实现显著性能增益。我们的 Video-Thinker-7B 大幅优于 Video-R1 等现有基线模型，在 7B 规模 MLLMs 中达到了最先进性能。

Emu3.5: Native Multimodal Models are World Learners
Emu3.5：原生多模态模型实现世界认知
我们推出 Emu3.5——一个大规模多模态世界模型，能够原生预测视觉与语言模态的下一状态。该模型基于包含超过10万亿Token的视觉-语言交错数据集进行端到端预训练，采用统一的下一Token预测目标，数据集主要源自互联网视频的连续帧及其转录文本。Emu3.5可原生处理交错式视觉-语言输入，并生成对应的交错式多模态输出。通过大规模强化学习微调，进一步增强了模型的多模态推理与生成能力。为提升推理效率，我们提出离散扩散适应（DiDA）方法，将逐Token解码转化为双向并行预测，在保持性能不变的前提下实现单图像推理速度提升约20倍。
Emu3.5展现出卓越的原生多模态能力，包括：长序列视觉-语言生成、任意模态到图像（X2I）生成、以及复杂富文本图像生成。同时具备强大的世界建模泛化能力，可在多样化场景与任务中实现时空一致的世界探索和开放世界具身智能控制。性能对比显示，Emu3.5在图像生成与编辑任务上达到与Gemini 2.5 Flash Image（Nano Banana）相当的水平，并在交错生成基准测试中取得更优结果。我们已在github.com/baaivision/…

AgentFold: Long-Horizon Web Agents with Proactive Context Management
AgentFold：具备主动上下文管理的长程网络智能体
基于大语言模型的网络智能体在信息检索领域展现出巨大潜力，但其在长程任务中的有效性受限于上下文管理的基本权衡。主流基于ReAct的智能体因累积噪声原始历史而面临上下文过载，而固定式总结完整历史的方法则存在关键细节不可逆丢失的风险。针对这些问题，我们提出AgentFold，一种以主动上下文管理为核心的新型智能体范式，其灵感源自人类回溯性整合的认知过程。AgentFold将上下文视为可主动塑造的动态认知工作区，而非被动填充的日志。在每个步骤中，它学习执行“折叠”操作，该操作在多个尺度上管理历史轨迹：既可执行细粒度压缩以保留关键细节，也可进行深度整合以抽象化多步骤子任务。在主流基准测试中的结果显著：仅通过简单监督微调（无需持续预训练或强化学习），我们的AgentFold-30B-A3B智能体在BrowseComp上达到36.2%，在BrowseComp-ZH上达到47.3%。值得注意的是，该性能不仅超越或持平规模大得多的开源模型（如DeepSeek-V3.1-671B-A37B），还超越了领先的专有智能体（如OpenAI的o4-mini）。

A Survey of Data Agents: Emerging Paradigm or Overstated Hype?
数据智能体综述：新兴范式还是过度炒作？
大语言模型 (LLM) 的快速发展催生了数据智能体 (Data Agent) —— 旨在协调数据与人工智能 (AI) 生态系统以处理复杂数据任务的自主系统。然而，"数据智能体"这一术语目前存在定义模糊和应用不一致的问题，常将简单的查询响应程序与复杂的自主架构相混淆。这种术语模糊性导致用户期望错配、责任界定困难以及行业发展障碍。受 SAE J3016 驾驶自动化标准启发，本综述首次提出数据智能体的系统化分层分类法，包含六个级别，描述并追踪自主性从手动操作 (L0) 到生成式全自主数据智能体 (L5) 愿景的渐进演变，从而明确能力边界与责任分配。基于此框架，我们按自主性递增顺序对现有研究进行结构化综述，涵盖专注于数据管理、数据准备和数据分析的专用数据智能体，以及面向高自主性多功能综合系统的新兴研究。我们进一步分析了推进数据智能体发展的关键演进节点与技术空白，特别关注当前从 L2 向 L3 的演进阶段——此时数据智能体正从流程执行转向自主协调。最后，以展望性路线图作为总结，前瞻主动式生成数据智能体的发展前景。

FARMER: Flow AutoRegressive Transformer over Pixels
FARMER：基于像素的流自回归Transformer
直接建模原始数据分布的显式似然是机器学习领域的核心课题，自回归建模已通过大语言模型实现了规模化成功应用。然而，视觉像素数据的连续自回归建模面临序列极长和高维空间的挑战。本文提出FARMER——一种新颖的端到端生成框架，将归一化流（NF）与自回归（AR）模型相结合，直接从原始像素实现易处理似然估计和高质量图像合成。FARMER采用可逆自回归流将图像转换为潜在序列，其分布由自回归模型隐式地建模。针对像素级建模中的冗余和复杂度问题，我们提出自监督降维方法，将NF潜在通道划分为信息组和冗余组，从而实现更高效的自回归建模。此外，我们设计了一步蒸馏方法以显著加速推理速度，并引入基于重采样的无分类器引导算法来提升图像生成质量。大量实验表明，FARMER在提供精确似然估计和可扩展训练的同时，与现有基于像素的生成模型相比展现出具有竞争力的性能。

RoboOmni: Proactive Robot Manipulation in Omni-modal Context
RoboOmni：全模态情境下的主动机器人操作
多模态大语言模型 (MLLMs) 的最新进展，显著推动了面向机器人操作的视觉-语言-动作 (VLA) 模型的快速发展。尽管现有方法在许多场景中表现有效，但它们主要依赖显式指令；而在实际人机交互过程中，人类很少直接给出此类指令。要实现高效协作，机器人需要具备主动推断用户意图的能力。为此，本研究提出跨模态情境指令这一新型范式，其核心在于从口语对话、环境声响及视觉线索中推导意图，而非依赖显式命令。针对这一范式，我们开发了 RoboOmni——一个基于端到端全模态大语言模型的感知-思考-对话-执行框架，该框架统一整合了意图识别、交互确认与动作执行功能。RoboOmni 通过时空维度融合听觉与视觉信号，实现鲁棒的意图识别，并支持直接语音交互。为解决机器人操作领域主动意图识别训练数据匮乏的问题，我们构建了 OmniAction 数据集，包含 14 万条交互片段、5000 余名说话者、2400 种事件音效、640 种背景环境以及六类情境指令。仿真与实物环境实验表明，RoboOmni 在任务成功率、推理速度、意图识别准确率和主动辅助能力上均优于基于文本及自动语音识别 (ASR) 的基线方法。

Kimi Linear: An Expressive, Efficient Attention Architecture
Kimi Linear：一种表达力强、高效的注意力架构
我们介绍了 Kimi Linear，一种混合线性注意力架构，首次在各种场景的公平比较下——包括短上下文、长上下文和强化学习 (RL) 扩展机制——超越完整注意力。其核心是 Kimi Delta Attention (KDA)，一种表达力强的线性注意力模块，通过更细粒度的门控机制扩展了 Gated DeltaNet，从而更有效地利用有限状态 RNN 内存。我们定制的分块算法通过 Diagonal-Plus-Low-Rank (DPLR) 转移矩阵的专门变体实现了高硬件效率，与通用 DPLR 公式相比显著减少了计算量，同时更符合经典的 delta 规则。
我们基于 KDA 和 Multi-Head Latent Attention (MLA) 的分层混合，预训练了一个具有 30 亿激活参数和 480 亿总参数的 Kimi Linear 模型。实验表明，在相同训练方案下，Kimi Linear 在所有评估任务中均以显著优势优于完整 MLA，同时将 KV 缓存使用量减少高达 75%，并在 100 万上下文下实现高达 6 倍的解码吞吐量。这些结果证明，Kimi Linear 可以作为完整注意力架构的即插即用替代方案，具有卓越的性能和效率，适用于输入和输出长度更长的任务。
为支持进一步研究，我们开源了 KDA 内核和 vLLM 实现，并发布了预训练和指令调优的模型检查点。

Game-TARS: Pretrained Foundation Models for Scalable Generalist Multimodal Game Agents
Game-TARS：面向可扩展通用多模态游戏智能体的预训练基础模型
我们提出了Game-TARS，一种通用游戏智能体，采用统一且可扩展的动作空间进行训练，该空间基于与人类操作习惯一致的本地键盘-鼠标输入。不同于基于API或图形用户界面的方法，此范式支持在异构领域（包括操作系统、网页和模拟游戏）中进行大规模持续预训练。Game-TARS在超过5000亿个token的多样化交互轨迹和多模态数据上完成了预训练。核心技术包括用于减少因果混淆的衰减持续损失函数，以及平衡推理深度与计算成本的高效稀疏思维策略。实验结果显示，Game-TARS在开放世界《我的世界》任务中的成功率达到了先前最优模型的约2倍，在未接触过的网页3D游戏中表现接近人类新手水平，并在第一人称射击游戏基准测试中超越了GPT-5、Gemini-2.5-Pro和Claude-4-Sonnet。训练阶段与测试阶段的扩展性实验表明，当扩展到跨游戏和多模态数据时，统一动作空间能持续带来性能提升。我们的研究成果证明，将简洁可扩展的动作表示与大规模预训练相结合，为开发具有广泛计算机操作能力的通用智能体开辟了可行路径。

ReForm: Reflective Autoformalization with Prospective Bounded Sequence Optimization
ReForm: 基于前瞻性有界序列优化的反思式自动形式化
自动形式化 (Autoformalization) 旨在将自然语言描述的数学内容转化为机器可验证的形式化语句，这对于利用形式化数学推理解决自然语言表述的数学问题至关重要。尽管大语言模型 (LLM) 能够生成语法正确的形式化语句，但往往难以保持原始问题的语义意图。这种局限源于现有 LLM 方法将自动形式化简单视为翻译任务，缺乏人类专家天然具备的自我反思与迭代优化机制。为解决这些问题，我们提出 ReForm——一种反思式自动形式化方法，通过将语义一致性评估深度整合至形式化过程，使模型能够迭代生成形式化语句、评估语义保真度，并通过渐进优化实现自我纠错。为有效训练该反思模型，我们提出前瞻性有界序列优化 (Prospective Bounded Sequence Optimization, PBSO) 方法，通过在序列不同位置施加差异化奖励机制，确保模型同步提升自动形式化精度与语义验证能力，避免流于表面的评判损害反思效能。在四个自动形式化基准测试上的实验表明，ReForm 相较最强基线平均提升 22.6%。为进一步确保评估可靠性，我们构建了 ConsistencyCheck 基准数据集，包含 859 条专家标注条目。该基准不仅验证了 LLM 作为评判者的可行性，更揭示出自动形式化本身具有极高难度：即便人类专家在高达 38.5% 的案例中仍会出现语义错误。

## 每周AI论文速递（251103-251107）

Thinking with Video: Video Generation as a Promising Multimodal Reasoning Paradigm
视频思维：视频生成作为一种前景广阔的多模态推理范式
"文本思维"与"图像思维"范式显著提升了大语言模型 (LLMs) 和视觉语言模型 (VLMs) 的推理能力。然而，这些范式存在固有局限：(1) 图像仅能捕捉瞬时状态，无法表征动态过程或连续变化；(2) 文本与视觉作为独立模态相互分离，阻碍了统一的多模态理解与生成。为突破这些限制，我们提出"视频思维"新范式，通过 Sora-2 等视频生成模型，在统一时序框架中实现视觉与文本推理的融合。为支撑本研究，我们构建了视频思维基准 (VideoThinkBench)，涵盖两大任务类型：(1) 视觉中心任务 (如视觉推理谜题)；(2) 文本中心任务 (如 GSM8K、MMMU 的子集)。评估结果表明，Sora-2 具备卓越的推理能力：在视觉中心任务中，其性能与最先进 (SOTA) VLMs 相当，且在视觉推理游戏等任务中实现超越；在文本中心任务中，Sora-2 在 MATH 数据集上达到 92% 准确率，在 MMMU 上达到 75.53% 准确率。我们进一步系统分析了其能力来源，发现自洽性与上下文学习能有效提升模型性能。综上所述，本研究证实视频生成模型有望成为统一的多模态理解与生成模型，从而确立"视频思维"作为统一的多模态推理范式。

VCode: a Multimodal Coding Benchmark with SVG as Symbolic Visual Representation
VCode：以 SVG 作为符号化视觉表示的多模态编码基准
在 AI 智能体时代，代码已成为推理与行动的一种精确且可执行的媒介。然而，相关进展主要集中于以语言为中心的任务，如程序合成与调试，导致视觉导向的编码研究相对不足。受人类基于草图进行推理的机制启发，我们提出将 SVG 代码作为一种紧凑、可解释且可执行的视觉表示形式。本文引入 VCode 基准，将多模态理解任务重新定义为代码生成问题：给定输入图像，模型必须生成能保留符号语义以支持下游推理的 SVG 代码。VCode 涵盖三大领域：通用常识（MM-Vet）、专业学科（MMMU）以及视觉核心感知（CV-Bench）。为评估符号保真度，我们提出 CodeVQA——一种创新评估协议，通过策略模型对渲染后的 SVG 进行问答，正确答案即表明符号信息被真实保留。实证研究表明，当前前沿视觉语言模型（VLM）在生成精确 SVG 方面仍面临困难，这暴露出语言导向与视觉导向编码能力之间存在显著差距。为弥合这一差距，我们开发了 VCoder 智能体框架，从两个维度增强 VLM 能力：（i）修订式思考，通过迭代分析差异持续优化 SVG 代码；（ii）视觉工具赋能，利用检测器与解析器提供模型固有能力之外的结构化线索（如物体、形状与文本）。在多项基准测试中，尽管具备强推理能力的前沿 VLM 整体表现良好，但在专业知识与三维推理方面仍存在局限。VCoder 相较性能最优的 Claude-4-Opus 实现了 12.3 个百分点的整体提升。人类研究表明，人类与 VLM 在渲染 SVG 任务上表现均有所下降，但二者表现的一致性印证了符号化视觉表示的巨大潜力。本基准与代码已开源于 github.com/CSU-JPG/VCo…

Diffusion Language Models are Super Data Learners
扩散语言模型是卓越的数据学习器
在严格控制的预训练条件下，我们观察到性能交叉现象：当唯一数据有限时，扩散语言模型 (DLMs) 通过增加训练周期数持续优于自回归 (AR) 模型。该交叉点随数据量增加或质量提升而延迟出现，随模型规模扩大而提前出现，且在密集与稀疏架构中均稳定存在。我们将性能提升归因于三个叠加因素：(1) 任意顺序建模能力，(2) 迭代双向去噪带来的超密集计算优势，以及 (3) 内置的蒙特卡洛数据增强；输入噪声或参数噪声虽能在数据受限时改善 AR 模型性能，但无法消除性能差距。在大规模训练中，使用约 1.5T token 计算预算、基于 100 亿唯一 Python token 训练的 17 亿参数 DLM，其性能超越了在严格匹配条件下训练的 AR 编码器。此外，10 亿参数 DLM 仅通过重复标准预训练数据（仅使用 10 亿 token），即在 HellaSwag 上获得 >56% 准确率，在 MMLU 上获得 >33% 准确率，且不依赖任何特殊技巧。我们还证实，在此数据受限的训练模式下，验证集交叉熵上升并不代表下游任务性能退化。

Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization
不要限制你的 VLA：对齐视觉表示以实现 OOD 泛化
视觉-语言-动作 (Vision-Language-Action, VLA) 模型的成功日益显著，这源于预训练视觉-语言模型 (Vision-Language Models, VLMs) 能够为智能体提供可迁移的世界知识和视觉-语言 (Vision-Language, VL) 基础，从而为具有更广泛泛化能力的动作模型奠定基础。然而，当这些 VLMs 被微调以适应动作模态时，其原始的 VL 表示和知识保留程度尚不明确。在本工作中，我们系统研究了 VLA 微调过程中的表示保留问题，发现简单的动作微调会导致视觉表示退化。为表征和量化这些影响，我们分析了 VLA 的隐藏表示和注意力图；进一步，我们设计了一组针对性任务和方法，将 VLA 模型与原始 VLM 进行对比，以分离动作微调引起的 VL 能力变化。我们还评估了多种对齐视觉表示的策略，并提出一种简单有效的方法，该方法可缓解退化并提升对分布外 (Out-of-Distribution, OOD) 场景的泛化性能。总体而言，我们的分析明确了动作微调与 VL 表示退化之间的权衡，并指出了恢复继承 VL 能力的实用途径。代码公开可用：blind-vla-paper.github.io

Every Activation Boosted: Scaling General Reasoner to 1 Trillion Open Language Foundation
每次激活皆增强：将通用推理模型扩展至万亿级开放语言基础模型
我们推出 Ling 2.0 系列，这是一套以推理为导向的语言基础模型，其核心设计原则是每次激活操作均能提升推理能力。该系列在统一的混合专家 (MoE) 架构下，实现了从百亿级到万亿级参数的可扩展性，并基于经验缩放定律，着重优化了高稀疏性、跨尺度一致性与计算效率。系列包含三款指令调优模型（非自主推理型）——Ling-mini-2.0、Ling-flash-2.0 和 Ling-1T，总参数量覆盖 160 亿至 1 万亿，与稠密模型相比，激活计算效率提升最高达 7 倍。Ling 2.0 融合了模型架构、预训练、后训练及基础设施的协同创新：采用具备 MTP（多维张量并行）的高稀疏 MoE 以实现高效推理、注入推理导向数据与训练中程思维链 (CoT) 激活、应用基于强化学习的微调（DFT、Evo-CoT），并实现全精度 FP8 训练及细粒度异构流水线。在万亿参数规模上，Ling-1T 确立了推理精度与计算效率的新帕累托前沿，证明当稀疏激活与推理目标精准对齐时，能够实现可扩展的高效智能。总体而言，Ling 2.0 为未来推理与思维模型（包括基于同一基座的 Ring 系列）的发展提供了连贯、开放且高效的基础框架。

V-Thinker: Interactive Thinking with Images
V-Thinker：基于图像的交互式思考
如何使大型多模态模型 (LMMs) 深度融合图像交互与长程推理能力，始终是该领域长期存在的挑战。近期以视觉为中心的推理研究探索出名为“基于图像的思考”的新范式，推动模型从图像辅助推理转向图像交互式思考。尽管这一突破使模型能专注于细粒度图像区域，但有限的视觉工具空间与任务定制化工作流设计仍制约着进一步发展。为突破此局限，我们提出 V-Thinker——一种通用多模态推理助手，通过端到端强化学习实现以视觉为中心的交互式思考。该系统包含两大核心组件：(1) 数据进化飞轮，可在多样性、质量与难度三个维度上自动合成、演进并验证交互式推理数据集；(2) 视觉渐进式训练课程，先通过点级监督实现感知对齐，再通过两阶段强化学习框架融合交互式推理。此外，我们推出 VTBench 专家验证基准，专门针对视觉交互式推理任务。大量实验表明，V-Thinker 在通用推理与交互式推理场景中均稳定超越基于 LMM 的强基线模型，为图像交互式推理应用的发展提供了重要洞见。

ThinkMorph: Emergent Properties in Multimodal Interleaved Chain-of-Thought Reasoning
ThinkMorph：多模态交织思维链推理中的涌现性质
多模态推理需要语言与视觉的迭代协调，但何种交织思维链具有意义仍不明确。我们提出，文本与图像思维应作为互补（而非同构）的模态，共同推进推理。基于此原则，我们开发了ThinkMorph——一个统一模型，其在约2.4万条高质量交织推理序列上微调，覆盖多种视觉参与度的任务。ThinkMorph能够生成渐进的文本-图像推理步骤，在保持语言逻辑连贯的同时，具体操控视觉内容。该模型在以视觉为核心的基准测试中显著提升（平均优于基础模型34.7%），并能泛化至域外任务，性能匹配或超越更大规模的专有多模态大语言模型。除性能优势外，ThinkMorph展现出涌现的多模态智能特性，包括未见的视觉处理能力、推理模式的自适应切换，以及通过多样化多模态思维实现更优的测试阶段扩展。这些发现为探索统一多模态推理模型的涌现能力指明了潜力方向。

OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows
OS-Sentinel：基于现实工作流混合验证的安全增强型移动 GUI 智能体
基于视觉语言模型 (VLM) 的计算机操作智能体在移动平台等数字环境中已展现出类人的操作能力。尽管这些智能体在推动数字自动化方面潜力巨大，但其可能引发的不安全操作（如系统破坏和隐私泄露）正引起高度关注。在移动环境广阔而复杂的操作空间中检测这些安全威胁是一项重大挑战，目前该领域的研究仍严重不足。为奠定移动智能体安全研究的基础，我们推出了 MobileRisk-Live——一个动态沙盒环境，并配套构建了包含细粒度标注现实轨迹的安全检测基准。在此基础上，我们提出 OS-Sentinel：一种新型混合安全检测框架，通过协同整合形式验证器（用于检测显式系统级违规）和基于 VLM 的上下文判断器（用于评估上下文风险与智能体行为），实现综合安全保障。实验表明，OS-Sentinel 在多项指标上相较现有方法提升 10%-30%。深入分析提供了关键见解，有力推动更安全、更可靠的自主移动智能体的发展。

INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization Formats
INT vs. FP：细粒度低比特位量化格式的综合研究
现代 AI 硬件（如 Nvidia 的 Blackwell 架构）正日益广泛采用低精度浮点 (FP) 格式，以处理大语言模型 (LLMs) 中普遍存在的激活值异常值 (outliers)。尽管存在这一行业趋势，但针对不同粒度的 FP 与整数 (INT) 量化方法的统一比较仍属空白，导致算法与硬件协同设计缺乏明确指导。本文通过系统研究 FP 和 INT 格式之间的权衡，填补了这一空白。我们揭示了一个关键的性能转折点：虽然 FP 在粗粒度量化中表现优异，但在细粒度（块级）量化下的比较则更为复杂。全面的比较结果表明，对于流行的 8 位细粒度格式（如块大小为 32 的 MX），MXINT8 在算法精度和硬件效率上均优于其 FP 对应方案。然而，对于 4 位格式，FP（例如 MXFP4 和 NVFP4）通常具有精度优势，但我们证明，在应用 Hadamard 旋转等异常值缓解技术时，NVINT4 可以超越 NVFP4。我们还提出了一种对称裁剪方法，解决了细粒度低比特位 INT 训练中的梯度偏差 (gradient bias) 问题，使 MXINT8 训练实现近乎无损的性能。这些发现对当前硬件发展路径提出了挑战，表明通用型 FP 方法并非最优，并主张细粒度 INT 格式（尤其是 MXINT8）能为未来 AI 加速器在精度、功率和效率之间提供更佳平衡。

Continuous Autoregressive Language Models
连续自回归语言模型
大语言模型 (LLMs) 的效率从根本上受限于其顺序、逐个 token 的生成过程。我们认为，要克服这一瓶颈，需要引入一个新的 LLM 扩展设计维度：提升每个生成步骤的语义带宽。为此，我们提出了连续自回归语言模型 (CALM)，实现了从离散的下一个 token 预测到连续的下一个向量预测的范式转变。CALM 采用高保真自编码器将 K 个 token 的块压缩为单个连续向量，并能以超过 99.9% 的准确率重建原始 token。这使得我们可以将语言建模为连续向量序列而非离散 token 序列，从而将生成步骤数量减少到原来的 1/K。这一范式转变需要新的建模工具；因此，我们开发了一套全面的无似然框架，支持在连续域中进行稳健的训练、评估和可控采样。实验表明，CALM 显著优化了性能与计算之间的权衡，在计算成本大幅降低的情况下，达到了性能强大的离散基线模型的水平。更重要的是，这些发现将下一个向量预测确立为一个强大且可扩展的路径，用于构建超高效语言模型。代码：github.com/shaochenze/…

Scaling Agent Learning via Experience Synthesis
通过经验合成实现智能体学习的规模化
尽管强化学习 (RL) 能够通过交互式自我改进增强大语言模型 (LLM) 智能体的能力，但其实际应用仍面临挑战：高成本的 rollout、有限的任务多样性、不可靠的奖励信号以及复杂的基础设施，这些问题都阻碍了可扩展经验数据的收集。为解决这些挑战，我们提出了 DreamGym——首个以可扩展性为核心设计的统一框架，通过合成多样化经验来实现自主智能体的高效在线 RL 训练。DreamGym 不依赖高成本的实境 rollout，而是将环境动态蒸馏为基于推理的经验模型，通过逐步推理生成一致的状态转移和反馈信号，从而为 RL 提供可扩展的智能体 rollout 收集。为提升状态转移的稳定性和质量，DreamGym 采用经验回放缓冲区，该缓冲区使用离线采集的真实世界数据初始化，并通过实时交互数据持续扩充，以主动支撑智能体训练。为优化知识获取，DreamGym 自适应生成针对当前智能体策略的新任务，实现更高效的在线课程学习。在不同环境与智能体骨干网络上的实验表明，DreamGym 在完全合成设置和仿真到实境迁移场景中均能显著提升 RL 训练效果。在 WebArena 等非 RL 就绪任务上，DreamGym 以超过 30% 的优势超越所有基线方法；在 RL 就绪但成本高昂的场景中，仅使用合成交互即可达到与 GRPO 和 PPO 相当的性能。当将纯合成经验训练的策略迁移至实境 RL 时，DreamGym 在大幅减少实境交互次数的同时，带来显著的额外性能提升，为通用 RL 提供了一种可扩展的热启动策略。

π_RL: Online RL Fine-tuning for Flow-based Vision-Language-Action Models
π_RL：基于流的视觉-语言-动作模型的在线强化学习微调
视觉-语言-动作 (VLA) 模型能够使机器人根据多模态输入理解并执行复杂任务。尽管近期研究探索利用强化学习 (RL) 自动化扩展监督微调 (SFT) 中繁重的数据收集流程，但由于基于流的 VLA (如 π0\pi_0π0​、π0.5\pi_{0.5}π0.5​) 通过迭代去噪产生的动作对数似然难以计算，大规模 RL 应用仍面临挑战。
我们提出 πRL\pi_{\text{RL}}πRL​ 解决这一难题，这是一个支持在并行仿真中训练基于流 VLA 的开源框架。πRL\pi_{\text{RL}}πRL​ 实现两种 RL 算法：(1) {Flow-Noise} 将去噪过程建模为离散时间马尔可夫决策过程 (MDP)，通过可学习的噪声网络实现精确对数似然计算；(2) {Flow-SDE} 将去噪与智能体-环境交互相结合，构建双层 MDP，采用常微分方程至随机微分方程 (ODE-to-SDE) 转换以提升 RL 探索效率。
我们在 LIBERO 与 ManiSkill 基准测试中评估 πRL\pi_{\text{RL}}πRL​。在 LIBERO 上，πRL\pi_{\text{RL}}πRL​ 将少样本 SFT 模型 π0\pi_0π0​ 和 π0.5\pi_{0.5}π0.5​ 的性能分别从 57.6% 提升至 97.6% 和从 77.1% 提升至 98.3%。在 ManiSkill 中，我们于 320 个并行环境中训练 πRL\pi_{\text{RL}}πRL​，在 4352 项抓取放置任务中，将 π0\pi_0π0​ 从 41.6% 提升至 85.7%，π0.5\pi_{0.5}π0.5​ 从 40.0% 提升至 84.8%，证明了异构仿真环境下可扩展的多任务 RL 能力。
总体而言，πRL\pi_{\text{RL}}πRL​ 相比 SFT 模型实现了显著性能提升与更强泛化能力，验证了在线 RL 对基于流 VLA 的有效性。

When Visualizing is the First Step to Reasoning: MIRA, a Benchmark for Visual Chain-of-Thought
当可视化是推理的第一步：MIRA，一个视觉思维链基准
我们提出了 MIRA，这是一个新基准，旨在评估模型在生成中间视觉图像对成功推理至关重要的场景中的表现。与传统仅依赖文本的思维链方法不同，MIRA 中的任务要求模型生成并利用中间图像（如草图、结构图或路径图）来指导推理过程。这种设置模拟了人类通过“画图思考”解决复杂问题的方式。MIRA 专注于本质上具有挑战性的任务，这些任务涉及复杂结构、空间关系或难以仅用语言表达的推理步骤。为确保评估数据的高质量，我们包含了 546 个多模态问题，并标注了中间视觉图像和最终答案。我们还为 MIRA 设计了一个统一的评估协议，涵盖三个输入评估级别：仅图像和问题的直接输入、带图像和思考提示的纯文本思维链输入，以及带标注图像线索和文本思考提示的视觉思维链输入。为探索基准上模型能力的上限，我们报告了不同 k 设置下的 pass@k 和多数投票准确率。实验结果显示，现有多模态大语言模型（包括最强私有模型和强大开放权重模型）在仅依赖文本提示时表现不佳；但当提供中间视觉线索时，模型性能一致提升，在所有模型和任务中平均相对提升 33.7%。我们还通过扩展搜索空间和设计与视觉思维链对齐的文本提示来探索上限，但两者与视觉思维链设置相比改进有限。这些结果凸显了想象视觉信息在 MIRA 成功推理中的关键作用。

UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions
UniAVGen：基于非对称跨模态交互的统一音视频生成
由于缺乏有效的跨模态建模，现有开源音视频生成方法通常存在唇形同步效果不佳和语义一致性不足的问题。为解决这些局限，我们提出UniAVGen——一个统一的联合音视频生成框架。UniAVGen采用双分支联合合成架构，通过两个并行扩散Transformer (DiTs) 构建统一的跨模态潜在空间。其核心是非对称跨模态交互机制，该机制实现双向、时序对齐的跨注意力，从而确保精确的时空同步与语义一致性。此外，通过面部感知调制模块增强跨模态交互，该模块在交互过程中动态聚焦于显著区域。为提升推理阶段的生成质量，我们额外引入模态感知无分类器引导策略，这种创新方法能够显式增强跨模态关联信号。值得注意的是，UniAVGen的鲁棒联合合成设计使其能在单一模型中无缝集成关键音视频任务，包括联合音视频生成与续写、视频到音频配音以及音频驱动视频合成。综合实验表明，在训练样本量显著减少的情况下 (1.3M vs. 30.1M) ，UniAVGen在音视频同步性、音色一致性和情感一致性方面均展现出全面优势。

EBT-Policy: Energy Unlocks Emergent Physical Reasoning Capabilities
EBT-策略：能量解锁涌现的物理推理能力
基于生成模型 (如扩散策略) 的隐式策略，已成为机器人策略学习与视觉-语言-动作 (VLA) 模型的标准方法。然而，这些方法常面临高计算成本、暴露偏差及推理动态不稳定等问题，导致在分布偏移下容易发散。基于能量的模型 (EBMs) 通过端到端学习能量景观并建模平衡动力学，有效提高了鲁棒性并减少了暴露偏差。但传统上，基于EBMs的策略难以有效扩展。近期基于能量的Transformer (EBTs) 的研究证明了EBMs在高维空间的可扩展性，然而其在解决物理实体模型核心挑战方面的潜力仍待深入挖掘。我们提出了一种新型基于能量的架构——EBT-策略，旨在解决机器人及现实场景中的核心问题。在模拟与真实任务中，EBT-策略均持续优于基于扩散的策略，且所需训练与推理计算量更少。值得注意的是，对于某些任务，它仅需两个推理步骤即可收敛，较扩散策略的100步减少了50倍 (即步数降至1/50)。此外，EBT-策略展现出先前模型未见的涌现能力，例如仅通过行为克隆、无需显式重试训练，即可实现从失败动作序列的零样本恢复。通过利用其标量能量进行不确定性感知推理与动态计算分配，EBT-策略为在分布偏移下实现鲁棒、可泛化的机器人行为开辟了前景广阔的路径。

LEGO-Eval: Towards Fine-Grained Evaluation on Synthesizing 3D Embodied Environments with Tool Augmentation
LEGO-Eval：基于工具增强的3D具身环境合成细粒度评估
尽管大语言模型 (LLMs) 在自动生成3D场景方面已取得进展，但生成结果常缺乏真实环境中的合理空间布局与对象属性。该问题根源在于指令描述过于粗略，因此需通过更精细、贴合现实场景的细粒度指令来改进3D场景合成。若缺乏真实场景，在虚拟环境中训练具身智能体会使其习得偏离真实物理规则与语义关系的先验知识，最终导致实际部署时性能下降。因此，验证细粒度指令与生成场景的一致性对有效学习至关重要。然而，现有评估方法（如CLIPScore与视觉语言模型VLMs）难以可靠衡量该一致性，主因在于其对3D场景理解不足，常导致场景元素关联错误。为此，我们提出LEGO-Eval评估框架，通过集成多类工具显式构建场景元素关联，从而实现更精准的一致性评估。同时，我们构建LEGO-Bench基准测试集，包含定义真实环境复杂布局与属性的详细指令集。实验表明，在场景-指令一致性评估中，LEGO-Eval的F1分数较VLM-as-a-judge提升0.41分。基于LEGO-Bench的测试揭示出现有生成方法的明显缺陷：所有被测方法生成完全符合细粒度指令场景的成功率最高仅为10%。

## 每周AI论文速递（251110-251114）

Lumine: An Open Recipe for Building Generalist Agents in 3D Open Worlds
Lumine: 构建3D开放世界中通用AI智能体的开放方案
我们推出Lumine，这是首个用于开发通用AI智能体的开放方案，能够在挑战性3D开放世界环境中实时完成长达数小时的复杂任务。Lumine采用类人交互范式，以视觉语言模型驱动，端到端地统一感知、推理与行动。它以5Hz处理原始像素，生成精确的30Hz键鼠动作，并仅在必要时自适应触发推理。在《原神》中训练后，Lumine成功通关整个五小时蒙德主线剧情，效率达到人类水平，并能遵循自然语言指令，在3D开放世界探索和2D图形界面操作中广泛执行收集、战斗、解谜及NPC交互等任务。除领域内性能外，Lumine还展现出强大的零样本跨游戏泛化能力：无需微调，即可在《鸣潮》中完成100分钟任务，并在《崩坏：星穹铁道》中通关完整五小时第一章。这些显著成果证明了Lumine在不同世界与交互机制中的高效性，标志着开放环境下通用AI智能体发展的实质性进展。

Grounding Computer Use Agents on Human Demonstrations
基于人类演示的计算机使用智能体基础构建
构建可靠的计算机使用智能体需要基础化：将自然语言指令与正确的屏幕元素精确关联。尽管已有大量网页和移动交互数据集，但桌面环境的高质量数据资源仍显不足。为填补这一空白，我们推出了 GroundCUA——一个基于专家人类演示构建的大规模桌面基础化数据集。该数据集覆盖 12 个类别下的 87 个应用程序，包含 5.6 万张屏幕截图，所有屏幕元素均经过精细标注，累计人类验证标注量超过 356 万条。基于这些演示，我们生成了涵盖广泛现实任务的多样化指令，为模型训练提供高质量数据支撑。利用 GroundCUA，我们开发了 GroundNext 系列模型，能够将指令映射至对应 UI 元素。在 30 亿和 70 亿参数规模下，通过监督微调，GroundNext 在五项基准测试中均达到最先进水平，且训练数据量不足先前工作的十分之一。后续强化学习进一步提升了模型性能，在 OSWorld 基准的智能体测试环境中，以 o3 作为规划器时，GroundNext 取得了与使用远超其训练数据量的模型相当或更优的结果。这些成果印证了高质量专家驱动数据集对推进通用计算机使用智能体发展的关键作用。

Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model Reasoning Ability in VibeThinker-1.5B
小模型，大逻辑：多样性驱动优化激发 VibeThinker-1.5B 的大模型级推理能力
针对当前普遍认为小模型天生缺乏强大推理能力的共识，本报告提出了 VibeThinker-1.5B，这是一个通过频谱到信号原则 (SSP) 开发的 1.5B 参数密集模型。该模型挑战了通过扩大模型参数来提升能力的流行方法，例如 DeepSeek R1 (671B) 和 Kimi k2 (>1T) 等模型所采用的策略。SSP 框架首先采用两阶段多样性探索蒸馏 (SFT) 生成广泛的解空间，随后通过最大熵引导策略优化 (RL) 强化正确信号。总训练成本仅为 7,800 美元，VibeThinker-1.5B 在推理能力上优于闭源模型如 Magistral Medium 和 Claude Opus 4，并与开源模型 GPT OSS-20B Medium 表现相当。值得注意的是，它在三个数学基准测试中超越了参数规模大 400 倍的 DeepSeek R1：AIME24 (80.3 对 79.8)、AIME25 (74.4 对 70.0) 和 HMMT25 (50.4 对 41.7)。这相对于其基础模型（得分分别为 6.7、4.3 和 0.6）是显著提升。在 LiveCodeBench V6 上，其得分为 51.1，超过 Magistral Medium 的 50.3 及其基础模型的 0.0。这些结果表明，小模型能够实现与大模型相媲美的推理能力，大幅降低训练和推理成本，从而推动先进 AI 研究的普及。

HaluMem: Evaluating Hallucinations in Memory Systems of Agents
HaluMem：评估智能体记忆系统中的幻觉
记忆系统是实现大语言模型（LLM）和AI智能体等人工智能系统长期学习与持续交互的关键组件。然而在记忆存储和检索过程中，这些系统常出现记忆幻觉现象，包括虚构、错误、冲突和遗漏等问题。现有对记忆幻觉的评估主要采用端到端问答形式，难以准确定位幻觉在记忆系统内部产生的具体操作环节。为此，我们提出记忆幻觉基准（HaluMem），这是首个专为记忆系统设计的操作级幻觉评估基准。HaluMem定义了记忆提取、记忆更新和记忆问答三项评估任务，全面揭示交互过程中不同操作阶段的幻觉行为。为支持评估，我们构建了以用户为中心的多轮人机交互数据集HaluMem-Medium和HaluMem-Long，两者均包含约1.5万记忆点和3500个多类型问题。每个用户的平均对话轮数分别达到1500轮和2600轮，上下文长度超过100万token（Token），可评估不同上下文规模与任务复杂度下的幻觉现象。基于HaluMem的实证研究表明，现有记忆系统在提取和更新阶段容易产生并积累幻觉，进而将错误传播至问答阶段。未来研究应致力于开发具有可解释性的受约束记忆操作机制，系统性地抑制幻觉并提升记忆可靠性。

One Small Step in Latent, One Giant Leap for Pixels: Fast Latent Upscale Adapter for Your Diffusion Models
潜在空间一小步，像素维度大跨越：扩散模型快速潜在上采样适配器
扩散模型难以突破其训练分辨率的限制：直接进行高分辨率采样速度缓慢且计算成本高昂，而后处理的图像超分辨率（ISR）方法需在解码后执行操作，不仅会引入伪影，还会增加额外延迟。本文提出潜在上采样适配器（LUA），该轻量模块可在最终VAE解码步骤之前，直接在生成器的潜在编码上执行超分辨率。LUA以即插即用式组件形式集成，无需修改基础模型结构或增加额外扩散阶段，仅需在潜在空间执行单次前向传播即可实现高分辨率合成。其采用共享式Swin架构骨干网络配合多尺度像素重组头，支持2倍与4倍上采样因子，同时保持与图像空间超分辨率基准的兼容性——在达到相近感知质量的前提下，将解码与上采样时间降低近3倍（从512像素生成1024像素仅需增加0.42秒，而使用相同SwinIR架构的像素空间超分辨率需1.87秒）。此外，LUA在不同VAE的潜在空间均展现出卓越的泛化能力，无需针对每个新解码器重新训练即可快速部署。大量实验表明，LUA在保真度方面可媲美原生高分辨率生成，同时为现代扩散流程中的可扩展高保真图像合成提供了实用高效的解决方案。

TiDAR: Think in Diffusion, Talk in Autoregression
TiDAR: 扩散思考，自回归交谈
扩散语言模型具备快速并行生成能力，而自回归 (AR) 模型因其因果结构与语言建模天然契合，通常在生成质量上更优。这引出一个核心问题：能否在实现高吞吐量、更高 GPU 利用率的同时，达到 AR 级别的质量？现有方法均未能有效平衡这两方面：要么采用较弱模型进行顺序草稿生成（推测解码）以优先保障 AR 特性，导致草稿效率低下；要么为扩散模型引入类 AR 的左到右解码逻辑，仍面临质量下降问题且丧失并行潜力。我们提出 TiDAR——一种序列级混合架构，通过专门设计的结构化注意力掩码，在单次前向传播中实现扩散式 token 草稿生成（思考）与自回归最终输出采样（交谈）。该设计充分利用 GPU 闲置计算资源，在草稿生成与验证能力间取得优异平衡。此外，TiDAR 作为独立模型具备低开销的部署友好特性。我们在 1.5B 和 8B 规模下，针对生成与似然任务对 TiDAR、AR 模型、推测解码及扩散变体进行广泛评估。凭借并行草稿生成与采样机制以及精确 KV 缓存支持，TiDAR 在吞吐量上超越推测解码，在效率与质量方面均优于 Dream、Llada 等扩散模型。最显著的是，TiDAR 成为首个在保持每秒生成 4.71-5.91 倍更多 token 的同时，完全弥合与 AR 模型质量差距的架构。

IterResearch: Rethinking Long-Horizon Agents via Markovian State Reconstruction
IterResearch：通过马尔可夫状态重构重新思考长视野智能体
深度研究智能体的最新进展表明，通过对外部信息源进行动态推理，有望实现自主知识构建。然而，现有方法采用单上下文范式，将所有信息累积在持续扩展的上下文窗口中，导致上下文拥塞和噪声干扰，从而限制了其在长视野任务中的效能。我们提出 IterResearch，一种新颖的迭代式深度研究范式，将长视野研究重新定义为具有策略性工作区重构的马尔可夫决策过程。该方法通过维护动态演进的报告作为记忆体，并定期整合关键见解，可在任意探索深度下保持稳定的推理能力。我们还开发了效率感知策略优化 (EAPO)，这是一个基于几何奖励衰减机制激励高效探索的强化学习框架，并通过自适应降采样实现稳定的分布式训练。大量实验表明，IterResearch 在六个基准测试中相较现有开源智能体平均提升 14.5 个百分点，显著缩小了与尖端专有系统的差距。值得注意的是，该范式展现出前所未有的交互扩展能力，支持多达 2048 次交互且性能大幅提升（从 3.5% 增至 42.5%），同时作为有效的提示策略，在长视野任务中较 ReAct 将尖端模型性能提升最高达 19.2 个百分点。这些成果确立了 IterResearch 作为长视野推理的多功能解决方案，既可作为训练完备的智能体独立运行，也可作为尖端模型的提示范式使用。

PAN: A World Model for General, Interactable, and Long-Horizon World Simulation
PAN：通用、可交互与长视野的世界模拟模型
世界模型使智能体能够想象、预测并推理世界如何随其动作演变，从而进行规划与决策。尽管当前视频生成模型可生成逼真视觉序列，但它们多采用从提示到完整视频的生成模式，缺乏因果控制、交互能力以及目标导向推理所需的长期一致性。而现有世界建模方法常局限于特定领域（如物理、游戏或三维场景动态），深度不足且可控性有限，难以泛化至多样化环境与交互形式。本文提出PAN，一种通用、可交互且支持长视野的世界模型，它基于历史状态与自然语言动作，通过高质量视频模拟预测未来世界状态。PAN采用生成式潜在预测（GLP）架构：其自回归潜在动态主干基于大语言模型（LLM），将模拟锚定于广泛文本知识，并支持语言指定动作的条件控制；视频扩散解码器则重建感知细节丰富且时序一致的视觉观测。该架构实现了潜在空间推理（想象）与可实现世界动态（现实）的统一。通过在大规模跨领域视频-动作对上进行训练，PAN支持开放域的动作条件模拟，并保持连贯的长期动态。大量实验表明，相较于其他视频生成器与世界模型，PAN在动作条件世界模拟、长视野预测及模拟推理任务中均表现优异，为构建通用世界模型迈出关键一步——这类模型能通过对未来状态的预测模拟支持推理与行动决策。

MADD: Multi-Agent Drug Discovery Orchestra
MADD：多智能体药物发现协奏曲
苗头化合物识别是早期药物发现的核心挑战，传统方法需耗费大量实验资源。人工智能的最新进展，特别是大语言模型 (LLMs)，催生了可降低成本和提升效率的虚拟筛选方法。然而，这些工具日益复杂，限制了湿实验研究人员的实际使用。多智能体系统通过融合 LLMs 的可解释性与专业模型及工具的精确性，提供了颇具前景的解决方案。本研究提出 MADD——一个能够根据自然语言查询构建并执行定制化苗头化合物识别流程的多智能体系统。MADD 部署四个协同工作的智能体，分别处理从头化合物生成与筛选中的关键子任务。我们在七个药物发现案例中评估 MADD，证明其性能优于现有基于 LLM 的解决方案。借助 MADD，我们率先将 AI 驱动的药物设计应用于五个生物靶标，并公开了已识别的苗头分子。最后，我们建立了包含三百余万种化合物的查询-分子对与对接评分新基准，以推动药物设计迈向智能体主导的未来。

Too Good to be Bad: On the Failure of LLMs to Role-Play Villains
过于良善难成恶：大语言模型在反派角色扮演中的失败
大语言模型（LLMs）正日益承担创造性生成任务，包括模拟虚构角色。然而，模型在刻画非亲社会或敌对型角色方面的能力仍鲜有研究。我们假设，现代大语言模型的安全对齐机制与逼真扮演道德模糊或反派角色的任务之间存在根本性冲突。为探究此问题，我们提出了道德角色扮演基准（Moral RolePlay benchmark），该新数据集包含四级道德倾向量表和一个平衡测试集，用于严格评估。我们要求前沿大语言模型扮演从道德楷模到纯粹恶棍的各类角色。大规模评估结果表明，随着角色道德水平的降低，角色扮演的逼真度呈现稳定且单调的下降趋势。模型在与安全原则直接冲突的特质上表现最差，如“欺诈性”和“操纵性”，往往以浅层的攻击性替代复杂的恶意刻画。此外，我们发现通用聊天机器人能力无法有效预测反派扮演水平，高度优化安全的模型表现尤为逊色。本研究首次系统性地揭示了这一关键局限，突显了模型安全性与创造性真实度之间的核心矛盾。所提出的基准和结论为开发更精细、情境感知的对齐方法奠定了基础。

Time-to-Move: Training-Free Motion Controlled Video Generation via Dual-Clock Denoising
Time-to-Move：通过双时钟去噪实现免训练的运动控制视频生成
基于扩散模型的视频生成技术能够合成逼真视频，但现有基于图像和文本的条件控制方法无法实现精确的运动控制。以往的运动条件合成方法通常需要对特定模型进行微调，计算成本高昂且适用性受限。本文提出 Time-to-Move (TTM) ，一种免训练、即插即用 (plug-and-play) 的框架，通过图像到视频 (I2V) 扩散模型实现运动与外观可控的视频生成。我们的核心思路是利用通过用户友好操作（如剪切-拖拽 (cut-and-drag) 或基于深度的重投影 (depth-based reprojection)）获得的粗略参考动画。受 SDEdit 利用粗略布局线索 (coarse layout cues) 进行图像编辑的启发，我们将这些粗略动画视为运动线索，并将该机制扩展至视频领域。我们通过图像条件保持外观一致性，并引入双时钟去噪 (dual-clock denoising) —— 一种区域依赖策略，在运动指定区域强制执行严格对齐，同时在其余区域保持灵活性，从而在用户意图忠实度与自然运动动态之间取得平衡。这种对采样过程的轻量级修改无需额外训练或运行时开销，且兼容任何骨干网络。在物体运动和相机运动的基准测试上进行的大量实验表明，TTM 在真实感与运动控制精度方面达到或超越了现有基于训练的基线方法。此外，TTM 还具备独特优势：通过像素级条件控制实现精确的外观调控，突破了纯文本提示的限制。欢迎访问我们的项目页面查看视频示例和代码：time-to-move.github.io/。

DRIVE: Data Curation Best Practices for Reinforcement Learning with Verifiable Reward in Competitive Code Generation
DRIVE: 竞争性代码生成中带可验证奖励的强化学习数据管理最佳实践
近期推理优先模型（如 OpenAI o1、DeepSeek R1）重新激发了对 RLVR 的兴趣。然而，相关进展主要集中在数学领域（如 AIME），竞争性编程代码生成方向探索不足，且数据管理受到的关注远少于 RL 算法设计。本研究探讨如何构建 RLVR 数据集（即 RL 提示），并提出在竞争性编程代码生成中实现强劲性能的实用训练技术。我们的流程始于从强开源模型蒸馏得到的监督微调（SFT），并辅以通用型与推理密集型数据进行增强。随后，强化学习采用包含可执行测试用例驱动奖励的两阶段流程：首先，在均匀分布的大规模竞争性编程问题集上，使用组相对策略优化（GRPO）进行训练，每个提示执行 8 次 rollout，并设置较短响应生成窗口（如 SFT 阶段 32k，本阶段 24k）以扩展熵并减少重复与截断问题；其次，执行 \textbf{Pre-GRPO} 阶段：在小型高质量挑战性问题集上，以每个提示 64 次 rollout 的大预算进行更新，采用硬焦点课程策略持续保留训练全程中最困难的实例。我们在 Qwen2.5-32B 上实现该方法，并在 LeetCode 和 Codeforces 周赛中进行评估以避免数据泄露。最终模型在同等规模模型中达到最先进性能，与 DeepSeek v3.1、Doubao-1.5-Thinking 等领先系统表现相当。我们还分析了缩放趋势，在内部大规模混合专家（MoE）模型上观察到显著的 RL 缩放效应。本研究提炼出竞争性编程代码生成中 RLVR 数据管理、熵扩展与课程设计的简洁最佳实践。

Visual Spatial Tuning
视觉空间调优
从视觉输入中捕获空间关系是实现人类水平通用智能的关键基础。先前研究多通过引入额外专家编码器来增强视觉语言模型 (VLMs) 的空间感知能力，但这不仅增加了计算开销，还往往损害模型的通用性能。为在通用架构中有效提升空间能力，我们提出视觉空间调优 (VST) 这一综合框架，旨在系统培养 VLMs 从空间感知到推理的类人视觉空间能力。我们首先通过构建大规模数据集 VST-P 来强化空间感知，该数据集包含 410 万样本，覆盖单视图、多图像和视频三大场景下的 19 类空间任务。继而推出 VST-R 精选数据集（含 13.5 万样本），专门训练模型进行空间推理。我们采用渐进式训练策略：先通过监督微调建立空间知识基础，再通过强化学习进阶优化空间推理能力。在保持通用能力不受影响的前提下，VST 在多个空间基准测试中均达到最先进水平，如在 MMSI-Bench 上获得 34.8% 的准确率，在 VSIBench 上达到 61.2%。实验表明，所提出的空间调优范式能显著增强视觉-语言-行动模型，为推动具身智能发展奠定基础。

## 每周AI论文速递（251117-251121）

Kandinsky 5.0: A Family of Foundation Models for Image and Video Generation
Kandinsky 5.0：图像与视频生成基础模型系列
本报告介绍了 Kandinsky 5.0，这是一个面向高分辨率图像和 10 秒视频合成的尖端基础模型系列。该框架包含三大核心模型：Kandinsky 5.0 Image Lite（6B 参数的图像生成模型系列）、Kandinsky 5.0 Video Lite（轻量级 2B 参数文本到视频及图像到视频模型）以及 Kandinsky 5.0 Video Pro（19B 参数模型，具备卓越视频生成质量）。我们全面概述了多阶段训练流程中的数据管理生命周期（包括数据收集、处理、过滤与聚类），该流程涉及大规模预训练，并融合了自监督微调 (SFT) 和强化学习 (RL) 后训练等质量增强技术。同时，我们提出了新颖的架构、训练及推理优化方法，使 Kandinsky 5.0 能够实现高速生成，并在多种任务中达到领先性能（经人工评估验证）。作为公开可用的大规模生成框架，Kandinsky 5.0 充分发挥预训练及后续阶段的潜力，可广泛应用于各类生成场景。我们期望通过本报告及开源代码与训练检查点的发布，显著推动研究社区在高质量生成模型开发与普及方面的进展。

MiroThinker: Pushing the Performance Boundaries of Open-Source Research Agents via Model, Context, and Interactive Scaling
MiroThinker：通过模型、上下文与交互缩放突破开源研究智能体的性能极限
我们推出 MiroThinker v1.0，这是一个旨在提升工具增强推理与信息检索能力的开源研究智能体。与先前仅扩展模型规模或上下文长度的智能体不同，MiroThinker 在模型层面探索交互缩放，系统性地训练模型处理更深层、更频繁的智能体-环境交互，将其作为性能提升的第三维度。相较于孤立运行且易因长推理链导致性能下降的 LLM 测试阶段缩放，交互缩放通过环境反馈与外部信息获取来修正错误并优化行动路径。通过强化学习，该模型实现了高效交互缩放：在 256K 上下文窗口下，单个任务可执行多达 600 次工具调用，支持持续的多轮次推理与复杂现实研究工作流。在 GAIA、HLE、BrowseComp 和 BrowseComp-ZH 四个代表性基准测试中，72B 参数版本分别达到 81.9%、37.7%、47.1% 和 55.6% 的准确率，超越此前开源智能体，并逼近 GPT-5-high 等商业竞品。我们的分析表明，MiroThinker 始终受益于交互缩放：随着模型参与智能体-环境交互的深度与频率增加，研究性能呈现可预测的提升，证明交互深度具有与模型规模和上下文长度相似的缩放特性。这些发现确立了交互缩放作为构建下一代开源研究智能体的第三关键维度，与模型能力和上下文窗口形成互补。

P1: Mastering Physics Olympiads with Reinforcement Learning
P1: 基于强化学习的物理奥林匹克竞赛精通
大语言模型 (LLMs) 的最新进展已将研究前沿从谜题求解推进至科学推理——即处理那些答案必须与自然现象一致、而非仅符合评分标准的问题。物理学是这一转变的关键试金石，它以基本方式将符号与现实绑定，成为大多数现代技术的基石。在本工作中，我们通过开发具备卓越物理推理能力的大语言模型，成功推动了物理研究进展，尤其擅长解决奥林匹克级别的物理问题。我们推出了 P1 系列，这是一个完全基于强化学习 (RL) 训练的开源物理推理模型家族。其中，P1-235B-A22B 是首个在最新国际物理奥林匹克竞赛 (IPhO 2025) 中达到金牌水平的开源模型，并在 2024/2025 年度的 13 项国际/区域物理竞赛中斩获 12 枚金牌。P1-30B-A3B 同样在 IPhO 2025 上超越几乎所有其他开源模型，获得银牌。进一步结合 AI 智能体框架 PhysicsMinions，P1-235B-A22B+PhysicsMinions 在 IPhO 2025 中取得总排名第一，并在 13 项物理竞赛中获最高平均分。除物理领域外，P1 模型在数学、编程等其他推理任务上也表现优异，彰显了该系列的强大泛化能力。

Souper-Model: How Simple Arithmetic Unlocks State-of-the-Art LLM Performance
Souper-Model: 简单算术如何实现最先进的大语言模型性能
大语言模型 (LLMs) 已在众多领域展现出卓越能力，但其训练过程仍需要大量资源和时间，涉及巨大的计算开销以及对训练流程的精细管理。模型汤化 (Model souping) ——即平均相同架构的多个模型权重的实践——已成为一种有前景的训练前和训练后技术，能够在不进行昂贵重新训练的情况下提升模型性能。本文提出类别专家汤 (SoCE)，一种系统性的模型汤化方法，该方法利用基准测试的构成来识别最优模型候选，并采用非均匀权重平均以最大化性能。与先前基于均匀平均的方法不同，我们的方法基于一个关键观察：基准测试的不同类别在模型性能上往往呈现低相关性。SoCE 为每个弱相关性类别集群识别“专家”模型，并通过优化的权重平均（而非均匀权重）进行组合。实验表明，该方法在多个领域（包括多语言能力、工具调用和数学推理）均提升了性能与鲁棒性，并在伯克利函数调用排行榜上取得了最先进的结果。

VIDEOP2R: Video Understanding from Perception to Reasoning
VIDEOP2R：从感知到推理的视频理解
强化微调 (RFT) 是一种包含监督微调 (SFT) 和强化学习 (RL) 的两阶段框架，已在提升大语言模型 (LLMs) 推理能力方面展现出良好效果。然而，将其扩展至大型视频语言模型 (LVLMs) 仍面临挑战。本文提出 VideoP2R，一种过程感知的视频 RFT 框架，通过将感知与推理建模为独立过程来增强视频推理能力。在 SFT 阶段，我们构建了三步流程，生成高质量的过程感知思维链数据集 VideoP2R-CoT-162K，专门用于感知与推理任务。在 RL 阶段，我们引入了过程感知组相对策略优化 (PA-GRPO) 算法，该算法为感知和推理过程分别分配奖励。实验表明，VideoP2R 在七个视频推理与理解基准中的六个上达到了最先进水平。消融研究进一步验证了过程感知建模与 PA-GRPO 的有效性，并证明模型感知输出足以支撑下游推理任务。

Uni-MoE-2.0-Omni: Scaling Language-Centric Omnimodal Large Model with Advanced MoE, Training and Data
Uni-MoE-2.0-Omni: 基于先进MoE、训练与数据的以语言为中心的全模态大模型规模化
我们推出荔枝 (Lychee) 系列中的 Uni-MoE 2.0。作为完全开源的全模态大模型 (Omnimodal Large Model, OLM) ，它在以语言为中心的多模态理解、推理和生成方面显著推进了荔枝 Uni-MoE 系列。基于 Qwen2.5-7B 的稠密架构 (dense architecture) ，我们通过三大核心创新从头构建了 Uni-MoE-2.0-Omni: 动态能力专家混合 (Mixture-of-Experts, MoE) 设计、采用迭代增强策略的渐进式训练方法，以及精心筛选的多模态数据匹配技术。该模型具备全模态理解能力，并能生成图像、文本和语音。在架构上，新型 MoE 框架通过共享专家、路由专家和空置专家平衡了 10 种跨模态输入的计算效率与能力，而全模态 3D RoPE (Rotary Position Embedding) 确保了自注意力层中的时空跨模态对齐。训练方面，在跨模态预训练后，我们采用渐进式监督微调策略激活模态特定专家，并通过平衡数据组合与迭代 GSPO-DPO 方法增强训练，以稳定强化学习 (Reinforcement Learning, RL) 过程并提升推理能力。数据层面，基础模型在约 750 亿 token 的开源多模态数据上训练，配备专用语音和图像生成 token，使其能够基于语言线索条件化输出来学习生成任务。在 85 个基准测试上的广泛评估表明，本模型在领先全模态大模型中达到最先进水平 (State-of-the-Art, SOTA) 或极具竞争力性能，在 76 个基准中的超 50 项上超越使用 1.2 万亿 token 训练的 Qwen2.5-Omni。核心优势包括视频理解 (8 项基准平均提升 7%) 、全模态理解 (4 项基准平均提升 7%) 和视听推理 (平均提升 4%) 。同时，它在长语音处理上取得进展 (词错误率, Word Error Rate, WER 降低 4.2%) ，并在底层图像处理与可控生成的 5 项指标中领先。

Think-at-Hard: Selective Latent Iterations to Improve Reasoning Language Models
Think-at-Hard：通过选择性隐式迭代提升推理语言模型性能
提升大语言模型 (LLMs) 的推理能力，特别是在参数约束条件下，对实际应用至关重要。现有研究提出了循环 Transformer 架构，为每个 Token 分配固定次数的额外迭代以提升生成质量。在完成首次标准前向传播后，该方法并非直接输出文本，而是将最后一层隐藏状态反馈至输入层进行额外迭代，以优化 Token 预测结果。然而我们发现存在隐式过度推理现象：首次传播后已预测正确的简单 Token，有时会在后续迭代中被错误修正。为此，我们提出 Think-at-Hard (TaH) 方法，通过动态隐式迭代机制，仅对困难 Token 进行深度迭代。该方法采用轻量级神经决策模块，仅在标准前向传播后可能预测错误的 Token 处触发隐式迭代。在隐式迭代过程中，低秩适应 (LoRA) 模块将 LLM 的目标从通用下一 Token 预测转向专注于困难 Token 的优化。我们还引入了双重因果注意力机制，将注意力范围从 Token 序列维度扩展至迭代深度维度。该设计在保持完全序列并行性的同时，实现了跨迭代的信息流动。实验表明，TaH 在五个高难度基准测试中显著提升 LLM 推理性能，且保持参数量不变。与对所有输出 Token 进行两次迭代的基线方法相比，TaH 在免除 94% Token 二次迭代的同时，准确率提升达 8.1-11.3%。相较于使用相同数据微调的强基线 Qwen3 单次迭代模型，准确率提升达 4.0-5.0%。当仅引入 LoRA 和迭代决策模块带来的不足 3% 额外参数时，准确率增益分别进一步提升至 8.5-12.6% 和 5.3-5.4%。代码已开源：github.com/thu-nics/Ta…

DoPE: Denoising Rotary Position Embedding
DoPE：旋转位置嵌入去噪方法
Transformer 模型中的旋转位置嵌入 (RoPE) 存在固有局限性，会削弱长度外推性能。我们将含位置编码的注意力图重新诠释为带噪声的特征图，并提出去噪位置编码 (DoPE)，这是一种基于截断矩阵熵的无训练方法，用于识别特征图中的异常频带。利用特征图的噪声特性，我们进一步采用无参数高斯分布对其进行重参数化，以实现鲁棒的外推。本方法从理论上揭示了注意力下沉现象的成因及其与截断矩阵熵的关联。在“大海捞针”和多样本上下文学习任务上的实验表明，DoPE 在长上下文（最高 64K token）中显著提升了检索精度与推理稳定性。结果表明，位置嵌入的去噪策略有效抑制了注意力下沉现象，恢复了均衡的注意力分布，为改进长度泛化提供了一种简洁而高效的解决方案。项目页面详见：The-physical-picture-of-LLMs.github.io
Reasoning via Video: The First Evaluation of Video Models' Reasoning Abilities through Maze-Solving Tasks
视频推理：通过迷宫求解任务首次评估视频模型的推理能力
视频模型在生成具有连贯运动动态的高保真视频方面取得了显著成功。类似于语言建模从文本生成发展到基于文本的推理，视频模型的进步促使我们思考：视频模型能否通过视频生成进行推理？与离散的文本语料相比，视频以明确的空间布局和时间连续性为基础，为空间推理提供了理想载体。在本工作中，我们探索了视频推理范式，并推出VR-Bench——一个系统评估视频模型推理能力的综合基准。该基准基于需要空间规划与多步推理的迷宫求解任务，包含7,920个过程生成视频，涵盖五种迷宫类型及多样视觉风格。实证分析表明，监督微调 (SFT) 能有效激发视频模型的推理能力。视频模型在推理过程中展现出更强的空间感知能力，其表现优于主流视觉语言模型 (VLM) ，且能适应不同场景、任务及复杂度级别。我们还发现了测试时扩展效应：推理阶段采用多样化采样可使推理可靠性提升10–20%。这些发现凸显了视频推理在空间推理任务中的独特潜力与可扩展性。

AraLingBench A Human-Annotated Benchmark for Evaluating Arabic Linguistic Capabilities of Large Language Models
AraLingBench：评估大语言模型阿拉伯语语言能力的人工标注基准
我们提出 AraLingBench：一个完全人工标注的基准，用于评估大语言模型 (LLMs) 的阿拉伯语语言能力。该基准涵盖五个核心类别：语法、词法、拼写、阅读理解和句法，通过 150 道专家设计的多项选择题直接评估结构性语言理解。对 35 个阿拉伯语和双语大语言模型的评估表明，当前模型虽然表现出较强的表面熟练度，但在深层语法和句法推理方面仍存在困难。AraLingBench 揭示了基于知识的基准测试高分与真正语言掌握能力之间的持久差距，证明许多模型的成功依赖于记忆或模式识别而非真正的理解能力。通过分离和测量基础语言技能，AraLingBench 为开发阿拉伯语大语言模型提供了诊断框架。完整评估代码已在 GitHub 平台开源发布。

Part-X-MLLM: Part-aware 3D Multimodal Large Language Model
Part-X-MLLM：部件感知的3D多模态大语言模型
我们提出了Part-X-MLLM，一种原生3D多模态大语言模型，通过将多样化的3D任务形式化为结构化、可执行语法中的程序，实现了统一处理。给定RGB点云和自然语言提示，模型以自回归方式生成单一、连贯的Token序列，其中包含部件级边界框、语义描述和编辑命令。这一结构化输出作为通用接口，可驱动下游几何感知模块执行部件级生成和编辑。通过将符号规划与几何生成解耦，本方法支持通过单一语言原生前端控制任何兼容的几何引擎。我们预训练了双编码器架构来分离结构与语义，并在大规模部件中心数据集上对模型进行指令调优。实验表明，该模型能高效生成高质量结构化规划，通过统一接口在接地问答、组合生成和局部编辑任务中实现了最先进的性能。项目页面：chunshi.wang/Part-X-MLLM…

Agent0: Unleashing Self-Evolving Agents from Zero Data via Tool-Integrated Reasoning
Agent0：通过工具集成推理实现零数据下的自我进化智能体
基于大型语言模型 (LLM) 的智能体通常采用强化学习 (RL) 进行训练，但其发展受限于对人工标注数据的依赖，这不仅制约了可扩展性，还将人工智能的能力局限于人类知识范畴。现有自我进化框架虽提供了替代路径，却常受限于模型固有能力与单轮交互机制，难以发展包含工具使用或动态推理的复杂训练课程。本文提出 Agent0——一个完全自主的框架，通过多步协同进化与无缝工具集成，无需外部数据即可培育高性能智能体。Agent0 在源自同一基础 LLM 的两个智能体间建立共生竞争机制：课程智能体负责设计难度递增的前沿任务，执行智能体则学习解决这些任务。通过集成外部工具增强执行智能体的解题能力，这种能力提升反过来驱动课程智能体构建更具复杂性且具备工具感知的新任务。在此迭代过程中，Agent0 形成自我强化的闭环，持续生成高质量训练课程。实验结果表明，Agent0 显著提升了推理能力，使 Qwen3-8B-Base 模型在数学推理基准上的性能提升 18%，在通用推理基准上提升 24%。代码发布于 github.com/aiming-lab/…

MMaDA-Parallel: Multimodal Large Diffusion Language Models for Thinking-Aware Editing and Generation
MMaDA-并行：用于思维感知编辑与生成的多模态大扩散语言模型
尽管思维感知生成 (thinking-aware generation) 旨在提升复杂任务性能，但我们识别出一个关键失效模式：现有顺序自回归方法会因错误传播而反而导致性能下降。为系统性地分析该问题，我们提出了 ParaBench，这是一个新基准，用于评估文本和图像输出模态。基于 ParaBench 的分析表明，性能下降与生成推理和最终图像之间的对齐不佳高度相关。为解决此问题，我们提出并行多模态扩散框架 MMaDA-并行，该框架能在整个去噪轨迹中实现文本与图像间的连续双向交互。MMaDA-并行采用监督微调进行训练，并通过并行强化学习 (ParaRL) 进一步优化；ParaRL 是一种新策略，在轨迹上施加语义奖励以强化跨模态一致性。实验验证表明，我们的模型显著改善了跨模态对齐和语义一致性，在 ParaBench 上相比最先进模型 Bagel 实现了输出对齐 (Output Alignment) 6.9% 的提升，从而为思维感知图像合成建立了更鲁棒的范式。代码已开源：github.com/tyfeld/MMaD…

SAM 3D: 3Dfy Anything in Images
SAM 3D：图像中任意物体的三维重建
我们提出SAM 3D——一个基于视觉的三维物体重建生成模型，能够从单张图像预测几何结构、纹理贴图和空间布局。该模型在自然图像中表现卓越，尤其适用于存在遮挡和场景杂乱的场景，其中上下文提供的视觉识别线索发挥着更重要的作用。我们通过人机协同标注流程实现这一目标，该流程可标注物体形状、纹理和位姿，以前所未有的规模提供基于视觉的三维重建数据。我们采用现代化的多阶段训练框架，结合合成预训练与真实世界对齐，突破了三维数据的"数据壁垒"。与近期工作相比，我们取得了显著提升，在真实物体和场景的人类偏好测试中胜率至少达5:1。我们将公开代码与模型权重、在线演示平台，以及一个全新的真实场景三维物体重建基准测试集。

A Style is Worth One Code: Unlocking Code-to-Style Image Generation with Discrete Style Space
一种风格对应一个代码：利用离散风格空间实现代码到风格的图像生成
创新的视觉风格化是艺术创作的核心要素，但生成新颖且一致的视觉风格仍面临重大挑战。现有生成方法通常依赖冗长的文本提示、参考图像或参数高效微调来引导风格感知的图像生成，但往往难以保证风格一致性、创造力有限且风格表示复杂。本文通过引入代码到风格图像生成这一新任务，主张一种风格可由一个数值代码表征，该任务仅凭一个数值风格代码即可生成具有新颖、一致视觉风格的图像。目前，该领域主要由行业（如 Midjourney）主导探索，学术界尚无开源研究。为填补这一空白，我们提出了首个开源方法 CoTyle。具体而言，我们首先从图像集合中训练一个离散风格代码本，以提取风格嵌入。这些嵌入作为文本到图像扩散模型 (T2I-DM) 的条件，用于生成风格图像。随后，我们在离散风格嵌入上训练自回归风格生成器，建模其分布，从而能够合成新颖的风格嵌入。在推理阶段，数值风格代码通过风格生成器映射为唯一风格嵌入，该嵌入引导 T2I-DM 生成对应风格的图像。与现有方法相比，我们的方法具备无与伦比的简洁性和多样性，仅需极少输入即可解锁广阔的可复现风格空间。大量实验验证，CoTyle 能有效将数值代码转化为风格控制器，证实了一种风格确实对应一个代码。

GroupRank: A Groupwise Reranking Paradigm Driven by Reinforcement Learning
GroupRank：一种由强化学习驱动的分组重排序范式
大语言模型 (LLM) 已展现出作为重排序器的强大潜力，能够提升 RAG (Retrieval-Augmented Generation) 系统的整体性能。然而，现有重排序范式面临一个核心理论与实践困境：逐点 (Pointwise) 方法虽然简单灵活，但独立评估文档，容易陷入排名近视陷阱，忽略文档间相对重要性；而列表 (Listwise) 方法能感知全局排名上下文，却存在固有的列表刚性缺陷，导致处理大规模候选集时出现严重的可扩展性与灵活性问题。为解决这些挑战，我们提出分组 (Groupwise) 方法，一种新颖的重排序范式。该方法将查询与一组候选文档共同输入模型，通过组内比较为每个文档分配个体相关性分数。这一设计既保留了逐点方法的灵活性，又实现了列表方法的比较能力。我们进一步采用 GRPO (Groupwise Reinforcement Learning with Policy Optimization) 进行模型训练，并配备异构奖励函数，该函数整合了排名指标与旨在对齐跨组分数分布的分布奖励。为克服高质量标注数据稀缺的瓶颈，我们提出一种创新流程，用于合成高质量检索与排名数据。生成的数据不仅可用于训练重排序器，还能用于训练检索器。大量实验验证了本方法的有效性。在两个推理密集型检索基准 BRIGHT 和 R2MED 上的测试结果表明了其优越性能。

V-ReasonBench: Toward Unified Reasoning Benchmark Suite for Video Generation Models
V-ReasonBench：面向视频生成模型的统一推理基准套件
生成式视频模型（如Veo-3）的最新进展展现了惊人的零样本推理能力，这催生了对系统化、可靠评估方法日益增长的需求。我们推出V-ReasonBench，这是一个旨在从四个关键维度评估视频推理能力的基准：结构化问题解决、空间认知、基于模式的推理和物理动力学。该基准基于合成与真实世界图像序列构建，提供了一系列多样化、答案可验证的任务，这些任务具有可重现性、可扩展性且无歧义。对六个前沿视频模型的评估显示出明显的维度间差异，在结构化、空间、基于模式和物理推理方面存在显著性能波动。我们进一步将视频模型与强图像模型进行对比，分析常见的幻觉（hallucination）现象，并探究视频持续时间如何影响帧链（Chain-of-Frames）推理。总体而言，V-ReasonBench提供了一个统一、可重现的框架来衡量视频推理能力，旨在支持开发具备更可靠、符合人类认知的推理技能的模型。

What Does It Take to Be a Good AI Research Agent? Studying the Role of Ideation Diversity
优秀 AI 研究智能体的关键要素？探讨构思多样性的作用
AI 研究智能体有望通过自动化机器学习模型的设计、实现与训练来加速科学进展。然而该领域尚处发展初期，决定智能体行为路径成败的关键因素仍未明晰。本文探究了构思多样性对智能体性能的影响机制。首先，我们在 MLE-bench（评估 AI 研究智能体的知名基准测试）上分析不同模型与智能体框架的行为轨迹，发现不同配置会产生不同程度的构思多样性，且性能更优的智能体通常表现出更高的构思多样性。进一步通过受控实验调整构思多样性水平，证实提升多样性可显著增强智能体性能。最后，我们超越 MLE-bench 基于奖牌评分的标准指标，通过多维度评估验证了研究结论在不同性能度量下的普适性。

First Frame Is the Place to Go for Video Content Customization
第一帧：视频内容定制的关键入口
第一帧在视频生成模型中扮演着什么角色？传统观点认为，它仅是视频时空序列的起始点，作为后续动画生成的基础。在本研究中，我们提出了一个根本性的新视角：视频模型隐式地将第一帧作为概念记忆缓冲区，用于存储视觉实体并在生成过程中重复利用。基于这一发现，我们证明仅需20-50个训练样本，无需修改模型架构或进行大规模微调，即可在多种场景下实现鲁棒且具备强泛化能力的视频内容定制。这揭示了视频生成模型在基于参考视频的定制任务中一项强大而长期被忽视的潜力。

PhysX-Anything: Simulation-Ready Physical 3D Assets from Single Image
PhysX-Anything：从单张图像生成可直接仿真的物理属性3D资产
3D建模正从静态视觉表示转向具备物理属性的可关节化资产，这类资产可直接用于仿真与交互。然而，现有大多数3D生成方法忽略了关键的物理属性与关节结构，限制了其在具身AI中的应用。为弥补这一不足，我们提出PhysX-Anything——首个可直接仿真的物理3D生成框架，仅需输入单张真实场景图像，即可生成具有显式几何结构、关节系统和物理属性的高质量可仿真3D资产。具体而言，我们开发了首个基于视觉语言模型 (VLM) 的物理3D生成模型，并提出新型3D表征方法，可高效对几何结构进行标记化处理。该方法将标记数量压缩至原数量的1/193，使得在标准VLM标记容量内即可实现显式几何学习，无需在微调阶段引入特殊标记，显著提升了生成质量。此外，针对现有物理3D数据集多样性不足的问题，我们构建了PhysX-Mobility数据集，将原有物理3D数据集的物体类别扩展2倍以上，包含2000余个常见真实物体并附有详尽的物理属性标注。在PhysX-Mobility与真实场景图像上的大量实验表明，PhysX-Anything具有卓越的生成性能与强泛化能力。在MuJoCo风格环境中开展的仿真实验进一步验证，本方法生成的资产可直接用于高接触频率的机器人策略学习。我们相信PhysX-Anything将有力推动下游应用发展，尤其在具身AI与物理仿真领域。

Step-Audio-R1 Technical Report
Step-Audio-R1 技术报告
近期推理模型通过扩展的思维链推理过程，在文本和视觉领域取得了显著成功。然而，音频语言模型中始终存在一个令人困惑的现象：它们在极少或无需推理的情况下表现更优，这引发了一个根本性问题——音频智能是否真能从深思熟虑的推理中受益？我们推出 Step-Audio-R1，这是首个成功在音频领域实现推理能力的音频推理模型。通过我们提出的基于模态的推理蒸馏 (MGRD) 框架，Step-Audio-R1 能够生成与音频相关的推理链，这些推理链真正扎根于声学特征，而非产生脱节的虚假推理。我们的模型展现出强大的音频推理能力，在涵盖语音、环境声音和音乐的综合音频理解与推理基准测试中，超越了 Gemini 2.5 Pro，并与最先进的 Gemini 3 Pro 性能相当。这些结果表明，当得到适当锚定时，推理是一种可跨模态迁移的能力，从而将扩展推理从劣势转化为音频智能的强大优势。通过成功构建首个音频推理模型，Step-Audio-R1 为开发真正跨所有感官模态进行深度思考的多模态推理系统开辟了新路径。

## 每周AI论文速递（251201-251205）

From Code Foundation Models to Agents and Applications: A Practical Guide to Code Intelligence
从代码基础模型到智能体与应用：代码智能实用指南
大语言模型 (LLMs) 从根本上改变了自动化软件开发，实现了将自然语言描述直接转换为功能代码，并通过诸如 GitHub Copilot (Microsoft)、Cursor (Anysphere)、Trae (ByteDance) 和 Claude Code (Anthropic) 等工具推动了商业应用。该领域已从基于规则的系统演进为基于 Transformer 的架构，在 HumanEval 等基准测试上的性能从个位数成功率提升至超过 95%。在本工作中，我们提供了一份关于代码大语言模型的全面综述与实用指南（包含一系列分析和探索性实验），系统性地审视了从数据管理到后训练的完整模型生命周期，涉及高级提示范式、代码预训练、监督微调、强化学习以及自主编码智能体。我们评估了通用大语言模型（GPT-4、Claude、LLaMA）与代码专用大语言模型（StarCoder、Code LLaMA、DeepSeek-Coder、QwenCoder）的代码能力，并批判性地探讨了相关技术、设计决策及其权衡。此外，我们阐明了学术研究（例如基准测试与任务）与实际部署（例如软件相关的代码任务）之间的差距，涵盖代码正确性、安全性、大型代码库的上下文感知以及与开发工作流的集成，并将有前景的研究方向与实际需求相关联。最后，我们通过一系列实验，对代码预训练、监督微调和强化学习进行了全面分析，内容涵盖缩放定律、框架选择、超参数敏感性、模型架构和数据集比较。

DeepSeek-V3.2: Pushing the Frontier of Open Large Language Models
DeepSeek-V3.2: 推动开源大语言模型的前沿
我们推出 DeepSeek-V3.2，这是一个将高效计算与卓越的推理及智能体性能融为一体的模型。DeepSeek-V3.2 的关键技术突破如下：(1) DeepSeek 稀疏注意力 (DSA)：我们引入了 DSA，这是一种高效的注意力机制，能在长上下文场景中显著降低计算复杂度，同时保持模型性能。(2) 可扩展的强化学习框架：通过采用稳健的强化学习协议并扩展后训练阶段的计算规模，DeepSeek-V3.2 的性能与 GPT-5 相当。值得注意的是，我们的高计算配置变体 DeepSeek-V3.2-Speciale 超越了 GPT-5，其推理能力与 Gemini-3.0-Pro 并驾齐驱，在 2025 年国际数学奥林匹克竞赛 (IMO) 和国际信息学奥林匹克竞赛 (IOI) 中均取得了金牌级别的成绩。(3) 大规模面向智能体的任务合成流水线：为了将推理能力融入工具使用场景，我们开发了一种新颖的合成流水线，能够系统性地大规模生成训练数据。该方法支持可扩展的智能体后训练，从而在复杂、交互式的环境中，显著提升了模型的泛化能力和遵循指令的鲁棒性。

LongVT: 通过原生工具调用实现“长视频思维”
LongVT: 通过原生工具调用实现“长视频思维”
大模态模型 (Large Multimodal Models, LMMs) 在结合文本思维链进行视频推理方面展现出巨大潜力。然而，它们仍易产生幻觉，尤其是在处理那些证据稀疏且时间分布分散的长视频时。受人类理解长视频方式（先全局概览，再细查相关片段）的启发，我们提出了 LongVT，一个端到端的智能体框架。该框架通过交错进行的“多模态工具调用思维链”，实现了“用长视频进行思考”。具体而言，我们将 LMMs 固有的时间定位能力作为一种原生视频裁剪工具，用于聚焦特定视频片段并重新采样更细粒度的视频帧。这种从全局到局部的推理循环会持续进行，直至答案能够基于检索到的视觉证据得到确认。针对长视频推理任务中细粒度问答 (QA) 数据稀缺的问题，我们构建并将发布一个名为 VideoSIAH 的数据套件，以支持模型的训练与评估。具体来说，我们的训练数据集包含：24.79 万个用于工具集成冷启动监督微调的样本、1600 个用于智能体强化学习的样本，以及 1.54 万个用于智能体强化微调的样本。我们的评估基准包含 1280 个 QA 对，这些数据通过一个半自动的数据流水线精心构建，并经过了人工验证。通过精心设计的三阶段训练策略和广泛的实证评估，LongVT 在四个具有挑战性的长视频理解与推理基准测试中，均持续超越现有的强基线模型。我们的代码、数据及模型检查点均已公开，地址为：github.com/EvolvingLMM…

Z-Image: An Efficient Image Generation Foundation Model with Single-Stream Diffusion Transformer
Z-Image: 基于单流扩散Transformer的高效图像生成基础模型
当前，高性能图像生成领域主要由专有系统主导，例如 Nano Banana Pro 和 Seedream 4.0。而领先的开源替代方案，如 Qwen-Image、Hunyuan-Image-3.0 和 FLUX.2，则普遍参数量庞大 (200亿至800亿)，导致其在消费级硬件上进行推理和微调都极不现实。为弥补这一空白，我们提出了 Z-Image，这是一个参数规模为 60亿 的高效基础生成模型。它基于可扩展单流扩散Transformer (Scalable Single-Stream Diffusion Transformer, S3-DiT) 架构构建，旨在挑战“不计成本堆叠规模”的行业范式。通过对整个模型生命周期进行系统性优化——从精心构建的数据基础设施到高效精简的训练方案——我们仅消耗了 31.4万 H800 GPU 小时 (约合 63万美元) 便完成了完整的训练流程。我们结合奖励后训练的少步蒸馏方案进一步得到了 Z-Image-Turbo，该版本不仅能在企业级 H800 GPU 上实现亚秒级推理延迟，还能兼容显存小于 16GB 的消费级硬件。此外，我们的全预训练范式也支持高效训练出 Z-Image-Edit，这是一个具备出色指令遵循能力的图像编辑模型。定性与定量实验均表明，我们的模型在多个维度上的性能均可比肩乃至超越领先的竞争对手。尤为突出的是，Z-Image 在生成逼真图像和渲染双语文本方面表现卓越，其效果足以媲美顶尖的商业模型。这证明了，即使大幅降低计算开销，同样能够实现最先进的性能。为促进可获取、低成本且性能领先的生成模型发展，我们已公开代码、模型权重并提供在线演示。

Live Avatar: 流式实时音频驱动的无限长度虚拟形象生成
Live Avatar: 流式实时音频驱动的无限长度虚拟形象生成
现有基于扩散模型的视频生成方法，从根本上受限于顺序计算和长时不一致性问题，制约了其在实时流式音频驱动虚拟形象合成中的实际采用。我们提出了 Live Avatar，一个算法-系统协同设计框架，能够利用一个 140 亿参数的扩散模型，实现高效、高保真且无限长度的虚拟形象生成。我们的方法引入了时间步强制流水线并行 (Timestep-forcing Pipeline Parallelism, TPP)，这是一种分布式推理范式，它跨多个 GPU 对去噪步骤进行流水线处理，从而有效打破自回归瓶颈，确保稳定、低延迟的实时流生成。为了进一步增强时间一致性，并缓解身份漂移和颜色伪影问题，我们提出了滚动锚定帧机制 (Rolling Sink Frame Mechanism, RSFM)，该机制通过利用缓存的参考图像动态重校准外观，以维持序列保真度。此外，我们采用自强制分布匹配蒸馏技术，在不牺牲视觉质量的前提下，实现了大规模模型的因果性、可流式化适配。Live Avatar 展现了最先进的性能，在 5 块 H800 GPU 上实现了 20 FPS 的端到端生成速度。据我们所知，这是首个在此参数量级上实现实用化、实时、高保真虚拟形象生成的工作。我们的研究为在工业级长视频合成应用中部署先进扩散模型确立了一种新范式。

DAComp: 全数据智能生命周期数据智能体基准测试
DAComp: 全数据智能生命周期数据智能体基准测试
现实中的企业数据智能工作流涵盖两大环节：一是将原始数据源转化为可供分析表格的数据工程，二是将这些表格转化为决策洞察的数据分析。为此，我们提出了DAComp基准，它包含210个任务，旨在模拟这些复杂的工作流。数据工程（DE）任务要求对工业级数据模式进行仓库层面的工程操作，包括从零开始设计和构建多阶段SQL管道，以及在需求演进时对现有系统进行改造。数据分析（DA）任务则提出开放式的业务问题，要求进行战略规划、通过迭代编码进行探索性分析、解读中间结果，并最终综合出可执行的建议。工程类任务采用基于执行的多指标评估体系进行评分。开放式任务则由一个经过实验验证的、可靠的LLM-judge进行评估，该评估器遵循一套分层且精心设计的评分标准。
我们的实验表明，即使是当前最先进的AI智能体在DAComp上也表现欠佳。数据工程任务的表现尤其低下，成功率不足20%，这暴露了在整体管道编排（而不仅仅是代码生成）方面存在关键瓶颈。数据分析任务的平均得分也低于40%，突显了智能体在开放式推理方面存在严重不足，并证明工程能力与分析能力是两种截然不同的技能。通过清晰地诊断这些局限，DAComp为开发真正适用于企业环境的、能力全面的自主数据智能体提供了一个严谨且贴近现实的测试平台。我们的数据与代码公开于 da-comp.github.io。

Qwen3-VL Technical Report
Qwen3-VL 技术报告
我们推出 Qwen3-VL，这是 Qwen 系列迄今为止能力最强的视觉语言模型 (Vision-Language Model)，在广泛的多模态基准测试中均取得了卓越性能。该模型原生支持高达 256K token 的交错多模态上下文，能够无缝融合文本、图像与视频输入。模型系列包含密集 (2B/4B/8B/32B) 与专家混合 (Mixture-of-Experts, MoE) (30B-A3B/235B-A22B) 两种架构变体，以满足不同场景下对延迟与质量的权衡需求。Qwen3-VL 的核心优势体现在三个方面：(i) 显著增强的纯文本理解能力，在多项测试中超越了同等规模的纯文本骨干模型；(ii) 强大的长上下文理解能力，其原生 256K token 窗口同时支持纯文本及交错的多模态输入，可对长文档和视频内容实现准确的信息保持、检索与交叉引用；(iii) 先进的跨模态推理能力，在单图、多图及视频任务上均表现优异，在 MMMU 及视觉数学基准 (如 MathVista 和 MathVision) 等综合评估中取得了领先的性能表现。在模型架构层面，我们进行了三项关键升级：(i) 引入增强型交错-MRoPE (interleaved-MRoPE)，以提升对图像与视频的时空建模能力；(ii) 集成 DeepStack 模块，通过有效利用多层次 ViT 特征来强化视觉与语言的对齐；(iii) 为视频任务设计了基于文本的时间对齐机制，从 T-RoPE 演进为显式的文本时间戳对齐，从而实现更精准的时序定位。在相近的 token 预算与延迟约束下，Qwen3-VL 在密集与 MoE 架构中均展现出卓越的性能。我们期待 Qwen3-VL 能够成为实际工作流中，支撑图像推理、智能体决策以及多模态代码智能的基础引擎。

ToolOrchestra: 通过高效的模型与工具编排增强智能
ToolOrchestra: 通过高效的模型与工具编排增强智能
大语言模型 (LLM) 是强大的通用系统，但在解决诸如“人类终极考试” (Humanity's Last Exam, HLE) 这类深刻且复杂的问题时，仍面临概念上的挑战和较高的计算成本。我们的研究表明，通过小型编排器来管理其他模型与多样化工具，不仅能够突破智能水平的极限，还能提升解决复杂 AI 智能体 (AI Agent) 任务的效率。本文提出了 ToolOrchestra，一种用于训练小型编排器以协调智能工具的方法。该方法明确采用强化学习，并设计了基于结果、效率和用户偏好的奖励机制。基于 ToolOrchestra，我们训练出了 Orchestrator，这是一个拥有 80 亿参数的模型。对于给定的查询，Orchestrator 能以比以往的工具使用智能体更低的成本获得更高的准确率，同时其工具选择行为能与用户偏好保持一致。在 HLE 基准测试中，Orchestrator 取得了 37.1% 的得分，超越了 GPT-5 (35.1%)，并且效率是后者的 2.5 倍。在 tau2-Bench 和 FRAMES 基准上，Orchestrator 以显著优势领先于 GPT-5，而成本仅约为后者的 30%。深入分析表明，Orchestrator 在多项指标下实现了性能与成本的最佳权衡，并且对未见过的工具展现出强大的泛化能力。这些结果证明，利用轻量级编排模型组合多样化工具，相比现有方法不仅效率更高，而且效果更好，从而为构建实用、可扩展的工具增强推理系统铺平了道路。

Envision: 面向因果世界过程洞察的统一理解与生成基准
Envision: 面向因果世界过程洞察的统一理解与生成基准
当前的多模态模型旨在通过统一理解与生成来克服单模态表示的局限，通常采用文本到图像 (T2I) 任务来确保语义一致性。然而，其在训练和评估中对静态单图像生成的依赖，导致了对静态模式匹配与语义融合的过拟合，同时也从根本上限制了模型对随时间演变的动态过程进行建模的能力。为应对这些局限，我们提出了 Envision——一个用于链式文本到多图像生成的因果事件进展基准。该基准基于世界知识，并以时空因果关系为结构，它整合了现有的评估维度，并包含了涵盖六个科学与人文领域的 1000 个四阶段提示。为了将评估从单图像扩展到序列帧，并检验模型是否在遵循因果-时间约束的同时真正内化了世界知识，我们引入了 Envision-Score，这是一个综合了多维一致性、物理合理性与美学质量的整体评估指标。对 15 个模型 (10 个专用 T2I 模型，5 个统一模型) 的全面评估表明：专用 T2I 模型在美学渲染上表现熟练，但缺乏深层的世界知识。统一多模态模型则弥补了这一不足，在因果叙事连贯性上持续优于专用模型。然而，即便是这些统一架构，其性能仍落后于闭源模型，且难以克服时空一致性的核心挑战。这表明，专注于因果孤立的单图像会阻碍多帧推理与生成，导致模型偏向于静态模式匹配而非动态世界建模，最终限制了世界知识的内化与内容的生成。

Stabilizing Reinforcement Learning with LLMs: Formulation and Practices
使用大语言模型稳定强化学习：公式化与方法
本文提出了一种基于大语言模型 (LLM) 的强化学习 (RL) 新公式，阐释了为何以及何种条件下，可以通过 REINFORCE 等策略梯度方法中的代理 token 级别目标函数来优化真实的序列级别奖励。具体而言，通过一阶近似分析，我们证明，只有当训练-推断差异与策略滞后性均被最小化时，该代理目标函数的有效性才能得到保证。这一见解从原理上解释了几种广泛采用的 RL 训练稳定化技术的关键作用，包括重要性采样校正、梯度裁剪，以及特别针对混合专家 (Mixture-of-Experts, MoE) 模型的路由重放。通过在一个总计消耗数十万 GPU 小时的 300 亿参数 MoE 模型上进行大量实验，我们发现：对于同策略 (on-policy) 训练，带有重要性采样校正的基本策略梯度算法能实现最高的训练稳定性。而当引入异策略 (off-policy) 更新以加速收敛时，结合梯度裁剪与路由重放对于缓解因策略滞后性引起的不稳定性至关重要。值得注意的是，一旦训练趋于稳定，无论采用何种冷启动初始化方式，持续优化总能获得相当的最终性能。我们希望，所分享的见解与开发的稳定 RL 训练方案能促进未来的研究。

DeepSeekMath-V2: Towards Self-Verifiable Mathematical Reasoning
DeepSeekMath-V2: 迈向可自我验证的数学推理
大语言模型在数学推理方面取得了显著进展。数学推理是人工智能的一个重要测试平台，其进一步发展可能影响科学研究。通过采用奖励最终正确答案的强化学习来扩展推理能力，大语言模型在一年内从性能不佳提升到在 AIME、HMMT 等定量推理竞赛中达到性能饱和。然而，这种方法存在根本性局限。追求更高的最终答案准确率无法解决一个关键问题：正确答案并不能保证推理过程正确。此外，许多数学任务（如定理证明）需要严格的逐步推导，而非仅仅给出数值答案，这使得基于最终答案的奖励机制无法适用。为了突破深度推理的瓶颈，我们认为有必要对数学推理的全面性和严谨性进行验证。自我验证对于扩展测试阶段的计算资源尤为重要，特别是对于那些没有已知解的开放性问题。为实现可自我验证的数学推理，我们研究了如何训练一个准确、可靠的大语言模型验证器用于定理证明。接着，我们以该验证器作为奖励模型来训练一个证明生成器，并激励生成器在最终确定证明前，尽可能多地识别并解决自身证明中的问题。为防止生成器能力增强导致生成与验证之间的差距缩小，我们提出通过增加验证阶段的计算资源，自动标注新产生的、难以验证的证明，从而创建训练数据以持续改进验证器。由此得到的模型 DeepSeekMath-V2 展现出强大的定理证明能力：在增加测试阶段计算资源的情况下，它在 IMO 2025 和 CMO 2024 上获得了金牌级分数，并在 Putnam 2024 上取得了接近满分的 118/120 分。

Nex-N1: 通过大规模环境构建的统一生态系统训练的智能体模型
Nex-N1: 通过大规模环境构建的统一生态系统训练的智能体模型
大语言模型 (LLMs) 从被动响应者向自主智能体的演进，要求学习范式发生根本性转变——即从静态模仿转向激励驱动的决策。然而，由于缺乏能够为有效策略学习生成高质量交互信号的可扩展基础设施，这一转变受到了严重阻碍。为解决此问题，我们提出了一种综合性方法，旨在系统化地提升交互环境的多样性和复杂性。该方法通过解决三个相互独立且互补的维度来实现规模化构建：(1) 复杂性：NexAU，一个灵活的智能体框架，支持通过简单配置构建复杂的智能体层次结构；(2) 多样性：NexA4A 能够从自然语言自动生成多样化的智能体层次结构，从而覆盖无限领域；(3) 保真度：NexGAP 通过集成动态的真实世界环境来合成具身轨迹，以此弥合仿真与现实之间的鸿沟。我们基于该基础设施所建立的多样且复杂的交互环境对 Nex-N1 进行了训练。在 SWE-bench 和 tau2 等基准测试上的实证结果表明，Nex-N1 始终优于最先进的开源模型，并且在复杂的智能体任务上，其性能可与前沿的专有模型相竞争。我们开源了 Nex 生态系统及模型权重，以推动相关领域的进一步研究。

MultiShotMaster: 可控多镜头视频生成框架
MultiShotMaster: 可控多镜头视频生成框架
当前的视频生成技术擅长生成单镜头片段，但难以生成具有叙事性的多镜头视频。这类视频需要灵活的镜头安排、连贯的叙事逻辑以及超越文本描述的控制能力。为应对这些挑战，我们提出了 MultiShotMaster，一个具备高可控性的多镜头视频生成框架。我们通过集成两种新颖的 RoPE (Rotary Position Embedding) 变体，扩展了一个预训练的单镜头模型。首先，我们引入了多镜头叙事 RoPE，它在镜头切换时施加显式的相位偏移，从而在维持时序叙事的前提下实现灵活的镜头编排。其次，我们设计了时空位置感知 RoPE，以融入参考 token 和 grounding (接地) 信号，从而实现基于时空位置的参考信息注入。此外，为克服数据稀缺问题，我们构建了一套自动化数据标注流水线，用于从视频数据中解析出多镜头视频片段、对应字幕、跨镜头 grounding 信号以及参考图像。我们的框架利用其内在的架构特性来支持多镜头视频生成，主要特点包括：文本驱动的镜头间一致性、支持运动控制的自定义主体（如物体或角色），以及背景驱动的自定义场景。镜头数量和时长均可灵活配置。大量实验表明，我们的框架在性能和可控性方面均表现优异。

Deep Research: A Systematic Survey
深度研究：一项系统性综述
大语言模型（LLMs）已迅速从文本生成工具演变为强大的问题求解器。然而，许多开放性任务要求具备批判性思维、整合多源信息并产生可验证的输出，这超出了单次提示（single-shot prompting）或标准检索增强生成（RAG）的能力范围。近期，大量研究开始探索深度研究（Deep Research， DR），其核心目标是将大语言模型的推理能力与搜索引擎等外部工具相结合，从而赋能大语言模型成为能够完成复杂、开放式任务的研究智能体（research agents）。本综述对深度研究系统进行了全面而系统的梳理，内容涵盖清晰的路线图、基础组件、实际实现技术、关键挑战以及未来方向。具体而言，我们的主要贡献如下：（i）形式化了一个三阶段路线图，并明确了深度研究与相关范式的区别；（ii）介绍了四个关键组件：查询规划、信息获取、记忆管理与答案生成，并为每个组件提供了细粒度的子类别划分；（iii）总结了包括提示工程、监督微调以及智能体强化学习在内的优化技术；（iv）整合了相关的评估标准与开放挑战，旨在为未来的发展提供指导与便利。鉴于深度研究领域正在快速发展，我们将持续维护并更新本综述，以同步反映该领域的最新进展。

How Far Are We from Genuinely Useful Deep Research Agents?
我们距离真正有用的深度研究智能体还有多远？
深度研究智能体 (Deep Research Agents, DRAs) 旨在通过迭代的信息检索与综合，自动生成分析师级别的报告。然而，现有的大多数 DRAs 仅在问答基准上进行验证，而生成综合性报告的研究仍被忽视。更严重的是，当前用于报告综合的基准存在任务复杂性和评估指标主观性强的问题，这既无法反映真实用户需求，也限制了生成报告的实际效用。为弥补这些不足，我们提出了细粒度深度研究基准 (Fine-grained DEepResearch bench, FINDER)。该基准经过增强，包含 100 个人工精心策划的研究任务，并配有 419 个结构化检查项，用以标准化报告的结构、分析深度和事实依据。基于主流 DRAs 生成的大约 1,000 份报告，我们进一步提出了深度研究失败分类法 (Deep rEsearch Failure Taxonomy, DEFT)，这是首个专门针对深度研究智能体的失败模式分类体系。DEFT 涵盖了推理、检索和生成三个方面的 14 种细粒度失败模式，其构建基于扎根理论，并采用了人工与大语言模型协同标注以及标注者间一致性检验。我们的实验结果表明，当前 DRAs 的主要挑战并非任务理解，而是证据整合、验证以及在推理过程中保持稳健的规划能力。

TUNA: 构建统一视觉表示以实现原生统一多模态模型
TUNA: 构建统一视觉表示以实现原生统一多模态模型
统一多模态模型 (UMMs) 旨在单个框架内同时实现多模态理解与生成。我们提出了 TUNA，一个原生 UMM，它通过将 VAE 编码器与表示编码器级联，构建了一个统一的连续视觉表示。这一统一的表示空间支持对图像和视频进行端到端处理，以同时服务于理解和生成任务。与先前采用解耦表示的 UMMs 相比，TUNA 的统一视觉空间避免了因使用独立编码器而导致的表示格式不匹配问题，从而在理解和生成任务上均优于解耦方案。此外，我们发现，性能更强的预训练表示编码器能够在所有多模态任务上持续带来更优的性能，这凸显了表示编码器的重要性。最后，在这种统一框架下，联合使用理解和生成数据进行训练，能使两项任务相互促进而非相互干扰。我们在多模态理解与生成基准测试上进行了大量实验，结果表明，TUNA 在图像与视频理解、图像与视频生成以及图像编辑任务上均取得了最先进的性能，充分证明了其统一表示设计的有效性和可扩展性。
引导式大语言模型自进化：最小化人类监督
引导式大语言模型自进化：最小化人类监督
人工智能 (AI) 自进化 (self-evolution) 一直被视作通向超级智能的途径，即模型能够从其自身学习经验中自主地获取、优化并内化知识。然而，实际应用中，无引导的自进化系统往往很快陷入性能平台期，甚至在训练过程中发生退化。这些失败源于概念漂移 (concept drift)、多样性崩溃 (diversity collapse) 和错误进化 (mis-evolution) 等问题，因为模型会不断强化自身偏见，并收敛到低熵 (low-entropy) 行为。为了在最小化对人类监督依赖的同时，实现模型稳定、可控的自进化，我们提出了 R-Few：一个引导式的自我对弈 (Self-Play) 挑战者-求解器 (Challenger-Solver) 框架。该框架通过基于上下文的锚定 (in-context grounding) 和混合训练 (mixed training)，引入了轻量级的人类监督。在每一轮迭代中，挑战者 (Challenger) 会采样一小部分人工标注的示例，用以指导合成问题的生成；而求解器 (Solver) 则遵循一个基于难度的在线课程学习 (online, difficulty-based curriculum) 策略，对人工示例和合成示例进行联合训练。在数学和通用推理基准测试中，R-Few 实现了持续且迭代的性能提升。例如，Qwen3-8B-Base 模型在数学任务上比 R-Zero 提升了 3.0 分，其性能与 General-Reasoner 相当，而后者的训练使用了多达 20 倍以上的人工标注数据。消融研究 (Ablation studies) 证实了基于锚定的挑战者训练 (grounded challenger training) 和基于课程的求解器训练 (curriculum-based solver training) 具有互补作用；进一步分析表明，R-Few 有效缓解了概念漂移，从而产生了更稳定、更可控的协同进化 (co-evolutionary) 动态。

MG-Nav: Dual-Scale Visual Navigation via Sparse Spatial Memory
MG-Nav：基于稀疏空间记忆的双尺度视觉导航
我们提出了 MG-Nav (Memory-Guided Navigation，记忆引导导航)，这是一个用于零样本视觉导航的双尺度框架，它将全局记忆引导规划与局部几何增强控制相统一。其核心是稀疏空间记忆图 (Sparse Spatial Memory Graph, SMG)，这是一种紧凑的、以区域为中心的记忆结构。其中每个节点聚合了多视角关键帧和对象语义信息，不仅能捕获外观与空间结构，还保留了视角多样性。在全局层面，智能体首先在 SMG 上进行定位，然后通过图像到实例的混合检索，规划出一条以目标为条件的节点路径，从而生成一系列可达的路径点，为长程导航提供引导。在局部层面，一个导航基础策略以点目标模式执行这些路径点，并采用障碍物感知控制；当从最终节点向视觉目标导航时，则切换至图像目标模式。为了进一步提升视角对齐和目标识别的能力，我们引入了 VGGT-adapter。这是一个基于预训练 VGGT 模型构建的轻量级几何模块，能够在共享的 3D 感知空间中对齐观测特征与目标特征。MG-Nav 以不同的频率执行全局规划和局部控制，并利用周期性的重新定位来纠正误差。在 HM3D Instance-Image-Goal 和 MP3D Image-Goal 基准测试上的实验表明，MG-Nav 实现了最先进的零样本性能，并且在动态场景重排和未见过的场景条件下仍能保持鲁棒性。
视频生成中的重力问题如何解决？利用可验证奖励对模型进行牛顿定律后训练
视频生成中的重力问题如何解决？利用可验证奖励对模型进行牛顿定律后训练
当前的视频扩散模型虽能生成视觉上逼真的片段，却常常违背基本物理定律，例如物体漂浮、加速度异常、碰撞行为不一致等，这揭示了视觉真实感与物理真实感之间存在的持续差距。为此，我们提出了 NewtonRewards\texttt{NewtonRewards}NewtonRewards，这是首个基于 可验证奖励\textit{可验证奖励}可验证奖励、以物理学原理为根基的视频生成后训练框架。该框架不依赖人类或视觉语言模型 (VLM) 的反馈，而是利用冻结的工具模型从生成视频中提取 可测量的代理量\textit{可测量的代理量}可测量的代理量：以光流作为速度的代理，以高级外观特征作为质量的代理。基于这些代理量，我们通过两种互补的奖励机制来显式地强化牛顿力学结构：一是强制执行恒定加速度动力学的牛顿运动学约束奖励，二是防止出现平凡退化解的质量守恒奖励。我们使用新构建的大规模基准数据集 NewtonBench-60K\texttt{NewtonBench-60K}NewtonBench-60K，在五种牛顿运动基元（自由落体、水平抛射、抛物线抛射、斜坡下滑与上滑）上对 NewtonRewards\texttt{NewtonRewards}NewtonRewards 进行了评估。在所有基元的视觉与物理指标上，NewtonRewards\texttt{NewtonRewards}NewtonRewards 均能持续提升生成视频的物理合理性、运动平滑度与时间连贯性，效果优于已有的后训练方法。此外，在高度、速度、摩擦力等参数发生分布外偏移时，该方法依然能保持强劲的性能。我们的研究结果表明，基于物理学的可验证奖励为实现物理感知的视频生成提供了一条可扩展的路径。

REASONEDIT: 面向推理增强的图像编辑模型
REASONEDIT: 面向推理增强的图像编辑模型
图像编辑模型近期取得了显著进展。一种常见的架构设计是将多模态大语言模型 (Multimodal Large Language Model, MLLM) 编码器与扩散解码器相结合，例如 Step1X-Edit 和 Qwen-Image-Edit 等系统。在这些系统中，MLLM 负责编码参考图像和编辑指令，但其参数在训练过程中保持冻结。本工作表明，释放 MLLM 的推理能力可以进一步拓展图像编辑模型的性能边界。具体而言，我们探索了两种推理机制——思维 (Thinking) 与反思 (Reflection)，以提升模型对指令的理解能力和编辑准确性。基于此，我们提出了一个思维-编辑-反思循环框架：思维机制利用 MLLM 的世界知识来解析抽象指令，而反思机制则评估编辑结果、自动纠正非预期的修改，并确定停止迭代的时机。大量实验验证了我们推理方法的有效性。当基于 Step1X-Edit 初始化我们的 DiT 模型 (即 ReasonEdit-S) 时，在 ImgEdit (+4.3%)、GEdit (+4.7%) 和 Kris (+8.2%) 基准上均取得了显著提升。此外，当与 Qwen-Image-Edit 结合构建 ReasonEdit-Q 时，其在 GEdit 和 Kris 基准上的表现也超越了此前所有的开源方法。

## 每周AI论文速递（251124-251128）

ROOT: Robust Orthogonalized Optimizer for Neural Network Training
ROOT：神经网络训练的鲁棒正交化优化器
大语言模型 (LLM) 的优化仍面临关键挑战，尤其随着模型规模扩大，其对算法不精确性与训练不稳定性的敏感度日益加剧。近期优化器研究通过动量正交化提升了收敛效率，但存在两大鲁棒性缺陷：正交化精度的维度敏感性及对异常值引发噪声的易损性。为解决这些问题，我们提出ROOT (Robust Orthogonalized Optimizer)，该优化器通过双重鲁棒机制增强训练稳定性。首先，我们设计了一种维度鲁棒的正交化方案，采用自适应牛顿迭代及针对特定矩阵尺寸定制的细粒度系数，确保在不同架构配置下均能保持精度一致性。其次，我们引入基于近端优化的鲁棒框架，在有效抑制异常值噪声的同时保留关键梯度方向。大量实验证明，ROOT 在鲁棒性方面显著提升，相比 Muon 和 Adam 类优化器，收敛速度更快且最终性能更优，尤其在噪声环境和非凸场景中表现突出。本研究确立了一种新范式，可用于开发鲁棒且精确的优化器，以应对现代大规模模型训练的复杂性。代码将发布于 github.com/huawei-noah…

General Agentic Memory Via Deep Research
基于深度研究的通用智能体记忆
记忆对于 AI 智能体至关重要，但广泛采用的静态记忆系统旨在预先构建随时可用的记忆，这不可避免地会导致严重的信息损失。为解决这一局限，我们提出了一种名为 通用智能体记忆 (GAM) 的新框架。GAM 遵循 "即时编译 (JIT)" 原则，专注于在运行时为其服务对象生成优化上下文，同时在离线阶段仅保留简洁而实用的记忆。为此，GAM 采用双重设计，包含以下组件：1) 记忆器 (Memorizer)，利用轻量级记忆提取关键历史信息，同时在通用页面存储中维护完整历史记录；2) 研究者 (Researcher)，基于预构建的记忆，从页面存储中检索并集成有用信息以响应在线请求。这种设计使 GAM 能够有效利用前沿大语言模型 (LLMs) 的智能体能力和推理时扩展性，同时通过强化学习实现端到端性能优化。在实验研究中，我们证明 GAM 在各种记忆驱动型任务完成场景中，相比现有记忆系统，取得了显著提升。

GigaEvo: An Open Source Optimization Framework Powered By LLMs And Evolution Algorithms
GigaEvo：一个由大语言模型和进化算法驱动的开源优化框架
大语言模型引导的进化计算领域近期取得重要进展，特别是 AlphaEvolve (Novikov 等人, 2025; Georgiev 等人, 2025) 在发现新颖数学构造和解决复杂优化问题方面展现出卓越成效。然而，现有公开文献中的高层描述未明确说明具体实现细节，这阻碍了研究的可复现性与深入探索。本报告提出 GigaEvo——一个可扩展的开源框架，支持研究人员对受 AlphaEvolve 启发的混合大语言模型-进化方法进行系统研究与实践。该框架采用模块化设计，核心组件包括：MAP-Elites 质量-多样性算法、基于异步有向无环图的评估流水线、支持洞见生成与双向谱系追踪的大语言模型驱动变异算子，以及灵活的多岛进化策略。为验证实现的可复现性，我们使用 AlphaEvolve 论文中的三类典型难题对 GigaEvo 进行评估：Heilbronn 三角形布局、正方形内圆填充问题和高维接吻数问题。本框架强调模块化架构、并行计算与实验便捷性，通过声明式配置支持快速原型开发。我们详细阐述了系统架构设计、关键技术决策与实验方法，旨在推动大语言模型驱动进化算法的持续研究。GigaEvo 框架及完整实验代码已开源：github.com/AIRI-Instit…

SAM 3: Segment Anything with Concepts
SAM 3：基于概念的分割万物模型
我们提出分割万物模型 (SAM) 3，这是一个统一模型，能够根据概念提示检测、分割并跟踪图像和视频中的对象。概念提示定义为短名词短语（如“黄色校车”）、图像示例或两者组合。可提示概念分割 (PCS) 接收这些提示，并输出所有匹配对象实例的分割掩码和唯一标识。为推进 PCS 研究，我们构建了可扩展数据引擎，生成包含 400 万独特概念标签的高质量数据集，涵盖图像和视频中的难负样本。该模型由共享单一骨干网络的图像级检测器和基于记忆的视频跟踪器组成，通过存在头解耦识别与定位模块，显著提升检测精度。SAM 3 在图像与视频 PCS 任务中实现精度翻倍，并优化了先前 SAM 模型在视觉分割任务中的性能。我们开源了 SAM 3 模型及新构建的基于概念的分割万物 (SA-Co) 基准，用于可提示概念分割研究。

Latent Collaboration in Multi-Agent Systems
多智能体系统中的潜在协作
多智能体系统 (MAS) 将大语言模型 (LLMs) 从独立的单模型推理扩展至协同的系统级智能。现有 LLM 智能体通常依赖基于文本的中介进行推理与通信，而本研究进一步实现了模型在连续潜在空间中的直接协作。我们提出 LatentMAS，一种端到端的无需训练框架，支持 LLM 智能体间的纯潜在协作。在 LatentMAS 中，各智能体首先通过最后一层隐藏嵌入执行自回归潜在思维生成；随后，一个共享潜在工作记忆负责保存并传递各智能体的内部表示，确保信息无损交换。理论分析表明，相较于基础的基于文本 MAS，LatentMAS 以显著更低的复杂度实现了更强的表达能力与无损信息保留。此外，在数学科学推理、常识理解和代码生成等 9 个综合基准测试中，实证评估显示 LatentMAS 持续优于强单模型及基于文本的 MAS 基线，准确率最高提升 14.6%，输出 Token 用量减少 70.8%-83.7%，端到端推理速度加快 4-4.3 倍。这些结果证明，本潜在协作框架在无需额外训练的前提下，不仅提升了系统级推理质量，还带来了显著的效率增益。代码与数据已完全开源：github.com/Gen-Verse/L…

GeoVista: Web-Augmented Agentic Visual Reasoning for Geolocalization
GeoVista: 面向地理定位的网络增强智能体视觉推理
当前智能体视觉推理的研究虽能实现深度多模态理解，但主要聚焦于图像处理工具，导致在构建更通用智能体模型方面存在不足。本文重新探讨地理定位任务，该任务不仅需要精细的视觉基础能力，还需在推理过程中借助网络搜索来验证或优化假设。鉴于现有地理定位基准无法满足高分辨率图像需求及深度智能体推理的定位挑战，我们构建了GeoBench基准，其中包含全球各地的照片、全景图以及不同城市的卫星图像子集，以严格评估智能体的地理定位能力。同时，我们提出GeoVista模型，它能将工具调用无缝整合到推理回路中，包括用于放大感兴趣区域的图像缩放工具和用于检索相关网络信息的搜索工具。我们为其开发了完整训练流程：首先通过冷启动监督微调 (SFT) 阶段学习推理模式与工具使用先验，再通过强化学习 (RL) 阶段进一步提升推理能力。通过采用分层奖励机制有效利用多级地理信息，显著提升了整体定位性能。实验结果表明，GeoVista在地理定位任务上显著优于其他开源智能体模型，且在多数指标上达到与闭源模型（如Gemini-2.5-flash和GPT-5）相当的水平。

AutoEnv: Automated Environments for Measuring Cross-Environment Agent Learning
AutoEnv：用于测量跨环境智能体学习的自动化环境
人类通过在不同动态、观察和奖励结构的世界中学习底层规则，自然地适应多样化环境。相比之下，现有智能体通常通过在单一领域内自我演化来展示改进，隐式地假设了固定的环境分布。跨环境学习在很大程度上仍未得到充分评估：既缺乏可控、异构环境的标准集合，也没有统一的方法来表征智能体如何学习。我们通过两个步骤来解决这些不足。首先，我们提出AutoEnv，一个自动化框架，将环境视为可因子化的转移、观察和奖励分布，实现低成本（平均4.12美元）生成异构世界。利用AutoEnv，我们构建了AutoEnv-36数据集，包含36个环境和358个已验证关卡，在该数据集上，七个语言模型实现了12-49%的归一化奖励，证明了AutoEnv-36的高挑战难度。其次，我们将智能体学习形式化描述为一个以组件为中心的过程，该过程由选择、优化和评估三个阶段驱动，并应用于可改进的智能体组件。基于此形式化，我们设计了八种学习方法，并在AutoEnv-36上对其进行了评估。实证结果表明，任何单一学习方法的性能增益随环境数量增加而迅速下降，揭示出固定学习方法无法在异构环境中扩展。学习方法的自适应环境选择能显著提升性能，但随着方法空间的扩大，表现出收益递减效应。这些结果凸显了智能体学习对于可扩展跨环境泛化的必要性及其当前局限，并将AutoEnv和AutoEnv-36作为研究跨环境智能体学习的测试平台。代码可在github.com/FoundationA…

OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe
OpenMMReasoner：基于开放通用方案推动多模态推理前沿发展
大语言推理模型的最新进展，引发了将其能力扩展至多模态领域的广泛关注。然而，尽管视觉推理已取得显著突破，但缺乏透明且可复现的数据构建与训练策略，仍是制约规模化研究的主要障碍。本研究提出OpenMMReasoner——一个完全透明的两阶段多模态推理方案，涵盖监督微调（SFT）和强化学习（RL）两个阶段。在SFT阶段，我们构建了包含87.4万样本的冷启动数据集，并通过严格的分步验证为推理能力奠定坚实基础。后续RL阶段利用跨多个领域的7.4万样本数据集，进一步强化并稳定模型能力，从而实现更鲁棒高效的学习过程。大量实验表明，本训练方案不仅显著超越强基线模型，更揭示了数据质量与训练设计对多模态推理性能的决定性作用。值得注意的是，在九大多模态推理基准测试中，本方法相较Qwen2.5-VL-7B-Instruct基线实现了11.6%的性能提升，为未来大规模多模态推理研究提供了坚实实证基础。我们已在github.com/EvolvingLMM…

Unveiling Intrinsic Dimension of Texts: from Academic Abstract to Creative Story
揭示文本的内在维度：从学术摘要到创意故事
内在维度 (ID) 是现代大语言模型分析中的重要工具，可用于研究训练动态、缩放规律和数据集结构，但其文本层面的决定因素尚待深入探索。我们通过交叉编码器分析、语言特征和稀疏自编码器 (SAEs) ，首次开展了基于可解释文本属性的 ID 系统性研究。本研究确立了三个关键发现：第一，ID 与基于熵的指标具有互补性——在控制文本长度后，两者无相关性，ID 捕获的是独立于预测质量的几何复杂度；第二，ID 呈现稳定的体裁分层现象——在所有测试模型中，科学文本显示低 ID 值 (~8) ，百科全书类内容为中等 ID 值 (~9) ，而创意写作与观点类文本则呈现高 ID 值 (~10.5) ，这表明当代大语言模型将科学文本视为“表征简单”的类别，而小说类文本需要更多表征自由度；第三，通过 SAEs 我们识别出因果特征：科学信号（正式语气、报告模板、统计数据）会降低 ID ，而人性化信号（个性化表达、情感元素、叙事结构）则会提升 ID 。定向控制实验证实了这些影响的因果性。因此，对当代模型而言，科学写作相对“易于处理”，而小说、观点性文本及情感内容则增加了表征复杂度。我们的多维度分析为 ID 的合理应用及基于 ID 结论的可靠解读提供了实践指导。

Multimodal Evaluation of Russian-language Architectures
俄语模型的多模态评估
多模态大语言模型 (MLLMs) 是当前研究关注的焦点，在规模和能力方面均展现出快速进步，然而其智能水平、局限性及潜在风险尚未得到充分理解。为了解决这些问题，尤其是在俄语语境下，鉴于目前尚无多模态基准，我们引入了 Mera Multi——一个面向俄语模型的开放多模态评估框架。该基准采用指令驱动设计，涵盖默认的文本、图像、音频和视频模态，包含 18 个全新构建的评估任务，面向通用模型及模态特定架构（如图像到文本、视频到文本和音频到文本）。我们的贡献包括：(i) 一套通用多模态能力分类体系；(ii) 18 个从零开始构建的数据集，注重俄语文化及语言特性，并配有统一提示词和评估指标；(iii) 闭源与开源模型的基线性能结果；(iv) 一套防止基准泄漏的防护方法，包括水印技术和私有数据集的许可协议。尽管当前研究聚焦于俄语，但所提出的基准为在类型学多样的语言（特别是斯拉夫语族）中构建多模态评估体系提供了可复现的方法论。

DeCo: Frequency-Decoupled Pixel Diffusion for End-to-End Image Generation
DeCo: 面向端到端图像生成的频率解耦像素扩散方法
像素扩散的目标是以端到端方式直接在像素空间生成图像。该方法规避了 VAE 在二阶段潜在扩散中的局限性，从而具备更高的模型容量。现有像素扩散模型因通常在单一扩散 Transformer (DiT) 中同时建模高频信号与低频语义，导致训练和推理速度缓慢。为构建更高效的像素扩散范式，我们提出频率解耦像素扩散框架。基于解耦高频与低频分量生成的思路，我们采用轻量级像素解码器，在 DiT 语义引导下生成高频细节。这使得 DiT 能够专注于低频语义建模。此外，我们引入频率感知流匹配损失，在强化视觉显著频率分量的同时抑制非显著分量。大量实验证明，DeCo 在像素扩散模型中取得最优性能，在 ImageNet 数据集上获得 1.62 (256×256) 和 2.22 (512×512) 的 FID 指标，显著缩小了与潜在扩散方法的性能差距。我们的预训练文生图模型在 GenEval 基准测试的系统级比较中，更以 0.86 的综合得分保持领先。代码已开源：github.com/Zehong-Ma/D…

Computer-Use Agents as Judges for Generative User Interface
计算机智能体作为生成式用户界面的评判者
计算机智能体 (CUA) 正日益擅长通过图形用户界面 (GUI) 自主操作数字环境。然而，当前大多数 GUI 仍主要面向人类设计（优先考虑美观性和可用性），迫使智能体采用许多对高效任务执行非必要的人类化操作模式。与此同时，编码语言模型 (Coder) 的快速发展正在革新自动 GUI 设计范式。这引出一个核心问题：能否以 CUA 作为评判者，辅助 Coder 实现自动 GUI 设计？为探究此问题，我们推出 AUI-Gym 基准测试集，涵盖 52 个跨领域应用的自动 GUI 开发任务。基于语言模型，我们合成了 1560 个模拟真实场景的任务。为确保任务可靠性，我们还开发了验证模块，通过编程验证每个任务在对应环境中的可执行性。在此基础上，我们提出 Coder-CUA 协同框架：Coder 担任设计者角色，负责生成和迭代优化网站界面；CUA 则作为评判者，评估功能实现质量并指导设计改进。评估标准不依赖视觉表现，而是基于任务可解决性与 CUA 导航成功率。为将 CUA 反馈转化为有效指导，我们设计了 CUA 仪表板，将多步导航轨迹凝练为直观的视觉摘要，为迭代设计提供可解释的优化指引。通过让智能体同时承担设计者与评判者角色，本框架将界面设计推向更符合智能体原生特性的高效可靠范式。本研究推动智能体从被动使用向数字环境主动参与迈出关键一步。代码与数据集详见 github.com/showlab/AUI…

DR Tulu: Reinforcement Learning with Evolving Rubrics for Deep Research
DR Tulu：基于演化评分标准的强化学习在深度研究中的应用
深度研究模型通过多步研究过程生成长篇且引用充分的答案。然而，现有大多数开放深度研究模型采用可验证奖励强化学习 (RLVR) 在易于验证的短篇问答任务上进行训练，这种方法无法扩展到实际的长篇研究任务。为此，我们提出了基于演化评分标准的强化学习 (RLER) 方法，通过构建与策略模型在训练过程中协同演化的评分标准，使评分体系能够整合模型新探索的信息，并提供具有区分度的同策略反馈。基于RLER方法，我们开发了深度研究Tulu模型 (DR Tulu-8B)，这是首个专门针对开放式长篇深度研究任务训练的开放模型。在科学、医疗保健及通用领域的四个长篇深度研究基准测试中，DR Tulu模型显著优于现有开放深度研究模型，其性能达到甚至超越了专有深度研究系统，同时具有更小的模型尺寸和更低的单次查询成本。为促进后续研究，我们完整公开了所有数据、模型和代码，包括新开发的基于MCP的深度研究系统智能体基础设施。

MedSAM3: Delving into Segment Anything with Medical Concepts
MedSAM3：融合医学概念的分割万物模型深入解析
医学图像分割是生物医学发现的基础技术。现有方法普遍存在泛化能力不足的问题，且针对新临床应用需进行大量耗时的人工标注。本文提出MedSAM-3模型——一种支持文本提示的医学图像与视频分割模型。通过对Segment Anything Model (SAM) 3架构在医学图像及对应语义概念标签上进行微调，MedSAM-3实现了医学可提示概念分割 (PCS) 功能，能够基于开放词汇文本描述精确定位解剖结构，而不仅依赖几何提示信息。我们还开发了MedSAM-3智能体 (Agent) 框架，通过集成多模态大语言模型 (MLLMs) ，在智能体参与循环的工作流程中实现复杂推理与迭代优化。涵盖X射线、磁共振成像 (MRI) 、超声、计算机断层扫描 (CT) 及视频等多种医学成像模态的综合实验表明，本方法性能显著优于现有专业模型与基础模型。相关代码与模型将在github.com/Joey-S-Liu/…

Agent0-VL: Exploring Self-Evolving Agent for Tool-Integrated Vision-Language Reasoning
Agent0-VL: 探索用于工具集成视觉语言推理的自进化智能体
视觉语言智能体在各种多模态推理任务中取得了显著进展，但其学习过程仍受限于人类标注监督的约束。近期出现的自奖励方法尝试通过让模型充当自身评判者或奖励提供者来突破这一限制。然而，纯文本形式的自我评估难以有效验证复杂的视觉推理步骤，且常出现评估幻觉问题。为解决这些挑战，受工具集成推理领域最新进展的启发，我们提出Agent0-VL——一种通过工具集成推理实现持续自我提升的自进化视觉语言智能体。Agent0-VL不仅将工具运用融入推理过程，还将其扩展至自我评估与自我修复环节，使模型能够通过证据驱动的分析实现推理过程的内省、验证与优化。该架构在单一的大视觉语言模型 (LVLM) 中整合了两个协同工作的角色：执行多轮工具集成推理的求解器 (Solver)，以及通过工具化批判生成结构化反馈与细粒度自奖励的验证器 (Verifier)。这些角色通过自进化推理循环 (Self-Evolving Reasoning Cycle) 相互协作，其中基于工具的验证机制与强化学习共同对齐推理与评估的分布，确保稳定的自我改进。通过这种零外部奖励的进化机制，Agent0-VL在无需任何人工标注或外部奖励模型的情况下，实现了推理行为与验证行为的自对齐，达成持续自我优化。在几何问题求解和视觉科学分析领域的实验表明，Agent0-VL相较基础模型实现了12.5%的性能提升。代码已开源：github.com/aiming-lab/…

## 每周AI论文速递（251208-251212）

Wan-Move: Motion-controllable Video Generation via Latent Trajectory Guidance
Wan-Move: 通过潜在轨迹引导实现运动可控的视频生成
我们提出了 Wan-Move，一个简单且可扩展的框架，旨在为视频生成模型引入运动控制能力。现有的运动可控方法通常面临控制粒度粗糙和可扩展性有限的问题，使其输出难以满足实际应用需求。通过实现精确且高质量的运动控制，我们缩小了这一差距。我们的核心思想是直接使原始的条件特征具备运动感知能力，从而指导视频合成。具体而言，我们首先使用密集点轨迹来表示物体运动，以实现对场景的细粒度控制。接着，我们将这些轨迹映射到潜在空间，并沿每条轨迹传播第一帧的特征，从而生成一个对齐的时空特征图，该图定义了每个场景元素应如何运动。此特征图作为更新得到的潜在条件，可以无缝集成到现成的图像到视频模型（例如 Wan-I2V-14B）中，作为运动引导，而无需改变任何模型架构。该方法无需辅助运动编码器，并使得基础模型的微调具备良好的可扩展性。通过大规模训练，Wan-Move 能够生成 5 秒、480p 的视频，用户研究表明其运动可控性可与 Kling 1.5 Pro 的商业版 Motion Brush 相媲美。为了支持全面评估，我们进一步设计了 MoveBench，这是一个精心构建的基准测试，包含多样化的内容类别和经过混合验证的标注。其显著特点在于数据量更大、视频时长更长以及高质量的运动标注。在 MoveBench 和公共数据集上进行的大量实验一致证明了 Wan-Move 卓越的运动生成质量。代码、模型和基准数据均已公开。

Visionary: The World Model Carrier Built on WebGPU-Powered Gaussian Splatting Platform
Visionary: 基于 WebGPU 高斯泼溅平台的世界模型载体
神经渲染，特别是 3D 高斯泼溅 (3D Gaussian Splatting, 3DGS) 技术，已迅速发展成为构建世界模型的关键组件。然而，现有的查看器解决方案往往较为分散、笨重或受传统流水线限制，导致部署难度大，且对动态内容与生成模型的支持有限。为此，我们提出了 Visionary，一个开放的、基于 Web 的原生平台，用于实时渲染各类高斯泼溅与网格数据。该平台基于高效的 WebGPU 渲染器构建，并集成了每帧 ONNX 推理能力，从而在保持轻量级、“即点即用”浏览器体验的同时，实现了动态神经处理。Visionary 引入了一个标准化的高斯生成器接口，不仅支持标准 3DGS 渲染，还允许以即插即用的方式，在每帧生成或更新高斯分布。这种推理能力也使得前馈式生成后处理得以应用。此外，平台还提供了一个 three.js 库插件，其简洁的 TypeScript API 便于无缝集成到现有 Web 应用程序中。实验表明，在相同的 3DGS 资源下，得益于基于 GPU 的图元排序，Visionary 相比现有 Web 查看器实现了更优的渲染效率。目前，它已支持多种变体，包括基于 MLP 的 3DGS、4DGS、神经化身以及风格转换或增强网络。通过在浏览器中直接统一推理与渲染，Visionary 显著降低了 3DGS 系列方法的复现、比较与部署门槛，为重建式与生成式两种范式提供了一个统一的世界模型载体。

Native Parallel Reasoner: Reasoning in Parallelism via Self-Distilled Reinforcement Learning
原生并行推理器：通过自蒸馏强化学习实现并行推理
我们提出了原生并行推理器 (Native Parallel Reasoner, NPR)，这是一个免教师框架，能够使大语言模型 (LLMs) 自我进化出真正的并行推理能力。NPR 通过三项关键创新，将模型从顺序式处理转变为原生并行认知：1) 一种自蒸馏渐进训练范式，无需外部监督，即可从“冷启动”格式发现过渡到严格的拓扑约束；2) 一种新颖的并行感知策略优化 (Parallel-Aware Policy Optimization, PAPO) 算法，该算法直接在执行图内部优化分支策略，使模型能够通过试错进行自适应分解；以及 3) 一个稳健的 NPR 引擎，它重构了 SGLang 的内存管理与流程控制，从而支持稳定、大规模并行强化学习训练。在八项推理基准测试上，基于 Qwen3-4B 训练的 NPR 实现了高达 24.5% 的性能提升和高达 4.6 倍的推理加速。与先前常需回退至自回归解码的基线方法不同，NPR 实现了 100% 的真正并行执行，从而为自我进化、高效且可扩展的智能体推理树立了新标准。

T-pro 2.0: An Efficient Russian Hybrid-Reasoning Model and Playground
T-pro 2.0：一个高效的俄语混合推理模型与测试平台
我们推出 T-pro 2.0，这是一个开放权重的俄语大语言模型 (LLM)，专注于混合推理并实现了高效推断。该模型支持直接回答和推理轨迹生成，通过采用一个针对西里尔字符优化的密集 Tokenizer 以及一个经过适配的 EAGLE 推测解码流水线，有效降低了延迟。为了促进可复现和可扩展的研究，我们在 Hugging Face 上发布了模型权重、T-Wix 500k 指令数据集、T-Math 推理基准以及 EAGLE 权重。这些资源使用户能够研究俄语推理任务，并可对模型及推断流水线进行扩展或适配。一个公开的 Web 演示提供了推理模式与非推理模式，并展示了我们的推断技术栈在不同任务上所带来的加速效果。因此，T-pro 2.0 作为一个开放易用的系统，可用于构建和评估高效、实用的俄语大语言模型应用。

TwinFlow: Realizing One-step Generation on Large Models with Self-adversarial Flows
TwinFlow: 基于自对抗流的大模型一步生成方法
近期，大型多模态生成模型在图像和视频等多模态生成任务上展现出卓越能力。这些模型通常基于扩散模型和流匹配等多步框架构建，其固有的多步推理过程（通常需要 40-100 次函数评估 (NFEs)）限制了推理效率。尽管已有多种少步推理方法旨在加速，但现有方案仍存在明显不足。主流的基于蒸馏的方法，如渐进蒸馏和一致性蒸馏，要么需要迭代的蒸馏流程，要么在极低步数（< 4-NFE）下性能显著下降。同时，将对抗训练融入蒸馏过程（例如 DMD/DMD2 和 SANA-Sprint）以提升性能，会因引入额外的辅助训练模型而导致训练不稳定、复杂度增加以及高昂的 GPU 内存开销。为此，我们提出了 TwinFlow，一个用于训练一步生成模型的简洁高效框架。该框架无需依赖固定的预训练教师模型，且在训练过程中避免了使用标准的对抗网络，因而非常适合构建大规模高效模型。在文生图任务上，我们的方法仅需 1-NFE 即可获得 0.83 的 GenEval 分数，性能优于 SANA-Sprint（基于 GAN 损失的框架）和 RCGM（基于一致性的框架）等强基线。尤为重要的是，我们通过在 Qwen-Image-20B 上进行全参数训练，验证了 TwinFlow 的可扩展性，并将其成功转换为一个高效的少步生成器。仅使用 1-NFE，我们的方法在 GenEval 和 DPG-Bench 基准测试上的性能即可与原版 100-NFE 模型相媲美，在质量仅有轻微下降的同时，将计算成本降低了 100×100\times100×。项目页面见 zhenglin-cheng.com/twinflow。

StereoWorld: Geometry-Aware Monocular-to-Stereo Video Generation
StereoWorld: 几何感知的单目到立体视频生成
随着 XR 设备的日益普及，市场对高质量立体视频的需求强劲增长，但其制作过程依然成本高昂且易产生伪影。为应对这一挑战，我们提出了 StereoWorld，这是一个端到端的框架，它通过改造一个预训练的视频生成器，实现了高保真的单目到立体视频生成。我们的框架使模型能够以输入的单目视频为条件，同时利用几何感知的正则化对生成过程进行显式监督，从而确保三维结构的保真度。此外，我们还集成了一个时空分块方案，以实现高效的高分辨率视频合成。为了支持大规模训练与评估，我们构建了一个高清立体视频数据集，其中包含超过 1100 万帧视频，其内容均与自然的人类瞳孔间距离 (IPD) 对齐。大量实验表明，StereoWorld 的性能显著优于现有方法，能够生成具有卓越视觉保真度和几何一致性的立体视频。项目网页地址为 ke-xing.github.io/StereoWorld…

Beyond Real: Imaginary Extension of Rotary Position Embeddings for Long-Context LLMs
超越实数：旋转位置编码的虚数扩展及其在长上下文大语言模型中的应用
旋转位置编码 (RoPE) 通过在复平面上对查询和键向量施加旋转，已成为大语言模型 (LLMs) 中编码序列顺序的标准方案。然而，在标准的实现中，注意力分数的计算仅使用了复数值点积的实部。这种简化丢弃了包含宝贵相位信息的虚部，可能导致对建模长上下文依赖至关重要的关系细节丢失。本文提出一种扩展方法，重新纳入了这一被丢弃的虚部。我们的方法利用完整的复数值表示，构建了一个双分量的注意力分数。我们从理论和实验上证明，该方法通过保留更多的位置信息，提升了对长上下文依赖的建模能力。此外，在一系列长上下文语言建模基准测试上的评估表明，相较于标准 RoPE，我们的方法能持续提升模型性能，且随着上下文长度的增加，其优势愈发显著。代码开源地址：github.com/OpenMOSS/ro…

Preserving Source Video Realism: High-Fidelity Face Swapping for Cinematic Quality
保持源视频真实感：实现电影级质量的高保真人脸交换
视频人脸交换在电影和娱乐制作中至关重要。然而，对于长且复杂的视频序列，实现高保真度和时间一致性仍是一个重大挑战。受近期参考引导图像编辑技术进展的启发，我们探索能否类似地利用源视频中丰富的视觉属性，来同时提升视频人脸交换的保真度与时间连贯性。基于此，本文提出了首个视频参考引导的人脸交换模型——LivingSwap。我们的方法以关键帧作为条件信号，引入目标身份特征，从而实现灵活可控的编辑。通过结合关键帧条件与视频参考引导，模型能够进行时序拼接，确保在长视频序列中稳定保持身份并实现高保真重建。为了解决参考引导训练数据稀缺的问题，我们构建了一个配对的人脸交换数据集 Face2Face，并通过反转数据对来确保可靠的真值监督。大量实验表明，我们的方法取得了最先进的结果，能够将目标身份与源视频的表情、光照和运动无缝融合，同时显著减少了生产流程中的人工工作量。项目网页：aim-uofa.github.io/LivingSwap

## 每周AI论文速递（251215-251219）

Kling-Omni Technical Report
Kling-Omni 技术报告
我们提出了 Kling-Omni，一个通用的生成式框架，旨在直接从多模态视觉语言输入合成高保真视频。基于端到端的设计理念，Kling-Omni 打破了多样化视频生成、编辑和智能推理任务之间的功能壁垒，将其整合为一个统一的整体系统。与割裂的流水线方法不同，Kling-Omni 支持多种用户输入，包括文本指令、参考图像和视频上下文，并将其转化为统一的多模态表示，从而实现电影级画质和高度智能的视频内容创作。为了支撑这些能力，我们构建了一个全面的数据系统，作为多模态视频创作的基础。该框架还通过高效的大规模预训练策略和优化的推理基础设施得到进一步强化。全面的评估表明，Kling-Omni 在上下文生成、基于推理的编辑以及多模态指令遵循方面展现出卓越的性能。Kling-Omni 不仅仅是一个内容创作工具，我们相信它是迈向能够感知、推理、生成并与动态复杂世界交互的多模态世界模拟器的关键进展。

Step-GUI Technical Report
Step-GUI 技术报告
多模态大语言模型 (Multimodal Large Language Model) 的最新进展为图形用户界面 (GUI) 自动化带来了前所未有的机遇。然而，一个核心挑战依然存在：如何在保证标注可靠性的前提下，高效获取高质量的训练数据？我们提出了一种由校准步骤奖励系统 (Calibrated Step Reward System) 驱动的自演进训练流水线。该流水线通过轨迹级校准，将模型生成的操作序列转化为可靠的训练信号，从而以降低 10 至 100 倍的成本实现了超过 90% 的标注准确率。基于此流水线，我们推出了 Step-GUI 模型系列 (4B/8B 参数)。该系列模型在保持强大通用能力的同时，实现了业界领先的 GUI 性能 (8B 模型: AndroidWorld 80.2%, OSWorld 48.5%, ScreenShot-Pro 62.6%)。随着 GUI 智能体能力的增强，实际部署要求能在异构设备间提供标准化接口，并保护用户隐私。为此，我们提出了 GUI-MCP，这是首个专为 GUI 自动化设计的模型上下文协议 (Model Context Protocol)。它采用分层架构，结合了底层的原子操作与将高层任务委派给本地专家模型的能力，从而实现了高隐私保护执行——敏感数据全程保留在设备本地。最后，为了评估智能体处理真实日常使用场景的能力，我们引入了 AndroidDaily 基准测试。该测试基于真实的移动设备使用模式构建，涵盖了高频日常场景，包含 3146 个静态动作和 235 个端到端任务 (8B 模型: 静态动作准确率 89.91%, 端到端任务成功率 52.50%)。我们的工作推动了实用型 GUI 智能体的发展，并展现了其在日常数字交互中进行实际部署的巨大潜力。

MMGR: Multi-Modal Generative Reasoning
MMGR: 多模态生成式推理
视频基础模型 (Video foundation models) 能够生成视觉逼真且时序连贯的内容，但其作为世界模拟器 (world simulators) 的可靠性，取决于它们是否捕捉到了物理、逻辑和空间约束。现有指标，如弗雷歇视频距离 (Frechet Video Distance, FVD)，侧重于感知质量，却忽略了推理错误 (reasoning failures)，包括对因果关系、物理定律和全局一致性的违背。我们提出了 MMGR (多模态生成式推理评估与基准，Multi-Modal Generative Reasoning Evaluation and Benchmark)，这是一个基于五种推理能力的系统性评估框架：物理推理、逻辑推理、3D 空间推理、2D 空间推理和时序推理。MMGR 在三个领域评估生成式推理 (Generative Reasoning)：抽象推理 (Abstract Reasoning，包括 ARC-AGI 和数独)、具身导航 (Embodied Navigation，包括真实世界的 3D 导航与定位) 以及物理常识 (Physical Commonsense，包括运动和组合交互)。MMGR 采用细粒度指标，要求视频和图像生成具备整体正确性。我们对领先的视频模型 (Veo-3, Sora-2, Wan-2.2) 和图像模型 (Nano-banana, Nano-banana Pro, GPT-4o-image, Qwen-image) 进行了基准测试，结果揭示了跨领域的显著性能差距。模型在物理常识任务上取得了中等成功，但在抽象推理上表现不佳 (在 ARC-AGI 上的准确率低于 10%)，并且在具身环境中的长时程空间规划方面存在困难。我们的分析指出了当前模型的关键局限，包括过度依赖感知数据、全局状态一致性较弱，以及优化目标更倾向于奖励视觉合理性而非因果正确性。MMGR 提供了一个统一的诊断基准，并为开发具备推理意识的生成式世界模型指明了一条路径。

EgoX: Egocentric Video Generation from a Single Exocentric Video
EgoX: 从单段第三人称视频生成第一人称视频
第一人称视角感知使人类能够直接从自身视角体验和理解世界。将第三人称视角视频转换为第一人称视角视频，为沉浸式理解开辟了新途径。然而，由于相机姿态变化剧烈且视图重叠区域极小，该任务仍极具挑战性。它要求模型在忠实保留可见内容的同时，以几何一致的方式合成不可见区域。为此，我们提出了 EgoX，一个从单段第三人称输入视频生成第一人称视频的新框架。EgoX 通过轻量化的低秩适配 (LoRA) 技术，利用大规模视频扩散模型的预训练时空知识，并引入了一种统一的调节策略。该策略通过沿宽度和通道维度拼接的方式，融合了第三人称与第一人称视角先验。此外，我们提出了一种几何引导的自注意力机制，能够选择性地关注空间相关区域，从而确保了几何一致性并实现了高视觉保真度。我们的方法能够生成连贯且逼真的第一人称视角视频，并在未见过的及真实场景视频上表现出了良好的可扩展性与鲁棒性。

Memory in the Age of AI Agents
AI 智能体时代的记忆
记忆已成为基于基础模型的智能体的一项核心能力，并且这一地位将持续保持。随着智能体记忆研究的迅速扩展并吸引前所未有的关注，该领域也日益呈现出碎片化趋势。现有关于智能体记忆的研究，其动机、实现方式和评估协议往往存在显著差异，而定义松散的记忆术语的激增进一步加剧了概念上的模糊性。诸如长/短期记忆之类的传统分类法已被证明不足以涵盖当代智能体记忆系统的多样性。本文旨在勾勒当前智能体记忆研究的最新全景。我们首先明确界定智能体记忆的范畴，并将其与大语言模型记忆、检索增强生成 (RAG) 以及上下文工程等相关概念区分开来。接着，我们通过形式、功能和动态这三个统一的视角来审视智能体记忆。从形式视角，我们识别出智能体记忆的三种主要实现方式：Token 级记忆、参数化记忆和潜在记忆。从功能视角，我们提出了一个更细粒度的分类法，区分事实性记忆、经验性记忆和工作记忆。从动态视角，我们分析了记忆如何随时间形成、演化与检索。为支持实际开发，我们汇编了关于记忆基准测试和开源框架的全面总结。在整合现有成果之外，我们还阐述了对新兴研究前沿的前瞻性看法，包括记忆自动化、强化学习集成、多模态记忆、多智能体记忆以及可信度问题。我们希望本综述不仅能作为现有研究的参考，更能为将记忆重新思考为未来智能体智能设计中的一等原语提供概念基础。

QwenLong-L1.5: Post-Training Recipe for Long-Context Reasoning and Memory Management
QwenLong-L1.5: 面向长上下文推理与记忆管理的后训练方案
我们推出 QwenLong-L1.5，这是一个通过系统性后训练创新实现卓越长上下文推理能力的模型。QwenLong-L1.5 的关键技术突破如下：(1) 长上下文数据合成流水线：我们开发了一套系统性的合成框架，用于生成需要基于全局分散证据进行多跳关联的挑战性推理任务。通过将文档解构为原子事实及其底层关系，并以编程方式构建可验证的推理问题，我们的方法能够大规模生成高质量训练数据，从而实现了从简单检索任务到真正长程推理能力的实质性跨越。(2) 面向长上下文训练的稳定强化学习：为克服长上下文强化学习 (RL) 中的核心不稳定性，我们引入了结合任务特定优势估计的任务平衡采样以缓解奖励偏差，并提出了自适应熵控制策略优化 (AEPO)，动态调节探索与利用之间的权衡。(3) 面向超长上下文的记忆增强架构：我们认识到，即使扩展的上下文窗口也无法容纳任意长的序列。为此，我们开发了一个包含多阶段融合强化学习训练的记忆管理框架，该框架将单次推理与基于记忆的迭代处理无缝集成，以处理超过 4M Token 的任务。基于 Qwen3-30B-A3B-Thinking 模型，QwenLong-L1.5 在长上下文推理基准测试中取得了与 GPT-5 和 Gemini-2.5-Pro 相当的性能，平均超越其基线 9.90 分。在超长任务 (1M~4M Token) 上，QwenLong-L1.5 的记忆智能体框架相比智能体基线实现了 9.48 分的性能提升。此外，所获得的长上下文推理能力也带来了在科学推理、记忆工具使用以及扩展对话等通用领域性能的增强。

Towards Scalable Pre-training of Visual Tokenizers for Generation
面向生成任务的可扩展视觉分词器预训练
视觉分词器 (例如，VAEs) 的潜在空间质量对现代生成模型至关重要。然而，标准的基于重建的训练范式所产生的潜在空间偏向于编码低级信息，这导致了一个基础性缺陷：更高的像素级精度并不能带来更高质量的生成结果。这意味着，将大量计算资源投入到视觉分词器预训练中，难以有效转化为生成性能的提升。我们将此界定为“预训练缩放问题”，并指出必须做出转变：一个潜在空间要想对生成任务有效，就必须能简洁地表征高级语义。为此，我们提出了 VTP，一个统一的视觉分词器预训练框架，率先对图像-文本对比损失、自监督损失和重建损失进行联合优化。我们的大规模研究得出了两个主要结论：(1) 理解是生成的关键驱动力；(2) VTP 展现出优越得多的缩放特性，其生成性能能随预训练投入的计算量、参数量和数据集大小而有效提升。经过大规模预训练后，我们的分词器取得了具有竞争力的性能指标 (在 ImageNet 上达到 78.2 的零样本精度和 0.36 的 rFID) ，并且在生成任务上的收敛速度比先进的蒸馏方法快 4.1 倍。更重要的是，它具备良好的可扩展性：在不改变标准 DiT 训练配置的情况下，仅通过在预训练 VTP 时投入更多 FLOPS，就能为下游生成任务带来 65.8% 的 FID 提升；相比之下，传统自编码器仅使用其 1/10 的计算量时，性能便已早早陷入停滞。我们的预训练模型发布于 github.com/MiniMax-AI/…

ReFusion: A Diffusion Large Language Model with Parallel Autoregressive Decoding
ReFusion: 一种具有并行自回归解码能力的扩散大语言模型
自回归模型 (Autoregressive Models, ARMs) 受限于其缓慢的顺序推理速度。掩码扩散模型 (Masked Diffusion Models, MDMs) 虽提供了并行的替代方案，但也面临两个关键缺陷：一是因无法使用键值 (Key-Value, KV) 缓存而导致的高计算开销，二是在学习难以处理的 Token 组合空间上的依赖关系时，会导致生成内容不连贯。为克服这些限制，我们提出了 ReFusion，这是一种新颖的掩码扩散模型。它通过将并行解码从 Token 级别提升至更高的槽位 (slot) 级别（每个槽位是一个固定长度的连续子序列），从而实现了卓越的性能与效率。其核心是一个迭代的“规划与填充”解码过程：首先，一个基于扩散的规划步骤识别出一组弱依赖的槽位；随后，一个自回归填充步骤并行解码这些选定的槽位。这种基于槽位的设计具有双重优势：它通过一个统一的因果框架实现了完整的 KV 缓存重用，同时将学习复杂度从巨大的 Token 组合空间降低到了可管理的槽位级排列空间。在七个多样化基准上的广泛实验表明，ReFusion 不仅以 34% 的性能提升和平均超过 18 倍的加速比显著超越了先前的 MDMs，而且在保持平均 2.33 倍加速比优势的同时，弥合了与强大 ARMs 之间的性能差距。

Adaptation of Agentic AI
智能体 AI 的适配
最先进的智能体 AI (Agentic AI) 系统构建于基础模型之上，这些模型能够通过适配来进行规划、推理，并与外部工具交互，以执行日益复杂和专门化的任务。随着此类系统能力和应用范围的增长，适配已成为提升其性能、可靠性和泛化能力的核心机制。本文旨在将这一快速发展的研究领域统一为一个系统性框架，该框架同时涵盖智能体适配与工具适配。我们进一步将智能体适配分解为工具执行信号触发型和智能体输出信号触发型，将工具适配分解为智能体无关型和智能体监督型。我们论证了该框架有助于厘清智能体 AI 中各种适配策略的设计空间，明确揭示其权衡取舍，并为系统设计过程中策略的选择或切换提供实践指导。随后，我们回顾了各类别中的代表性方法，分析了其优势与局限，并着重指出了关键的开放性挑战与未来机遇。总而言之，本文旨在为致力于构建更强大、高效、可靠的智能体 AI 系统的研究人员与从业者，提供一个坚实的理论基石和清晰的实践路线图。

LongVie 2: Multimodal Controllable Ultra-Long Video World Model
LongVie 2: 多模态可控超长视频世界模型
在预训练视频生成系统基础上构建视频世界模型，是迈向通用时空智能的关键且富有挑战性的一步。一个理想的世界模型应具备三个核心特性：可控性、长期视觉质量与时间一致性。为此，我们采用了一种渐进式策略：首先提升可控性，进而扩展到长期、高质量的视频生成。本文提出了 LongVie 2，这是一个端到端的自回归框架，其训练包含三个阶段：(1) 多模态引导，通过融合密集与稀疏的控制信号，提供隐式的世界层面监督以增强可控性；(2) 输入帧的退化感知训练，旨在缩小训练与长期推理之间的差异，从而维持高视觉质量；(3) 历史上下文引导，通过对齐相邻视频片段间的上下文信息来确保时间一致性。此外，我们推出了 LongVGenBench，一个包含 100 段高分辨率、时长一分钟视频的综合评测基准，涵盖了多样化的真实世界与合成场景。大量实验证明，LongVie 2 在长程可控性、时间连贯性与视觉保真度方面均达到了最先进水平，并能支持持续生成长达五分钟的视频，这标志着我们在构建统一视频世界模型的征程上迈出了坚实的一步。

WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling
WorldPlay: 面向实时交互式世界建模的长期几何一致性
本文提出了 WorldPlay，这是一个流式视频扩散模型，能够实现具有长期几何一致性的实时交互式世界建模，从而解决了当前方法所面临的速度与内存之间的权衡问题。WorldPlay 基于三项关键创新。1) 我们采用了一种双重动作表示，以实现对用户键盘和鼠标输入的鲁棒动作控制。2) 为了确保长期一致性，我们提出的重构上下文内存能够动态地从历史帧重建上下文，并利用时间重构技术使几何上重要但历史久远的帧保持可访问性，从而有效缓解了内存衰减问题。3) 我们还提出了上下文强制，这是一种专为内存感知模型设计的新型蒸馏方法。通过对齐教师模型与学生模型之间的内存上下文，该方法保留了学生模型利用长程信息的能力，在实现实时生成速度的同时，防止了误差漂移。综上所述，WorldPlay 能够以 24 FPS 的帧率实时生成长序列的 720p 流式视频，具有卓越的一致性，其性能优于现有技术，并在多样化的场景中表现出强大的泛化能力。项目页面与在线演示请访问：3d-models.hunyuan.tencent.com/world/ 和 3d.hunyuan.tencent.com/sceneTo3D。

Video Reality Test: Can AI-Generated ASMR Videos fool VLMs and Humans?
视频真实性测试：AI 生成的 ASMR 视频能欺骗视觉语言模型和人类吗？
视频生成技术的最新进展已能产出极为生动、常与真实视频难以区分的内容，这使得 AI 生成视频检测成为一个新兴的社会挑战。现有的 AIGC (AI-Generated Content) 检测基准大多针对无音频视频进行评估，覆盖宽泛的叙事领域，且仅侧重于分类任务。然而，当前最先进的视频生成模型能否制作出沉浸式、音画同步的视频，从而可靠地欺骗人类和视觉语言模型 (Vision-Language Models, VLMs)，仍是一个悬而未决的问题。为此，我们提出了视频真实性测试 (Video Reality Test)，这是一个基于 ASMR (Autonomous Sensory Meridian Response) 源构建的视频基准套件，用于在强视听关联条件下测试感知真实性，其特点包括以下两个维度：(i) 沉浸式 ASMR 音视频源。该基准基于精心筛选的真实 ASMR 视频构建，专注于细粒度的动作-物体交互，并在物体、动作和背景方面具有多样性。(ii) 同行评审式评估。采用一种对抗性的创作者-评审者协议：视频生成模型扮演创作者，旨在欺骗评审者；而 VLMs 则扮演评审者，致力于识别虚假内容。我们的实验结果表明：表现最佳的创作者模型 Veo3.1-Fast 甚至能成功欺骗大多数 VLM 评审者：最强的评审者模型 (Gemini 2.5-Pro) 仅达到 56% 的准确率 (随机基线为 50%)，远低于人类专家 81.25% 的准确率。添加音频有助于提升真假辨别能力，但诸如水印等表面线索仍会显著误导模型。这些发现界定了当前视频生成真实性的边界，并揭示了 VLMs 在感知保真度与视听一致性方面的局限性。我们的代码可在 github.com/video-reali… 获取。

Next-Embedding Prediction Makes Strong Vision Learners
下一嵌入预测构建强大的视觉学习模型
受自然语言中生成式预训练成功的启发，我们探究同样的原理能否构建出强大的自监督视觉学习模型。我们的方法不是训练模型输出用于下游任务的特征，而是训练其生成嵌入 (embedding) 来直接执行预测任务。本工作探索了从学习表征 (representation) 到学习预测模型这一转变。具体而言，模型学习在给定历史补丁嵌入的条件下预测未来的补丁嵌入，该方法结合了因果掩码 (causal masking) 和停止梯度 (stop gradient)，我们称之为下一嵌入预测自回归 (Next-Embedding Predictive Autoregression, NEPA)。我们证明，在 ImageNet-1k 上仅以下一嵌入预测为学习目标预训练一个简单的 Transformer 模型即可取得良好效果——无需像素重建、离散 Token、对比损失或任何任务特定的头部 (head)。该方案保持了架构的简洁性和可扩展性，无需引入额外的设计复杂度。NEPA 在多项任务上表现强劲：使用 ViT-B 和 ViT-L 骨干网络进行微调后，在 ImageNet-1K 上分别达到了 83.8% 和 85.3% 的 top-1 准确率，并能有效迁移至 ADE20K 数据集的语义分割任务。我们相信，基于嵌入的生成式预训练为视觉自监督学习提供了一种简单、可扩展且可能模态无关 (modality-agnostic) 的替代方案。

LLaDA2.0: Scaling Up Diffusion Language Models to 100B
LLaDA2.0: 将扩散语言模型规模扩展至 100B 参数
本文提出了 LLaDA2.0——一系列通过系统化转换自回归 (Auto-Regressive, AR) 模型而构建的离散扩散大语言模型 (Discrete Diffusion Large Language Model, dLLM)，其总参数量扩展至 100B，从而为前沿级别的模型部署确立了新范式。LLaDA2.0 并非成本高昂的从头训练，而是遵循知识继承、渐进适应与注重效率的设计原则，并采用一种新颖的、基于三阶段块级 WSD 的训练方案，将预训练的 AR 模型无缝转换为 dLLM。该方案包括：块扩散中逐步增大块尺寸（预热阶段）、大规模全序列扩散（稳定阶段）以及回退至紧凑尺寸的块扩散（衰减阶段）。结合监督微调 (SFT) 和直接偏好优化 (DPO) 进行训练后对齐，我们得到了 LLaDA2.0-mini (16B) 和 LLaDA2.0-flash (100B)，这是两个为实际部署优化的、经过指令调优的混合专家 (Mixture-of-Experts, MoE) 变体。通过保持并行解码的优势，这些模型在达到前沿规模时，能提供卓越的性能与效率。两个模型均已开源。

Finch: Benchmarking Finance & Accounting across Spreadsheet-Centric Enterprise Workflows
Finch: 面向以电子表格为核心的企业工作流的财务与会计基准测试
我们提出了一个财务与会计基准测试 (Finch)，用于评估 AI 智能体在真实企业级专业工作流上的性能。这些工作流融合了数据录入、结构化、格式化、网络搜索、跨文件检索、计算、建模、验证、翻译、可视化及报告等多种任务。Finch 的数据源包括安然公司 (包含来自 150 名员工的 15,000 份电子表格和 50 万封电子邮件) 及其他金融机构的真实工作环境，完整保留了实际工作中跨多模态工件 (文本、表格、公式、图表、代码和图像) 的杂乱特性，并覆盖了预算、交易和资产管理等多个领域。
我们提出了一种结合大语言模型 (LLM) 辅助发现与专家标注的工作流构建方法：(1) 从真实的电子邮件线程和电子表格文件版本历史中，通过 LLM 辅助并经由专家验证来推导工作流；(2) 对工作流进行细致的专家标注，此过程耗费了超过 700 小时的领域专家工时。最终，我们构建了 172 个复合工作流，包含 384 项任务，涉及 1,710 个电子表格 (总计 2,700 万个单元格) 以及 PDF 等其他文件，从而捕捉了真实企业工作所固有的混乱性、长期性、知识密集性与协作性。
我们对包括 GPT 5.1、Claude Sonnet 4.5、Gemini 3 Pro、Grok 4 和 Qwen 3 Max 在内的前沿 AI 系统进行了人工与自动化评估。结果显示，GPT 5.1 Pro 总计耗时 48 小时，仅能通过 38.4% 的工作流，而 Claude Sonnet 4.5 的通过率仅为 25.0%。进一步的全面案例分析揭示了真实企业工作流给 AI 智能体带来的具体挑战。

## 每周AI论文速递（251222-251226）

DataFlow: An LLM-Driven Framework for Unified Data Preparation and Workflow Automation in the Era of Data-Centric AI
DataFlow: 面向以数据为中心 AI 时代的统一数据准备与工作流自动化 LLM 驱动框架
大语言模型 (LLMs) 对高质量数据的需求快速增长，这使得对可扩展、可靠且语义丰富的数据准备管道的需求变得尤为迫切。然而，当前实践仍主要依赖临时脚本和定义松散的工作流，它们缺乏原则性的抽象，阻碍了可复现性，并对模型在环 (model-in-the-loop) 的数据生成支持有限。为应对这些挑战，我们提出了 DataFlow，一个统一且可扩展的 LLM 驱动数据准备框架。DataFlow 采用系统级抽象设计，实现了模块化、可复用和可组合的数据转换，并提供了类似 PyTorch 风格的管道构建 API，用以构建可调试和可优化的数据流。该框架包含近 200 个可复用操作符和六个领域通用管道，覆盖文本、数学推理、代码、Text-to-SQL、智能体驱动的检索增强生成 (Agent RAG) 以及大规模知识提取。为进一步提升易用性，我们引入了 DataFlow-Agent，它能够通过操作符合成、管道规划和迭代验证，自动将自然语言描述转换为可执行的管道。在六个代表性用例中，DataFlow 均能一致地提升下游 LLM 性能。我们的数学、代码和文本管道性能超越了精心构建的人工数据集和专门的合成基线：在 Text-to-SQL 任务上，其执行准确率较 SynSQL 最高提升 3%；在代码基准测试上平均提升 7%；在 MATH、GSM8K 和 AIME 基准上取得了 1 到 3 个百分点的性能增益。此外，由 DataFlow 生成的统一万样本 (10K) 数据集，使得基础模型的性能超越了在百万级 (1M) Infinity-Instruct 数据上训练的同类模型。这些结果表明，DataFlow 为可靠、可复现和可扩展的 LLM 数据准备提供了一个实用且高性能的底层支持，并为未来以数据为中心的 AI 发展奠定了系统级基础。

Probing Scientific General Intelligence of LLMs with Scientist-Aligned Workflows
通过科学家工作流对齐评估大语言模型的科学通用智能
尽管科学 AI 领域取得了进展，但关于科学通用智能 (Scientific General Intelligence, SGI) —— 即自主构思、探索并跨科学领域进行推理的能力 —— 仍缺乏一个连贯的框架。我们提出了一个基于实践探究模型 (Practical Inquiry Model, PIM: 审议、构思、行动、感知) 的可操作 SGI 定义，并通过四个与科学家工作流对齐的任务来具体实现这一定义：深度研究、想法生成、干/湿实验 (dry/wet experiments) 以及实验推理。SGI-Bench 基准包含 1000 多个由专家精心策划的跨学科样本，其灵感来源于《科学》杂志提出的 125 个重大科学问题，可用于系统评估最先进的大语言模型。评估结果揭示了多方面的差距：尽管在步骤层面与人类工作流对齐，但深度研究任务的精确匹配率仍然很低 (10--20%)；生成的想法缺乏可行性和细节；干实验任务中代码可执行性高，但执行结果的准确性低；湿实验方案的步骤序列保真度低；并且在多模态比较推理方面持续面临挑战。我们进一步引入了测试时强化学习 (Test-Time Reinforcement Learning, TTRL)，该方法在模型推理阶段优化基于检索增强的新颖性奖励，从而能在不依赖参考答案的情况下提升生成假设的新颖性。综上所述，我们基于 PIM 的定义、以工作流为中心的基准测试以及实证分析，为开发能够真正推动科学发现进程的 AI 系统奠定了基础。

SemanticGen: Video Generation in Semantic Space
SemanticGen：语义空间视频生成
当前最先进的视频生成模型通常学习视频在 VAE (Variational Autoencoder) 潜在空间中的分布，并通过 VAE 解码器将其映射到像素空间。这种方法虽然能够生成高质量视频，但存在收敛速度慢的问题，并且在生成长视频时计算开销巨大。本文提出 SemanticGen，一种新颖的解决方案，通过在语义空间中进行视频生成来应对这些挑战。我们的核心观点是：由于视频本身存在固有冗余，生成过程应当始于一个紧凑的高层语义空间以进行全局规划与结构设计，随后再补充高频细节，而非直接使用双向注意力对海量的低层视频 Token 进行建模。SemanticGen 采用两阶段生成流程：第一阶段，一个扩散模型生成紧凑的语义视频特征，这些特征定义了视频的全局布局；第二阶段，另一个扩散模型以这些语义特征为条件，生成 VAE 潜在表示，进而产生最终视频输出。我们观察到，相较于在 VAE 潜在空间中生成，在语义空间中进行生成能实现更快的收敛速度。此外，我们的方法在扩展到长视频生成任务时，依然保持高效且计算成本可控。大量实验表明，SemanticGen 能够生成高质量视频，其性能优于当前最优方法和多个强基线模型。
Step-DeepResearch Technical Report
Step-DeepResearch 技术报告
随着大语言模型 (LLM) 向自主 AI 智能体 (AI Agent) 演进，深度研究 (Deep Research) 已成为一项关键的评估维度。然而，现有的学术基准（如 BrowseComp）往往难以满足现实世界对开放式探索研究的需求，这类研究需要强大的意图识别、长期决策和跨来源验证能力。为此，我们推出了 Step-DeepResearch，一个高性价比的端到端智能体。我们提出了一种基于原子化能力 (Atomic Capabilities) 的数据合成策略，用以强化任务规划和报告撰写能力，并结合了从智能体行为训练、监督微调 (SFT) 到强化学习 (RL) 的渐进式训练路径。该方法通过一个检查表式评估器 (Checklist-style Judger) 得到增强，显著提升了系统的鲁棒性。此外，为了填补中文领域在深度研究评估方面的空白，我们针对真实的深度研究场景建立了 ADR-Bench 基准。实验结果表明，Step-DeepResearch (32B) 在 Scale AI Research Rubrics 评估中取得了 61.4% 的得分。在 ADR-Bench 上，其性能显著优于同类模型，并能与 OpenAI、Gemini DeepResearch 等最先进 (SOTA) 的闭源模型相媲美。这些发现证明，通过精细化的训练，中等规模的模型能够以业界领先的性价比实现专家级的能力。

TurboDiffusion: Accelerating Video Diffusion Models by 100-200 Times
TurboDiffusion: 将视频扩散模型加速 100-200 倍
我们提出了 TurboDiffusion，这是一个视频生成加速框架，能够在保持视频质量的同时，将端到端的扩散模型生成过程加速 100 至 200 倍。TurboDiffusion 主要通过以下几个组件实现加速：(1) 注意力机制加速：TurboDiffusion 采用低比特 SageAttention 和可训练的稀疏线性注意力 (Sparse-Linear Attention, SLA) 来加速注意力计算。(2) 步数蒸馏：TurboDiffusion 使用 rCM 方法进行高效的步数蒸馏。(3) W8A8 量化：TurboDiffusion 将模型参数和激活值量化为 8 位 (W8A8)，以加速线性层运算并减少模型体积。此外，该框架还集成了其他多项工程优化技术。
我们在 Wan2.2-I2V-14B-720P、Wan2.1-T2V-1.3B-480P、Wan2.1-T2V-14B-720P 以及 Wan2.1-T2V-14B-480P 模型上进行了实验。结果表明，即使在单块 RTX 5090 GPU 上，TurboDiffusion 也能实现 100-200 倍的视频生成加速，同时生成视频的质量与原始方法相当。包含模型检查点及易于使用代码的 GitHub 仓库地址为：github.com/thu-ml/Turb…

PhysBrain: Human Egocentric Data as a Bridge from Vision Language Models to Physical Intelligence
PhysBrain: 人类自我中心数据作为从视觉语言模型到物理智能的桥梁
机器人的泛化能力依赖于物理智能：即在自我中心感知与行动条件下，对状态变化、密集接触交互以及长时程规划进行推理的能力。然而，大多数视觉语言模型主要基于第三人称数据进行训练，这为人形机器人带来了根本性的视角失配。由于成本高昂且多样性有限，扩展机器人自我中心数据的采集仍不现实；而大规模的人类自我中心视频则提供了一个可扩展的替代方案，它们天然地捕捉了丰富的交互语境与因果结构。关键挑战在于如何将原始的自我中心视频转化为结构化且可靠的具身训练监督信号。为此，我们提出了一个 Egocentric2Embodiment 转换流程，该流程将第一人称视频转化为具有强制证据基础和时序一致性的、多层次且模式驱动的视觉问答监督信号，从而能够大规模构建 Egocentric2Embodiment 数据集 (E2E-3M)。通过在 E2E-3M 数据集上进行训练，我们得到了一个具备自我中心感知能力的具身大脑，称为 PhysBrain。PhysBrain 在自我中心理解方面表现出显著提升，尤其是在 EgoThink 任务上的规划能力。它提供了一个具备自我中心感知能力的初始化状态，使得视觉语言-动作模型的微调过程样本效率更高，并在 SimplerEnv 上取得了更高的成功率 (53.9%)，这证明了从人类自我中心监督信号到下游机器人控制的有效迁移。

Robust-R1: Degradation-Aware Reasoning for Robust Visual Understanding
Robust-R1：基于退化感知推理的鲁棒视觉理解
在极端现实世界的视觉退化条件下，多模态大语言模型 (MLLM) 难以维持可靠的性能，这限制了其实际应用的鲁棒性。现有的鲁棒多模态大语言模型主要依赖于隐式训练或适应方法，这些方法仅侧重于提升视觉编码器的泛化能力，导致模型可解释性有限且优化过程相对孤立。为克服这些局限，我们提出了 Robust-R1，这是一个通过结构化推理链来显式建模视觉退化的新型框架。我们的方法整合了三个核心部分：(i) 为奠定退化感知推理基础而进行的监督微调，(ii) 为实现精准退化参数感知的奖励驱动对齐，以及 (iii) 能够适应退化强度的动态推理深度缩放。为支持此方法，我们构建了一个包含 1.1 万个样本的专用数据集，其中涵盖了在四个关键现实视觉处理阶段合成的真实退化。每个样本均标注有结构化推理链，链中连接了退化参数、感知影响、原始语义推理链及最终结论。全面的评估结果表明，Robust-R1 具备最先进的鲁棒性：它在现实世界退化基准 R-Bench 上的表现优于所有通用及鲁棒基线模型，并且在 MMMB、MMStar 和 RealWorldQA 基准上面临多强度对抗性退化时，依然保持了卓越的抗退化性能。

The Prism Hypothesis: Harmonizing Semantic and Pixel Representations via Unified Autoencoding
棱镜假说：通过统一自编码调和语义与像素表示
跨模态的深度表示本质上是相互交织的。本文中，我们系统地分析了多种语义与像素编码器的频谱特性。有趣的是，我们的研究揭示了一个极具启发性且鲜有探索的对应关系：编码器的特征频谱与其功能角色密切相关——语义编码器主要捕获编码抽象含义的低频分量，而像素编码器则额外保留了传达细粒度细节的高频信息。这一发现提供了一个统一的视角，将编码器行为与其底层频谱结构关联起来。我们将其定义为棱镜假说，即每种数据模态都可被视为自然世界在共享特征频谱上的投影，其作用类似于棱镜。基于此见解，我们提出了统一自编码 (UAE)，该模型通过一种创新的频带调制器来调和语义结构与像素细节，使二者能够无缝共存。在 ImageNet 和 MS-COCO 基准上进行的大量实验表明，我们的 UAE 能够有效地将语义抽象与像素级保真度统一到单一潜在空间中，并取得了最先进的性能。

Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies
自底向上策略优化：语言模型策略隐含内部策略
现有的强化学习 (RL) 方法将大语言模型 (LLMs) 视为单一的统一策略，忽略了其内部机制。因此，理解策略在不同层和模块间的演变过程，对于实现更具针对性的优化以及揭示复杂的推理机制至关重要。本文通过利用 Transformer 残差流的固有划分，以及隐藏状态与解嵌入矩阵的合成结果与最终可采样策略之间的等价性，对语言模型策略进行分解。这种分解揭示了内部层策略 (Internal Layer Policies)，其对应于各独立层的贡献；以及内部模块策略 (Internal Modular Policies)，其与每层中的自注意力机制和前馈网络 (FFN) 组件相关联。通过分析内部策略的熵，我们发现：(a) 早期层保持高熵以支持探索，顶层则收敛至接近零的熵以实现精细化，且收敛模式因模型系列不同而有所差异。(b) Llama 的预测空间在最后一层迅速收敛，而 Qwen 系列模型，尤其是 Qwen3，则展现出一种更接近人类、渐进结构化的推理模式。受这些发现启发，我们提出了自底向上策略优化 (Bottom-up Policy Optimization, BuPO)，这是一种新颖的 RL 范式，可在训练早期直接优化内部层策略。通过在底层对齐训练目标，BuPO 重构了基础推理能力，并取得了卓越的性能。在复杂推理基准上进行的大量实验证明了我们方法的有效性。我们的代码可在 github.com/Trae1ounG/B… 获取。

When Reasoning Meets Its Laws
当推理遇见其定律
尽管大推理模型 (Large Reasoning Models, LRMs) 性能卓越，但其推理行为常常有违直觉，导致推理能力未能达到最优。为了从理论层面形式化所期望的推理行为，本文提出了推理定律 (Laws of Reasoning, LoRe) 这一统一框架，用以刻画大推理模型内在的推理模式。我们首先提出了计算定律，其核心假设是推理计算量应与问题复杂度呈线性关系。除了计算量，我们还通过补充的准确率定律对推理定律进行了扩展。由于问题复杂度在实践中难以量化，我们借助该定律的两个可检验属性——单调性与组合性——来验证这些假设。为此，我们引入了 LoRe-Bench 基准测试，用于系统性地评估大推理模型的这两个可处理属性。评估结果表明，大多数推理模型具备合理的单调性，但缺乏组合性。针对此问题，我们开发了一种有效的微调方法，以强制模型满足计算定律的组合性要求。大量的实证研究表明，更好地遵循计算定律能够在多个基准测试上持续提升模型的推理性能，并揭示出不同属性与定律之间的协同效应。项目页面：lore-project.github.io/

Latent Implicit Visual Reasoning
潜在隐式视觉推理
尽管大型多模态模型（LMMs）已取得显著进展，但其本质上仍以文本为中心，将语言作为核心推理模态。因此，它们在处理以视觉为主的推理任务时能力有限。近期的一些方法尝试通过利用辅助图像、深度图或图像裁剪来监督中间视觉步骤，以解决此问题。然而，这些策略为“有用”的视觉抽象形态设定了限制性先验，带来了高昂的标注成本，且跨任务泛化能力较差。为克服这一关键局限，我们提出了一种任务无关的机制，它能训练 LMMs 自主发现并利用视觉推理标记，而无需任何显式监督。这些标记具有全局注意力，并能以任务自适应的方式对图像进行重新编码，从而使模型能够提取相关的视觉信息，无需依赖人工设计的监督信号。我们的方法性能优于直接微调，在多种视觉中心任务上——包括那些中间抽象难以明确定义的任务——均取得了最先进的成果，同时也能很好地泛化至多任务指令微调场景。

LongVideoAgent: 基于多智能体的长视频推理
LongVideoAgent: 基于多智能体的长视频推理
多模态大语言模型以及利用工具进行长视频问答的系统所取得的进展，展现了处理长达数小时视频内容并进行推理的潜力。然而，现有方法大多仍将视频内容压缩为有损摘要，或依赖于功能有限的工具集，这导致时间定位能力被削弱，且容易遗漏细粒度线索。为此，我们提出一个多智能体框架：一个主控大语言模型负责协调一个定位智能体来锁定与问题相关的视频片段，以及一个视觉智能体来提取有针对性的文本化视觉观察。主控智能体在预设的步骤限制内进行规划，并通过强化学习进行训练，旨在实现简洁、准确且高效的多智能体协作。该设计通过定位机制使主控智能体能专注于相关片段，利用视觉细节补充字幕信息，并生成可解释的推理轨迹。在我们新提出的 LongTVQA 和 LongTVQA+ 数据集（这两个剧集级数据集由 TVQA/TVQA+ 聚合而成）上，我们的多智能体系统性能显著优于多个强大的非智能体基线模型。实验还表明，强化学习能进一步强化已训练智能体的推理与规划能力。代码与数据将在 longvideoagent.github.io/ 发布。

Region-Constraint In-Context Generation for Instructional Video Editing
面向教学视频编辑的区域约束上下文生成
上下文生成 (In-context generation) 范式近期在教学图像编辑领域展现出强大能力，兼具数据高效性与合成高质量的特点。然而，将这种上下文学习应用于基于指令的视频编辑并非易事。若不指定编辑区域，结果可能出现编辑区域不准确，以及在去噪过程中编辑区域与非编辑区域之间发生 Token 干扰的问题。为解决这些问题，我们提出了 ReCo，一种新的教学视频编辑范式，其创新之处在于深入探究了上下文生成过程中编辑区域与非编辑区域之间的约束建模。技术上，ReCo 将源视频与目标视频沿空间（宽度）维度拼接，进行联合去噪。为校准视频扩散学习，ReCo 利用了两项正则化项：潜在正则化与注意力正则化，它们分别作用于单步反向扩散去噪后的潜在表示 (latents) 和注意力图 (attention maps)。潜在正则化旨在增大源视频与目标视频之间编辑区域的潜在差异，同时减小非编辑区域的差异，从而强化对编辑区域的修改，并抑制非编辑区域意外内容的生成。注意力正则化则抑制目标视频编辑区域中的 Token 对源视频对应区域 Token 的注意力，以此减轻目标视频生成新对象时来自源视频对应 Token 的干扰。此外，我们提出了一个大规模高质量的视频编辑数据集 ReCo-Data，包含 50 万对指令-视频样本，以支持模型训练。在四项主流基于指令的视频编辑任务上进行的大量实验，验证了我们所提方案的优越性。

Seed-Prover 1.5: Mastering Undergraduate-Level Theorem Proving via Learning from Experience
Seed-Prover 1.5：通过经验学习精通本科级定理证明
近期，大语言模型 (LLM) 在生成严谨数学证明方面取得了重大进展。然而，利用大语言模型在形式化语言 (如 Lean) 中进行定理证明仍然面临挑战且计算开销巨大，尤其是在处理本科及以上难度的问题时。本文提出了 Seed-Prover 1.5，这是一个通过大规模智能体强化学习训练的形式化定理证明模型，并配套一个高效的测试时扩展工作流。该模型在强化学习过程中，通过与 Lean 等工具进行广泛交互，持续积累经验，从而显著提升了形式化定理证明的能力与效率。此外，结合自然语言证明领域的最新进展，我们的测试时扩展工作流有效弥合了自然语言与形式化语言之间的鸿沟。与现有最先进方法相比，Seed-Prover 1.5 在更小的计算预算下实现了更优的性能：它解决了 88% 的 PutnamBench (本科级)、80% 的 Fate-H (研究生级) 以及 33% 的 Fate-X (博士级) 问题。尤为突出的是，利用本系统，我们在 9 小时内解决了 2025 年普特南数学竞赛 12 道题目中的 11 道。我们的研究表明，由高质量形式化反馈驱动的经验学习规模化扩展，在形式化数学推理领域拥有巨大的发展潜力。

Learning to Reason in 4D: Dynamic Spatial Understanding for Vision Language Models
学习进行 4D 推理：视觉语言模型的动态空间理解
视觉语言模型 (VLM) 在通用理解任务上表现出色，但在动态空间推理 (DSR) 方面仍显薄弱。DSR 指的是对物体几何形状及其在三维空间中随时间演变的关系进行推理。这种薄弱主要归因于可扩展的 4D 感知训练资源匮乏。为弥合在数据集、基准和模型方面的这一差距，我们推出了 DSR 套件。首先，我们提出一种自动化流水线，能够从真实场景视频中为 DSR 任务生成多项选择题对。该流水线利用现代视觉基础模型，提取丰富的几何与运动信息，包括相机位姿、局部点云、物体掩膜、朝向以及三维轨迹。这些几何线索可用于构建用于模型训练的 DSR-Train 数据集，以及经过人工进一步精炼、用于评估的 DSR-Bench 基准。与先前研究相比，我们的数据强调以下特性：(i) 源自真实场景视频，(ii) 具备物体级和场景级的三维信息要求，(iii) 包含视点变换，(iv) 涉及多物体交互，以及 (v) 提供细粒度、分步骤的答案。除了数据贡献，我们还提出一个轻量级的几何选择模块 (GSM)，用于将几何先验无缝集成到 VLM 中。该模块能压缩问题语义，并从预训练的 4D 重建先验中提取与问题相关的知识，将其编码为一组紧凑的几何 token。这种有针对性的知识提取避免了无关知识对模型的干扰。实验表明，将 DSR-Train 和 GSM 集成到 Qwen2.5-VL-7B 模型中，能显著提升其动态空间推理能力，同时保持了在通用视频理解基准上的准确率。

## 每周AI论文速递（251229-260102）

mHC: Manifold-Constrained Hyper-Connections
mHC: 流形约束的超连接

近来，以超连接 (HC) 为代表的研究，通过扩展残差流宽度并多样化连接模式，对过去十年间确立的、普遍存在的残差连接范式进行了拓展。尽管这带来了显著的性能提升，但连接模式的多样化从根本上损害了残差连接固有的恒等映射特性，进而导致严重的训练不稳定性、受限的可扩展性，并产生了显著的内存访问开销。为应对这些挑战，我们提出了流形约束的超连接 (mHC)。这是一个通用框架，它将 HC 的残差连接空间投影到特定流形上，以恢复恒等映射特性，同时融合了严格的基础设施优化以确保效率。实证实验表明，mHC 能有效进行大规模训练，带来切实的性能提升与卓越的可扩展性。我们预计，mHC 作为 HC 的一种灵活且实用的扩展，将有助于更深入地理解拓扑架构设计，并为基础模型的演进提供有前景的方向。

Mindscape-Aware Retrieval Augmented Generation for Improved Long Context Understanding
用于改进长上下文理解的 Mindscape-Aware 检索增强生成

人类理解长而复杂的文本，依赖于对内容的整体语义表征。这种全局视角有助于组织先验知识、解释新信息，并整合分散在文档中的证据，这正体现了心理学中所揭示的人类 Mindscape-Aware（心智景观感知）能力。当前的检索增强生成 (RAG) 系统缺乏这种指导，因此在处理长上下文任务时面临困难。本文提出了 Mindscape-Aware RAG (MiA-RAG)，这是首个为基于大语言模型的 RAG 系统赋予显式全局上下文感知能力的方法。MiA-RAG 通过分层摘要构建一个全局语义表征（即心智景观），并以此为基础指导检索和生成过程。这使得检索器能够形成信息更丰富的查询嵌入，同时使生成器能够在连贯的全局上下文中对检索到的证据进行推理。我们在多种长上下文和双语基准测试上评估了 MiA-RAG 在基于证据的理解和全局语义整合方面的性能。结果表明，MiA-RAG consistently surpasses baselines, and further analysis shows that it aligns local details with a coherent global representation, enabling more human-like long-context retrieval and reasoning.

InsertAnywhere: Bridging 4D Scene Geometry and Diffusion Models for Realistic Video Object Insertion
InsertAnywhere: 融合4D场景几何与扩散模型以实现逼真的视频对象插入

基于扩散模型的视频生成技术近期取得了显著进展，为可控视频编辑带来了新的可能。然而，由于对4D场景的理解有限，以及对遮挡和光照效应的处理不足，实现逼真的视频对象插入 (VOI) 仍然面临挑战。本文提出了 InsertAnywhere，这是一个新的 VOI 框架，能够实现几何一致的对象放置和外观忠实的视频合成。我们的方法首先采用一个4D感知的掩码生成模块，该模块重建场景几何，并在视频帧间传播用户指定的对象位置，同时确保时间连贯性和遮挡一致性。在此空间基础之上，我们扩展了一个基于扩散的视频生成模型，以联合合成插入的对象及其周围的局部变化（如光照和阴影）。为了进行有监督训练，我们引入了 ROSE++，这是一个光照感知的合成数据集，通过将 ROSE 对象移除数据集转换为三元组（包含对象移除后的视频、对象存在时的视频以及由 VLM 生成的参考图像）而构建。大量实验表明，我们的框架能够在多样化的真实世界场景中生成几何合理且视觉连贯的对象插入效果，其性能显著优于现有的研究模型和商业模型。

Coupling Experts and Routers in Mixture-of-Experts via an Auxiliary Loss
通过辅助损失耦合混合专家模型中的专家与路由器

混合专家 (Mixture-of-Experts, MoE) 模型缺乏明确的约束来确保路由器的决策与专家的能力良好匹配，这最终会限制模型性能。为解决此问题，我们提出了专家-路由器耦合 (expert-router coupling, ERC) 损失，这是一种轻量级辅助损失，旨在将路由器的决策与专家能力紧密耦合。我们的方法将每个专家的路由器嵌入 (router embedding) 视为分配给该专家的 Token 的代理 Token (proxy token)，并将扰动后的路由器嵌入输入专家以获取其内部激活 (internal activations)。ERC 损失对这些激活施加了两项约束：(1) 每个专家对其自身代理 Token 的激活必须高于对其他任何专家代理 Token 的激活。(2) 每个代理 Token 在其对应专家处激发的激活必须强于在其他任何专家处激发的激活。这些约束共同作用，确保每个路由器嵌入能准确表征其对应专家的能力，同时使每个专家专注于处理实际被路由至它的 Token。ERC 损失计算高效，仅需处理 n^2 个激活（n 为专家数量）。这意味着一个与批次大小无关的固定开销，不同于先前那些计算成本随 Token 数量（通常每批次达数百万）增长的耦合方法。通过对参数量从 30亿到 150亿的 MoE-LLMs 进行预训练，并基于数万亿 Token 进行广泛分析，我们验证了 ERC 损失的有效性。此外，ERC 损失还能在训练过程中对专家的专业化程度进行灵活控制和定量追踪，从而为理解 MoE 模型提供了宝贵洞见。

Youtu-LLM: Unlocking the Native Agentic Potential for Lightweight Large Language Models
Youtu-LLM: 释放轻量级大语言模型的原生智能体潜力

我们推出 Youtu-LLM，这是一个轻量级但功能强大的语言模型，它成功兼顾了高计算效率与原生智能体智能。与通常依赖知识蒸馏的小型模型不同，Youtu-LLM (1.96B) 采用从头预训练的方式，旨在系统性地发展其推理与规划能力。其关键技术进展如下：(1) 支持长上下文的紧凑架构：该模型基于密集的多潜在注意力 (MLA) 架构和一种新颖的 STEM 导向词汇表构建，支持长达 128k 的上下文窗口。这一设计使其能够在极小的内存开销下实现稳健的长上下文推理与状态追踪，非常适合长程智能体任务和推理任务。(2) 结构化的 "常识-STEM-智能体" 课程学习：我们构建了一个约 11T token 的大规模语料库，并采用多阶段训练策略。通过逐步将预训练数据的分布从通用常识转向复杂的 STEM 及智能体任务，我们确保模型获得的是深层的认知能力，而非浅层的任务对齐。(3) 可扩展的智能体中期训练：针对智能体中期训练，我们采用了多样化的数据构建方案，在数学、代码和工具使用等领域合成了丰富多样的行动轨迹。这些高质量数据使模型能够有效地内化规划与反思行为。广泛的评估表明，Youtu-LLM 为参数量小于 20 亿的大语言模型树立了新的性能标杆。在通用基准测试中，其性能可与更大的模型相媲美；而在智能体专项任务上，它则显著超越了现有的 SOTA 基线模型，这证明轻量级模型同样可以具备强大的内在智能体能力。

Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling
基于超图记忆改进多步 RAG 以进行长上下文复杂关系建模

多步检索增强生成 (RAG) 已成为一项广泛采用的策略，用于增强大语言模型 (LLM) 在需要全局理解和深度推理任务上的性能。许多 RAG 系统集成了工作记忆模块以整合检索到的信息。然而，现有的记忆设计主要充当被动存储器，仅用于积累孤立的事实，以压缩冗长输入并通过演绎生成新的子查询。这种静态特性忽略了原始事实间关键的高阶关联，而这些事实的组合往往能为后续步骤提供更强的指导。因此，其表示能力以及对多步推理和知识演进的影响有限，导致在长上下文处理中出现推理碎片化和全局理解能力薄弱的问题。我们提出了 HGMem，一种基于超图的记忆机制，它将记忆的概念从简单的存储扩展为一种动态、富有表现力的结构，以支持复杂推理和全局理解。在我们的方法中，记忆被表示为一个超图，其超边对应不同的记忆单元，从而能够在记忆内部逐步形成高阶交互。该机制围绕核心问题连接事实与思路，演进为一个一体化、情境化的知识结构，为后续步骤的深度推理提供有力支撑。我们在多个专为测试全局理解能力设计的挑战性数据集上评估了 HGMem。大量实验和深入分析表明，我们的方法能持续提升多步 RAG 的性能，并在多种任务上显著优于各强基线系统。

LiveTalk: Real-Time Multimodal Interactive Video Diffusion via Improved On-Policy Distillation
LiveTalk: 通过改进的同策略蒸馏实现实时多模态交互式视频扩散

利用扩散模型进行实时视频生成，对于构建通用多模态交互式 AI 系统至关重要。然而，扩散模型通过迭代过程、结合双向注意力对所有视频帧进行同步去噪，这阻碍了实时交互。虽然现有的蒸馏方法可以使模型具备自回归特性并减少采样步数以缓解此问题，但这些方法主要集中于文生视频任务，导致人机交互显得不自然且效率低下。本文旨在实现一种基于多模态上下文（包括文本、图像和音频）的实时交互式视频扩散模型，以弥合这一差距。我们观察到，领先的同策略蒸馏方法 Self Forcing 在多模态条件输入下会面临挑战（出现闪烁、黑帧和质量下降等视觉伪影）。为此，我们研究了一种改进的蒸馏方案，该方案着重优化条件输入的质量，以及同策略优化的初始化和调度策略。在 HDTF、AVSpeech 和 CelebV-HQ 等多模态条件（音频、图像和文本）驱动的虚拟形象视频生成基准测试中，我们蒸馏得到的模型，在推理成本和延迟降低 20 倍的前提下，其视觉质量与相似或更大规模的全步长双向基线模型相当。此外，我们将该模型与音频语言模型以及长视频推理技术 Anchor-Heavy Identity Sinks 相结合，构建了 LiveTalk——一个实时多模态交互式虚拟形象系统。在我们精心构建的多轮交互基准上进行的系统级评估显示，LiveTalk 在多轮视频连贯性和内容质量方面均优于 Sora2、Veo3 等最先进的模型，同时将响应延迟从 1-2 分钟大幅降低至实时生成水平，从而实现了流畅无缝的人机多模态交互。

Yume-1.5: A Text-Controlled Interactive World Generation Model
Yume-1.5: 一个文本控制的交互式世界生成模型

近期的一些方法展现了利用扩散模型生成交互式、可探索世界的潜力。然而，这些方法大多面临关键挑战，例如参数量过大、依赖冗长的推理步骤以及历史上下文快速增长，这些问题严重限制了实时性能，并且缺乏文本控制生成能力。为解决这些挑战，我们提出了 \method，这是一个新颖的框架，用于从单张图像或文本提示生成逼真、交互且连续的世界。\method 通过一个精心设计的框架实现此目标，该框架支持基于键盘对生成的世界进行探索。该框架包含三个核心组件：(1) 一个集成了统一上下文压缩与线性注意力的长视频生成框架；(2) 一个由双向注意力蒸馏和增强文本嵌入方案驱动的实时流式加速策略；(3) 一种用于生成世界事件的文本控制方法。相关代码库已提供在补充材料中。

Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem
任其流动：基于 ROCK 与 ROLL 的智能体式构建，在开放智能体学习生态系统中打造 ROME 模型

智能体式构建 (Agentic crafting) 要求大语言模型 (LLM) 在现实环境中通过多轮操作来执行任务，具体包括采取行动、观察结果并迭代优化其生成的制品。尽管该能力至关重要，但开源社区目前仍缺乏一个系统化、端到端的生态系统来简化智能体的开发流程。为此，我们提出了智能体学习生态系统 (Agentic Learning Ecosystem, ALE)，这是一个旨在优化智能体大语言模型生产流水线的基础设施。ALE 包含三个核心组件：ROLL，一个用于权重优化的后训练 (post-training) 框架；ROCK，一个用于生成训练轨迹的沙盒环境管理器；以及 iFlow CLI，一个用于高效上下文工程 (context engineering) 的智能体框架。我们发布了 ROME (ROME is Obviously an Agentic Model)，这是一个基于 ALE 构建、并在超过一百万条轨迹上训练而成的开源智能体模型。我们的方法包含用于合成复杂行为的数据组合协议 (data composition protocols)，以及一种新颖的策略优化算法——基于交互的策略对齐 (Interaction-based Policy Alignment, IPA)。IPA 算法在语义交互块而非单个 Token 上分配信用，从而提升了长视野 (long-horizon) 训练的稳定性。在实证评估中，我们在一个结构化设置中对 ROME 进行了测试，并推出了 Terminal Bench Pro 基准测试，该基准在规模和污染控制方面均有改进。ROME 在 SWE-bench Verified 和 Terminal Bench 等多个基准测试中均展现出强劲性能，这证明了 ALE 基础设施的有效性。

## 每周AI论文速递（260105-260109）

GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization
GDPO: 面向多奖励RL优化的组奖励解耦归一化策略优化
随着语言模型能力日益增强，用户不仅期望其提供准确的响应，还希望它们能在多样化的场景中表现出符合不同人类偏好的行为。为此，强化学习 (RL) 训练框架已开始整合多个奖励信号，每个奖励对应一种特定偏好，以引导模型产生这些期望行为。然而，近期研究默认在多奖励设置下直接采用组相对策略优化 (GRPO)，而未深入探究其适用性。本文证明，直接应用GRPO对不同rollout奖励组合进行归一化，会导致这些组合的优势值坍缩为相同数值，从而降低训练信号的分辨率，导致收敛结果次优，甚至在部分情况下引发早期训练失败。为此，我们提出了组奖励解耦归一化策略优化 (GDPO)。这一新策略优化方法通过解耦各奖励的归一化过程，解决了上述问题，能更真实地保留奖励间的相对差异，从而实现更精确的多奖励优化，并大幅提升训练稳定性。我们在工具调用、数学推理和代码推理三个任务上对比了GDPO与GRPO，评估了包括正确性指标（准确率、错误率）和约束遵循指标（格式、长度）。在所有实验设置下，GDPO均一致优于GRPO，证明了其在多奖励强化学习优化中的有效性和泛化能力。

NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos
NeoVerse: 利用真实世界单目视频增强 4D 世界模型
本文提出 NeoVerse，一个多功能 4D 世界模型，能够执行 4D 重建、新视角轨迹视频生成以及丰富的下游任务。我们首先指出，当前 4D 世界建模方法普遍存在可扩展性局限，其根源在于依赖昂贵且专用的多视图 4D 数据，或训练预处理流程繁琐。相比之下，NeoVerse 基于一个核心设计理念，使得整个流程能够轻松扩展至多样化的真实世界单目视频。具体而言，NeoVerse 具备免姿态前馈 4D 重建、在线单目退化模式模拟以及其他协调一致的技术。这些设计使 NeoVerse 具备了多功能性以及对多种领域的泛化能力。同时，NeoVerse 在标准重建与生成基准测试中取得了最先进的性能。项目页面详见 neoverse-4d.github.io。

Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization
Youtu-Agent: 通过自动化生成与混合策略优化提升智能体生产力
现有的大语言模型 (LLM) 智能体框架面临两大挑战：配置成本高昂与能力固化。构建高质量智能体通常需要在工具集成和提示工程上投入大量人工，而已部署的智能体若不进行代价高昂的微调，则难以适应动态环境。为解决这些问题，我们提出了 Youtu-Agent，这是一个专为 LLM 智能体自动化生成与持续进化设计的模块化框架。Youtu-Agent 具备结构化配置系统，实现了执行环境、工具包与上下文管理的解耦，从而支持灵活复用与自动化组装。我们引入了两种生成范式：面向标准任务的 工作流 模式，以及面向复杂、非规范化需求的 元智能体 模式，后者能够自动生成工具代码、提示词及配置。此外，Youtu-Agent 构建了一套混合策略优化系统：(1) 智能体实践 模块，使智能体能够通过上下文内优化积累经验、提升性能，且无需更新模型参数；(2) 智能体强化学习 模块，可与分布式训练框架集成，支持以端到端、大规模的方式对任意 Youtu-Agent 进行可扩展且稳定的强化学习。实验表明，使用开源权重模型时，Youtu-Agent 在 WebWalkerQA (71.47%) 和 GAIA (72.8%) 基准上取得了领先性能。我们的自动化生成流程工具合成成功率超过 81%，而实践模块在 AIME 2024 和 2025 上分别将性能提升了 2.7% 和 5.4%。此外，我们的智能体强化学习训练在 7B 参数规模的 LLM 上实现了 40% 的加速，同时性能持续稳定提升，在数学及通用/多跳问答基准测试中，编码/推理与搜索能力分别最高提升了 35% 和 21%。

InfiniDepth: Arbitrary-Resolution and Fine-Grained Depth Estimation with Neural Implicit Fields
InfiniDepth: 基于神经隐式场的任意分辨率细粒度深度估计
现有的深度估计方法本质上受限于在离散的图像网格上预测深度。这种表示形式限制了其向任意输出分辨率的扩展能力，并影响了几何细节的还原。本文提出了 InfiniDepth，该方法将深度表示为神经隐式场。通过一个简单而有效的局部隐式解码器，我们可以在连续的二维坐标处查询深度值，从而实现任意分辨率下的细粒度深度估计。为了更全面地评估本方法的性能，我们从五款不同的游戏中构建了一个高质量的 4K 合成基准数据集，该数据集涵盖了具有丰富几何与外观细节的多样化场景。大量实验表明，无论是在合成数据还是真实世界数据的基准测试上，InfiniDepth 在相对深度估计和度量深度估计任务中均达到了最先进的性能，尤其在精细细节区域的表现尤为突出。此外，该方法也能显著提升大视角变化下新视图合成任务的效果，所生成的结果质量更高，且空洞和伪影更少。

LTX-2: Efficient Joint Audio-Visual Foundation Model
LTX-2: 高效的联合视听基础模型
当前的文本到视频扩散模型虽能生成高质量的视频序列，但通常是无声的，缺乏音频所能提供的语义、情感及氛围线索。为此，我们提出了 LTX-2，这是一个开源的基础模型，能够以统一的方式生成高质量且时间同步的视听内容。LTX-2 采用非对称双流 Transformer 架构，其中视频流包含 140 亿参数，音频流包含 50 亿参数。两个流通过双向视听交叉注意力层进行耦合，该层包含时间位置嵌入以及用于共享时间步条件化的跨模态 AdaLN。此架构不仅实现了统一视听模型的高效训练与推理，还为视频生成分配了比音频生成更多的模型容量。
我们采用了多语言文本编码器，以支持对更广泛提示词的理解，并引入了一种模态感知的无分类器引导机制，从而提升了视听对齐效果与可控性。除了生成语音，LTX-2 还能生成丰富、连贯的音频轨道，这些音频能够贴合每个场景的角色、环境、风格与情感，并包含自然的背景音和拟音效果。在我们的评估中，该模型在开源系统中实现了最先进的视听质量与提示跟随性，同时仅需专有模型一小部分的计算成本和推理时间，便能达到与之相当的效果。所有模型权重和代码均已开源发布。

Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting
熵自适应微调：解决自信冲突以缓解遗忘
监督微调 (Supervised Fine-Tuning, SFT) 是领域适应的标准范式，但它常常以灾难性遗忘为代价。与此形成鲜明对比的是，基于策略的强化学习 (Reinforcement Learning, RL) 能有效保留模型的通用能力。我们探究了这种差异，并发现了一个根本性的分布不匹配问题：RL 与模型的内在信念保持一致，而 SFT 则迫使模型拟合外部监督信号。这种不匹配通常表现为一种"自信冲突" (Confident Conflicts) 的 Token，其特征是预测概率低但熵值也低。在这种情况下，模型对其自身预测高度自信，却被迫学习与之相悖的真实标签，从而引发破坏性的梯度更新。为解决此问题，我们提出了熵自适应微调 (Entropy-Adaptive Fine-Tuning, EAFT)。与仅依赖预测概率的方法不同，EAFT 利用 Token 级别的熵作为门控机制，以区分认知不确定性和知识冲突。这使得模型能够从不确定的样本中学习，同时抑制来自冲突数据的梯度。我们在数学、医学和 AI 智能体领域，对 Qwen 和 GLM 系列模型 (参数规模从 4B 到 32B) 进行了广泛实验，结果证实了我们的假设。EAFT 在始终达到与标准 SFT 相当的下游任务性能的同时，显著缓解了通用能力的衰退。

K-EXAONE Technical Report
K-EXAONE 技术报告
本技术报告介绍了 K-EXAONE，这是一个由 LG AI Research 开发的大规模多语言大语言模型。K-EXAONE 基于专家混合 (Mixture-of-Experts, MoE) 架构构建，总参数量为 236B，推理时激活参数量为 23B。它支持 256K Token 的上下文窗口，并涵盖六种语言：韩语、英语、西班牙语、德语、日语和越南语。我们在一个涵盖推理、智能体能力、通用能力、韩语能力及多语言能力的综合基准测试套件上对 K-EXAONE 进行了评估。在这些评估中，K-EXAONE 展现出了与同类规模的开源模型相当的性能。K-EXAONE 旨在通过推进人工智能技术来创造更美好的生活，其定位是一个强大的闭源 AI 基础模型，适用于广泛的工业与科研应用。

Evolving Programmatic Skill Networks
演化式程序化技能网络
我们研究在开放域具身环境中持续的技能获取问题，智能体需要构建、优化并重用其不断增长的可执行技能库。我们提出了程序化技能网络（PSN），该框架中的技能是可执行的符号程序，它们构成一个组合网络，并通过经验不断演化。PSN 定义了三个由大语言模型实例化的核心机制：(1) 用于对技能组合进行结构化故障定位的 REFLECT，(2) 具备成熟度感知更新门控的渐进式优化，该机制能稳定可靠技能，同时为不确定技能保持可塑性，以及 (3) 在回滚验证下的规范结构重构，以维持网络紧凑性。我们进一步指出，PSN 的学习动态在结构上与神经网络训练存在相似性。在 MineDojo 和 Crafter 环境上的实验表明，该方法在开放域任务分布上具有强大的技能重用能力、快速适应能力和优异的泛化性能。\footnote{我们计划开源代码。

Can LLMs Predict Their Own Failures? Self-Awareness via Internal Circuits
大语言模型能预测自身的失败吗？基于内部路径的自我感知
大语言模型 (LLMs) 能够生成流畅且复杂的输出，但常常无法识别自身的错误和幻觉。现有方法通常依赖于外部评判器、多样本一致性或基于文本的自我批判，这些方法要么会产生额外的计算开销，要么与真实正确性的关联较弱。我们探讨一个问题：大语言模型能否通过检查推理过程中的内部状态来预测自身的失败？我们提出了 Gnosis，一种轻量级的自我感知机制，它使参数冻结的 LLMs 能够通过解码其隐藏状态和注意力模式的信号，进行内在的自我验证。Gnosis 被动地观察内部轨迹，将其压缩为固定资源占用的描述符，并以极低的推理开销预测正确性，仅增加约 500 万个参数，且其运行与序列长度无关。在数学推理、开放域问答和学术知识基准测试中，在参数规模从 17 亿到 200 亿不等的多个冻结骨干模型上，Gnosis 在准确性和校准度方面均持续优于性能强劲的内部基线模型和规模庞大的外部评判器。此外，它能够零样本泛化到部分（不完整）的生成结果，从而实现对失败生成路径的早期检测，并进行计算感知的控制。这些结果表明，可靠的正确性线索本就存在于生成过程之中，无需外部监督即可高效提取。

NextFlow: Unified Sequential Modeling Activates Multimodal Understanding and Generation
NextFlow: 统一序列建模赋能多模态理解与生成
我们提出了 NextFlow，这是一个统一的仅解码器自回归 Transformer 模型，在 6 万亿交织的文本-图像离散 Token 上训练而成。通过在统一的自回归架构内利用统一的视觉表示，NextFlow 原生具备了多模态理解与生成能力，实现了图像编辑、交织内容生成以及视频生成等功能。鉴于不同模态的本质差异——文本具有严格的顺序性，而图像则具有内在的层次性——我们为文本保留了下一 Token 预测，但对视觉生成采用了下一尺度预测。这有别于传统的光栅扫描方法，使得生成 1024x1024 分辨率图像仅需 5 秒，比同类自回归 (AR) 模型快数个数量级。我们通过一套稳健的训练方案解决了多尺度生成的不稳定性问题。此外，我们还引入了一种用于强化学习的前缀调优 (prefix-tuning) 策略。实验表明，NextFlow 在统一模型中取得了最先进的性能，并且在视觉质量上可与专门的扩散 (diffusion) 基线模型相匹敌。

MOSS Transcribe Diarize: Accurate Transcription with Speaker Diarization
MOSS Transcribe Diarize: 带说话人角色分离的精准转录
带说话人角色和时间戳的转录 (Speaker-Attributed, Time-Stamped Transcription, SATS) 旨在转录语音内容，并精确确定每位说话人的发言时间点，这对于会议转录尤其有价值。现有的 SATS 系统很少采用端到端方案，并且普遍存在上下文窗口有限、长距离说话人记忆能力弱以及无法输出时间戳等局限。为了克服这些不足，我们提出了 MOSS Transcribe Diarize，这是一个统一的多模态大语言模型，能够以端到端的方式联合完成带说话人角色和时间戳的转录。该模型在大量真实场景数据上进行训练，并配备了可处理长达 90 分钟音频输入的 128k 上下文窗口，因此具有良好的可扩展性和强大的泛化能力。在全面的评估中，它在多个公开及内部基准测试上的表现均优于当前最先进的商业系统。

Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation
Avatar Forcing：面向自然对话的实时交互式头部数字人生成
说话头生成技术旨在从静态肖像中创建逼真的数字人 (Avatar) ，以用于虚拟交流与内容创作。然而，现有模型尚无法营造出真正交互式交流的体验，其生成的响应往往是单向的，缺乏情感参与感。我们为实现真正交互式的数字人，识别出两个关键挑战：一是在因果约束条件下实时生成运动；二是在无需额外标注数据的情况下，学习富有表现力且鲜活自然的反应。为应对这些挑战，我们提出了 Avatar Forcing，这是一个用于交互式头部数字人生成的新框架，它通过扩散驱动 (Diffusion Forcing) 对实时用户-数字人交互进行建模。该设计使得数字人能够以低延迟处理实时多模态输入（包括用户的音频和动作），从而对语音、点头、笑声等言语与非言语线索做出即时反应。此外，我们引入了一种直接偏好优化方法，该方法利用通过丢弃用户条件构建的合成负样本，实现了对富有表现力交互的无标签学习。实验结果表明，我们的框架能够实现低延迟（约500毫秒）的实时交互，相比基线模型获得了6.8倍的加速，并生成了反应灵敏且富有表现力的数字人运动，在超过80%的评估中优于基线模型。

Taming Hallucinations: Boosting MLLMs' Video Understanding via Counterfactual Video Generation
抑制幻觉：通过反事实视频生成增强 MLLMs 的视频理解能力
多模态大语言模型 (Multimodal Large Language Models, MLLMs) 在视频理解方面取得了显著进展。然而，它们存在一个关键缺陷：过度依赖语言先验，这可能导致视觉上无根据的幻觉，尤其是在处理违背常识的反事实视频时。这一局限源于文本与视频之间固有的数据不平衡，而由于收集和标注反事实数据成本高昂，该问题难以解决。为此，我们提出了 DualityForge，一个新颖的反事实数据合成框架。该框架利用可控的、基于扩散模型的视频编辑技术，将真实世界视频转化为反事实场景。通过将结构化的上下文信息嵌入视频编辑和问答生成过程，该框架能自动生成高质量的问答对以及用于对比训练的原始视频与编辑后视频配对。基于此，我们构建了 DualityVidQA，一个旨在减少 MLLM 幻觉的大规模视频数据集。此外，为充分利用配对数据的对比特性，我们提出了 Duality 归一化优势训练 (Duality-Normalized Advantage Training, DNA-Train)。这是一个两阶段的 SFT-RL 训练机制，其中强化学习阶段应用了成对的 ℓ1\ell_1ℓ1​ 优势归一化，从而实现更稳定、高效的策略优化。在 DualityVidQA-Test 上的实验表明，我们的方法能显著降低模型在反事实视频上的幻觉，相比 Qwen2.5-VL-7B 基线获得了 24.0% 的相对提升。此外，我们的方法在幻觉评测和通用基准测试上均取得了显著进步，显示出强大的泛化能力。我们将开源数据集和代码。

Recursive Language Models
递归语言模型
我们从推理时扩展的角度，研究如何让大语言模型 (LLMs) 能够处理任意长度的提示。我们提出了递归语言模型 (RLMs)，这是一种通用的推理策略。它将长提示视为外部环境的一部分，使大语言模型能够以编程方式对提示片段进行检查、分解，并递归地调用自身进行处理。我们发现，在四个不同的长上下文任务中，RLMs 能够成功处理长度超出模型原始上下文窗口两个数量级的输入。并且，即使是对于较短的提示，其输出质量也显著优于基础大语言模型和常见的长上下文扩展框架，同时每次查询的成本与之相当（甚至更低）。

DreamID-V:Bridging the Image-to-Video Gap for High-Fidelity Face Swapping via Diffusion Transformer
DreamID-V：通过扩散 Transformer 弥合图像到视频鸿沟以实现高保真人脸交换
视频人脸交换 (VFS) 旨在将源身份无缝注入目标视频，同时精确保持原始的姿态、表情、光照、背景及动态信息。现有方法在维持时序一致性的同时，往往难以兼顾身份相似度与属性保留。为应对这一挑战，我们提出了一个综合性框架，旨在将图像人脸交换 (IFS) 的优势无缝迁移至视频领域。我们首先引入了一种新颖的数据流水线 SyncID-Pipe，它预训练了一个身份锚定视频合成器，并将其与 IFS 模型相结合，构建用于显式监督的双向 ID 四元组。基于此配对数据，我们提出了首个基于扩散 Transformer 的框架 DreamID-V，其核心是一个模态感知条件模块，用于区分性地注入多模态条件。同时，我们提出了一种合成到真实的课程学习机制以及一种身份一致性强化学习策略，以提升在复杂场景下的视觉真实感与身份一致性。针对现有基准测试有限的问题，我们引入了 IDBench-V，这是一个涵盖多样化场景的综合基准测试集。大量实验表明，DreamID-V 性能优于现有最先进方法，并展现出出色的通用性，能够无缝适配各类与人脸交换相关的任务。

## 每周AI论文速递（260112-260116）

Watching, Reasoning, and Searching: A Video Deep Research Benchmark on Open Web for Agentic Video Reasoning
观看、推理与搜索：面向智能体视频推理的开放网络视频深度研究基准
在现实世界的视频问答场景中，视频本身通常仅提供局部视觉线索，而可验证的答案广泛分布于开放网络。因此，模型需要协同完成跨帧线索提取、迭代式检索以及基于多跳推理的验证。为弥补这一差距，我们构建了首个视频深度研究基准 VideoDR。VideoDR 的核心是视频条件化的开放域视频问答，要求模型执行跨帧视觉锚点提取、交互式网络检索，并对视频与网络联合证据进行多跳推理。通过严格的人工标注与质量控制，我们构建了涵盖六个语义领域的高质量视频深度研究样本集。我们评估了在流程式 (Workflow) 与智能体式 (Agentic) 两种范式下的多个闭源及开源多模态大语言模型。结果表明，智能体式 (Agentic) 范式并非总是优于流程式 (Workflow) 范式：其性能提升取决于模型在长链检索过程中维持初始视频锚点的能力。进一步分析指出，目标漂移 (goal drift) 和长程一致性 (long-horizon consistency) 是核心瓶颈。总之，VideoDR 为研究开放网络环境下的视频智能体提供了一个系统性基准，并揭示了下一代视频深度研究智能体所面临的关键挑战。

BabyVision: Visual Reasoning Beyond Language
BabyVision: 超越语言的视觉推理
人类在掌握语言能力之前很久便已发展出核心视觉技能，然而，当代的多模态大语言模型 (Multimodal LLMs, MLLMs) 仍严重依赖语言先验来弥补其薄弱的视觉理解能力。我们发现了一个关键事实：最先进的多模态大语言模型在人类（即使是3岁儿童）都能轻松解决的基本视觉任务上持续表现不佳。为了系统地探究这一差距，我们提出了 BabyVision 基准，旨在评估多模态大语言模型独立于语言知识的核心视觉能力。BabyVision 涵盖广泛的任务，包含388个测试项，划分为四个关键类别下的22个子类。实证结果与人工评估表明，领先的多模态大语言模型性能显著低于人类基线。Gemini3-Pro-Preview 的得分为49.7，落后于6岁儿童的表现，且远低于成人平均分94.1。这些结果表明，尽管当前的多模态大语言模型在知识密集型评估中表现出色，但它们仍然缺乏基本的视觉原语。BabyVision 的进展是迈向人类水平视觉感知与推理能力的一步。我们还通过提出 BabyVision-Gen 和自动评估工具包，探索了利用生成模型解决视觉推理问题。我们的代码和基准数据已在 github.com/UniPat-AI/B… 发布，以供复现。

Thinking with Map: Reinforced Parallel Map-Augmented Agent for Geolocalization
基于地图思考：用于地理定位的强化并行地图增强智能体
图像地理定位任务旨在利用视觉线索，预测图像在地球上的拍摄位置。现有的大型视觉语言模型 (LVLM) 方法利用了世界知识、思维链 (Chain-of-Thought) 推理和智能体 (Agent) 能力，但忽略了人类常用的一种策略——使用地图。在本工作中，我们首先赋予模型 基于地图思考 的能力，并将其形式化为一个地图中的智能体循环。我们为此开发了一个两阶段优化方案：首先是智能体强化学习 (RL)，随后是并行测试时缩放 (TTS)。RL 阶段旨在增强模型的智能体能力，以提高其采样效率；而并行 TTS 阶段则允许模型在做出最终预测前并行探索多条候选路径，这对地理定位任务至关重要。为了在最新且真实（非合成）的图像上评估我们的方法，我们进一步提出了 MAPBench，这是一个完全基于真实世界图像的综合性地理定位训练与评估基准。实验结果表明，我们的方法在大多数指标上优于现有的开源和闭源模型。具体而言，与启用 Google 搜索/地图定位模式的 Gemini-3-Pro 相比，我们的方法将 Acc@500m 指标从 8.0% 显著提升至 22.1%。

STEP3-VL-10B Technical Report
STEP3-VL-10B 技术报告
我们推出 STEP3-VL-10B，这是一个轻量级开源基础模型，旨在重新权衡紧凑效率与前沿多模态智能能力。STEP3-VL-10B 通过两项战略转变实现：首先，在 1.2T 多模态 Token 上采用统一且全部参数可训练的预训练策略，将语言对齐的感知编码器与 Qwen3-8B 解码器集成，以建立内在的视觉-语言协同；其次，采用一个大规模后训练流程，包含超过 1000 次强化学习迭代。关键在于，我们实施了并行协调推理 (PaCoRe) 来扩展测试时的计算规模，将资源分配给可扩展的感知推理，以探索并整合多样化的视觉假设。因此，尽管其模型规模紧凑，仅为 10B 参数，STEP3-VL-10B 的性能却媲美甚至超越了规模大 10 到 20 倍的模型（例如 GLM-4.6V-106B、Qwen3-VL-235B）以及顶级的闭源旗舰模型，如 Gemini 2.5 Pro 和 Seed-1.5-VL。它实现了同类最佳的绩效，在 MMBench 上取得 92.2% 的得分，在 MMMU 上取得 80.11% 的得分；同时在复杂推理任务中表现卓越，在 AIME2025 上达到 94.43%，在 MathVision 上达到 75.95%。我们发布了完整的模型套件，旨在为社区提供一个强大、高效且可复现的基准。

Urban Socio-Semantic Segmentation with Vision-Language Reasoning
基于视觉语言推理的城市社会语义分割
城市作为人类活动的中心，其区域包含丰富的语义实体。从卫星影像中分割这些多样的实体，对众多下游应用至关重要。当前先进的分割模型能够可靠地分割由物理属性定义的实体 (例如，建筑物、水体) ，但在处理社会语义类别 (例如，学校、公园) 时仍面临挑战。本研究通过视觉语言模型 (Vision-Language Model) 的推理能力，实现了社会语义分割。为此，我们提出了一个名为 SocioSeg 的城市社会语义分割数据集，该新资源包含卫星影像、数字地图以及按层级结构组织的社会语义实体的像素级标注。此外，我们提出了一种名为 SocioReasoner 的新型视觉语言推理框架，它通过跨模态识别与多阶段推理，模拟人类识别与标注社会语义实体的过程。我们采用强化学习来优化这一不可微的流程，从而有效激发视觉语言模型固有的推理能力。实验结果表明，我们的方法相较于现有最优模型取得了性能提升，并展现出强大的零样本泛化能力。我们的数据集与代码已公开于 github.com/AMAP-ML/Soc…

Rewarding the Rare: Uniqueness-Aware RL for Creative Problem Solving in LLMs
奖励稀缺性：面向大语言模型创造性问题解决的独特性感知强化学习
强化学习已成为大语言模型后训练，尤其是针对复杂推理任务的核心范式。然而，该方法常面临探索崩溃问题：模型策略过早地收敛于少数几种主导的推理模式。这虽然能提升 pass@1 指标，却限制了推理路径层面的多样性，从而抑制了 pass@k 指标的进一步增益。我们认为，问题的根源在于现有方法侧重于对局部 Token 行为进行正则化，而非鼓励解决方案集合的多样性。为此，我们提出了独特性感知强化学习。该方法定义了一个推理路径层面的优化目标，明确奖励那些采用罕见高级策略的正确解决方案。具体而言，我们利用一个基于大语言模型的评判器，将针对同一问题生成的不同推理路径按其高级解决策略（忽略表面差异）进行聚类，并依据聚类规模反比地重新调整策略优势值。如此一来，正确且新颖的策略将获得比冗余策略更高的奖励。在数学、物理和医学推理等多个基准测试上的实验表明，我们的方法能够在大规模采样预算下持续提升 pass@kkk 指标，并增大 pass@kkk 曲线下面积，同时不损害 pass@1 性能。该方法有效维持了探索过程，并能在更大规模上发掘出更多样化的解决方案策略。

DeepResearchEval: An Automated Framework for Deep Research Task Construction and Agentic Evaluation
DeepResearchEval：一个用于深度研究任务构建与智能体评估的自动化框架
深度研究系统已广泛应用于多步骤网络研究、分析与多源信息综合，但其评估仍面临挑战。现有基准测试往往需要大量标注来构建任务，依赖静态的评估维度，或在引文缺失时无法可靠地验证事实。为填补这些空白，我们提出了 DeepResearchEval，一个用于深度研究任务构建与智能体 (Agentic) 评估的自动化框架。在任务构建方面，我们设计了一个角色 (Persona) 驱动的流程，能够基于多样化的用户画像生成真实、复杂的研究任务，并应用一个两阶段过滤器（任务资格 (Task Qualification) 与搜索必要性 (Search Necessity)）来筛选出仅那些需要整合多源证据并进行外部检索的任务。在评估方面，我们提出了一个智能体流程，包含两个组件：一是自适应点式质量评估 (Adaptive Point-wise Quality Evaluation)，它能根据每个生成的任务动态推导出任务特定的评估维度、标准及权重；二是主动事实核查 (Active Fact-Checking)，它能通过网页搜索自主提取并验证报告中的陈述，即便在引文缺失的情况下也能进行。

Controlled Self-Evolution for Algorithmic Code Optimization
面向算法代码优化的受控自进化
自进化方法通过迭代式的“生成-验证-精炼”循环来提升代码生成质量。然而，现有方法探索效率低下，难以在有限预算内发现复杂度更优的解决方案。这种低效源于几个瓶颈：初始化偏差会将进化过程限制在较差的解空间区域；随机操作缺乏反馈引导，不可控；且跨任务的经验未能得到充分利用。为应对这些挑战，我们提出了受控自进化 (Controlled Self-Evolution, CSE)，其包含三个核心组件。多样化规划初始化通过生成结构各异的算法策略，以实现对解空间的广泛覆盖。遗传进化则采用反馈引导机制替代随机操作，从而支持有针对性的变异与组合式交叉。分层进化记忆能够在任务间与任务内两个层面，同时捕获成功与失败的经验。在EffiBench-X基准上的实验表明，CSE在使用不同大语言模型 (LLM) 骨干时，均稳定优于所有基线方法。此外，CSE在进化早期即展现出更高的效率，并能在此后的整个进化过程中持续改进。我们的代码已公开于 github.com/QuantaAlpha…

MMFormalizer: Multimodal Autoformalization in the Wild
MMFormalizer: 真实场景下的多模态自动形式化
自动形式化 (Autoformalization) 旨在将自然语言描述的数学内容转化为形式化语句，以实现机器推理。然而，在真实物理世界的开放场景下，由于其多模态特性，自动形式化面临着根本性挑战：物理学问题常常需要从视觉元素中推断出隐藏的约束条件 (例如质量或能量)。为此，我们提出了 MMFormalizer，它通过整合来自真实世界数学和物理领域的实体进行自适应基础 (adaptive grounding)，从而将自动形式化的范畴从纯文本扩展到了多模态。MMFormalizer 通过递归基础 (recursive grounding) 和公理组合 (axiom composition)，从感知基础 (perceptually grounded) 的基元出发，递归地构建形式化命题。其自适应的递归终止机制确保每一个抽象概念都有视觉证据支撑，并基于维度或公理基础 (dimensional or axiomatic grounding)。我们在一个新构建的基准测试 PhyX-AF 上评估了 MMFormalizer。该基准包含从 MathVerse、PhyX、综合几何 (Synthetic Geometry) 和解析几何 (Analytic Geometry) 中精心挑选的 115 个样本，涵盖了多样化的多模态自动形式化任务。结果表明，GPT-5 和 Gemini-3-Pro 等前沿模型在形式化编译和语义准确性方面取得了最高分，其中 GPT-5 在物理推理任务上表现尤为出色，而几何领域仍然是挑战最大的方向。总体而言，MMFormalizer 为统一的多模态自动形式化提供了一个可扩展的框架，有效连接了感知与形式推理。据我们所知，这是首个能够处理经典力学 (基于哈密顿量推导)、相对论、量子力学和热力学的多模态自动形式化方法。更多详细信息请访问我们的项目页面：MMFormalizer.github.io。

MAXS: Meta-Adaptive Exploration with LLM Agents
MAXS: 基于大语言模型智能体的元自适应探索
大语言模型 (LLM) 智能体通过多工具协作，具备内在的推理能力。然而，在智能体推理过程中，现有方法通常存在两个问题：(i) 由于缺乏前瞻性，导致局部短视的生成；(ii) 轨迹不稳定，即早期的微小错误可能演变为发散的推理路径。这些问题使得难以在全局有效性与计算效率之间取得平衡。为解决这两个问题，我们提出了 MAXS (Meta-Adaptive Exploration with LLM Agents，项目地址：github.com/exoskeleton…) ，这是一个基于 LLM 智能体的元自适应推理框架，能够灵活集成工具执行与推理规划。MAXS 采用前瞻策略，将推理路径向前推演若干步，以估计工具使用的优势值，并结合步骤一致性方差与步骤间趋势斜率，共同筛选出稳定、一致且高价值的推理步骤。此外，我们引入了轨迹收敛机制，一旦路径一致性达成，便停止进一步推演，从而控制计算成本，实现在多工具推理中平衡资源效率与全局有效性。我们在三个基础模型 (MiMo-VL-7B、Qwen2.5-VL-7B、Qwen2.5-VL-32B) 和五个数据集上进行了大量实验，结果表明 MAXS 在性能与推理效率上均持续优于现有方法。进一步的分析证实了我们前瞻策略与工具使用机制的有效性。

A^3-Bench: Benchmarking Memory-Driven Scientific Reasoning via Anchor and Attractor Activation
A^3-Bench：基于锚点与吸引子激活的记忆驱动科学推理基准
科学推理不仅依赖于逻辑推断，也需要激活先验知识与经验结构。记忆能够有效复用知识，提升推理的一致性与稳定性。然而，现有基准主要评估最终答案或逐步推理的连贯性，忽略了人类推理所依赖的 记忆驱动 机制，该机制通过激活锚点 (Anchor) 和吸引子 (Attractor)，并将其整合到多步推理中来实现。为填补这一空白，我们提出了 A³-Bench (a3-bench.github.io)，这是一个基于锚点与吸引子激活 (Anchor and Attractor Activation) 理论、旨在通过双尺度记忆驱动激活来评估科学推理的基准。
首先，我们采用 SAPM 流程 (即主题、锚点与吸引子、问题及记忆形成) 对跨领域的 2,198 个科学推理问题进行了标注。其次，我们引入了一个利用锚点和吸引子的双尺度记忆评估框架，并提出了 AAUI (锚点-吸引子利用指数) 指标以量化记忆激活率。最后，通过对多种基础模型及推理范式的实验，我们验证了 A³-Bench 的有效性，分析了记忆激活如何影响推理性能，从而深入理解了记忆驱动的科学推理机制。

PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning
PaCoRe: 学习通过并行协调推理扩展测试时计算量
我们提出了并行协调推理 (PaCoRe)，这是一个旨在克服当代语言模型核心局限性的训练与推理框架：即模型无法在固定上下文窗口下，将测试时计算量 (Test-Time Compute, TTC) 扩展到远超顺序推理的程度。PaCoRe 摒弃了传统的顺序范式，转而通过多轮消息传递架构协调的大规模并行探索来驱动 TTC。在每一轮中，系统启动多个并行推理轨迹，将其发现压缩成受上下文长度限制的消息，然后综合这些消息来指导下一轮推理，并最终生成答案。通过大规模、基于结果的强化学习进行端到端训练，模型掌握了 PaCoRe 所需的信息综合能力，能够将有效 TTC 扩展到数百万 token 的规模，同时不突破上下文长度限制。该方法在多个不同领域都带来了显著提升，尤其在数学推理方面超越了前沿系统：一个 80 亿参数的模型在 HMMT 2025 数据集上达到了 94.5% 的准确率，通过将有效 TTC 扩展至约两百万 token，超越了 GPT-5 的 93.2%。我们开源了模型检查点、训练数据以及完整的推理流水线，以促进后续研究。

MemGovern: Enhancing Code Agents through Learning from Governed Human Experiences
MemGovern: 通过从经过治理的人类经验中学习增强代码智能体
尽管自主软件工程 (SWE) 智能体正在重塑编程范式，但它们目前存在一个“封闭世界”的局限：它们试图从零开始或仅依赖本地上下文来修复缺陷，而忽略了 GitHub 等平台上可用的海量历史人类经验。然而，现实世界中的问题跟踪数据往往是非结构化和碎片化的，这阻碍了智能体有效利用这些开放世界的经验。本文提出了 MemGovern 框架，旨在治理原始 GitHub 数据，并将其转化为智能体可操作的体验记忆。MemGovern 通过经验治理流程，将人类经验转换为便于智能体使用的经验卡片，并引入了一种智能体驱动的经验搜索策略，从而实现基于逻辑的人类专业知识检索。通过生成 13.5 万个经过治理的经验卡片，MemGovern 带来了显著的性能提升，在 SWE-bench Verified 基准测试中将问题解决率提高了 4.65%。作为一种插件式方案，MemGovern 为构建适配智能体的记忆基础设施提供了一种解决方案。

Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning
面向推理的协作式多智能体测试时强化学习
多智能体系统已发展成为许多实际应用中由大语言模型驱动的实用协作者，其鲁棒性得益于多样性和交叉验证。然而，多智能体强化学习 (MARL) 训练资源密集且不稳定：智能体间的协同适应会导致环境非平稳性，且奖励信号通常稀疏且方差高。为此，我们提出了 多智能体测试时强化学习 (MATTRL) 框架，该框架在推理阶段将结构化的文本经验注入多智能体的决策审议中。MATTRL 组建一个多专家团队进行多轮讨论，检索并整合测试时经验，最终达成共识以做出决策。我们还研究了信用分配机制，用于构建轮级经验池并将其重新注入对话流程。在医学、数学和教育等领域的多个挑战性基准测试上，MATTRL 的平均准确率相较于多智能体基线提升了 3.67%，相较于相应的单智能体基线提升了 8.67%。消融研究分析了不同的信用分配方案，并详细比较了它们对训练结果的影响。MATTRL 为无需额外调优、且能有效应对分布偏移的多智能体推理，提供了一条稳定、高效且有效的路径。

Motion Attribution for Video Generation
视频生成中的运动归因
尽管视频生成模型发展迅速，但数据如何影响运动仍不明确。我们提出了 Motive (MOTIon attribution for Video gEneration)，这是一个运动中心、基于梯度的数据归因框架，能够适应现代大规模高质量视频数据集和模型。我们利用该框架研究哪些微调片段会改善或损害时序动态。Motive 通过运动加权损失掩码将时序动态与静态外观分离，实现了高效且可扩展的运动特定影响力计算。在文本到视频模型上，Motive 能够识别出对运动有强烈影响的片段，并以此指导数据筛选工作，从而提升时间一致性与物理合理性。使用 Motive 精选出的高影响力数据进行微调，我们的方法在 VBench 基准上同时提升了运动平滑度与动态程度，相较于预训练基础模型，获得了 74.1% 的人类偏好胜率。据我们所知，这是首个在视频生成模型中归因于运动而非视觉外观的框架，并利用该归因结果来构建微调数据集。

Solar Open Technical Report
Solar Open 技术报告
我们介绍了 Solar Open，这是一个拥有 1020 亿参数、面向低资源语言的双语专家混合 (Mixture-of-Experts， MoE) 大语言模型。Solar Open 展示了一种通过解决三个相互关联的挑战来构建具有竞争力大语言模型的系统性方法。首先，为了应对低资源语言数据稀缺的问题以实现有效训练，我们合成了 4.5 万亿个高质量、领域特定且面向强化学习 (RL) 的 Token。其次，我们通过课程学习 (Curriculum Learning) 来协调这些数据，在总计 20 万亿 Token 的数据上，联合优化其构成、质量阈值和领域覆盖范围。第三，为了通过可扩展的强化学习来获得推理能力，我们应用了我们提出的 SnapPO 框架进行高效优化。在英语和韩语的各项基准测试中，Solar Open 都取得了具有竞争力的性能，这证明了该方法对于推动低资源语言 AI 发展的有效性。

VIBE: Visual Instruction Based Editor
VIBE: 基于视觉指令的编辑器
基于指令的图像编辑是生成式 AI (Generative AI) 中发展最迅速的领域之一。过去一年，该领域迈上了新台阶，涌现出数十个开源模型以及能力强大的商业系统。然而，目前仅有少数开源方法能达到实用级质量。此外，作为这些管线主流选择的扩散主干网络，通常体积庞大且计算成本高昂，难以适配许多部署和研究场景；其广泛使用的版本通常包含 60 亿至 200 亿参数。本文提出了一种紧凑、高吞吐的基于指令的图像编辑管线，它采用一个现代的 20 亿参数 Qwen3-VL 模型来指导编辑过程，并使用一个 16 亿参数的扩散模型 Sana1.5 进行图像生成。我们在架构、数据处理、训练配置和评估等方面的设计决策，均以低成本推理和严格的源一致性为目标，同时确保在此规模可行的主要编辑类别上保持高质量。在 ImgEdit 和 GEdit 基准测试上的评估表明，所提方法的性能匹配甚至超越了参数量大数倍、推理成本显著更高的基线模型，并且在需要保留输入图像的编辑任务上表现尤为突出，例如属性调整、对象移除、背景编辑和针对性替换。该模型可适配 24 GB 的 GPU 显存，在 NVIDIA H100 上以 BF16 精度生成高达 2K 分辨率的编辑图像仅需约 4 秒，且无需任何额外的推理优化或模型蒸馏。

Distribution-Aligned Sequence Distillation for Superior Long-CoT Reasoning
面向卓越长链思维推理的分布对齐序列蒸馏
在本报告中，我们介绍了 DASD-4B-Thinking，这是一个轻量级但能力强大、完全开源的推理模型。在数学、科学推理和代码生成等具有挑战性的基准测试中，它在同等规模的开源模型中实现了 SOTA 性能，甚至优于一些更大的模型。我们首先批判性地重新审视了社区中广泛采用的一种蒸馏范式：基于教师模型生成回答进行监督微调 (SFT)，也称为序列级蒸馏 (Sequence-Level Distillation)。尽管近期一系列遵循此方案的工作展现了显著的效率和强大的实证性能，但它们主要立足于 SFT 的视角。因此，这些方法将重点放在了设计 SFT 数据过滤的启发式规则上，而在很大程度上忽略了蒸馏本身的核心原则——即让学生模型学习教师模型的完整输出分布，从而继承其泛化能力。具体而言，我们指出了当前实践中的三个关键局限：i) 对教师模型序列级分布的表征不足；ii) 教师模型的输出分布与学生模型的学习能力之间存在错配；iii) 教师强制训练 (Teacher-Forced Training) 与自回归推理 (Autoregressive Inference) 之间的差异导致的暴露偏差。总而言之，这些不足反映了在整个蒸馏过程中系统性缺乏明确的师生交互，使得蒸馏的精髓未能得到充分利用。为了解决这些问题，我们提出了几项方法学创新，它们共同构成了一个增强的序列级蒸馏训练流程。值得注意的是，DASD-4B-Thinking 仅使用 44.8 万训练样本就取得了有竞争力的结果——这比大多数现有开源工作所使用的样本量少了一个数量级。为了支持社区研究，我们公开发布了模型和训练数据集。

KnowMe-Bench: Benchmarking Person Understanding for Lifelong Digital Companions
KnowMe-Bench: 用于终身数字伴侣的人物理解基准测试
现有的长期记忆基准测试大多使用多轮对话或合成的用户历史，这使得检索性能并不能完美地代表模型的人物理解能力。我们提出了 \BenchName，这是一个基于长篇自传叙事构建的可公开发布的基准测试。在这些叙事中，人物的行动、背景和内心思想为推断其稳定的动机和决策原则提供了丰富的证据。\BenchName~将每个叙事重构为一个具有闪回感知和时间锚定的序列，并通过一系列与证据关联的问题来评估模型，这些问题涵盖事实回忆、主观状态归因和原则级推理。在不同来源的叙事上，检索增强系统主要提升了事实准确性，但在需要时间定位的解释和更高层次的推理方面，错误仍然存在，这凸显了对超越检索的记忆机制的需求。我们的数据发布于 \href{KnowMeBench}{github.com/QuantaAlpha…

CaricatureGS: Exaggerating 3D Gaussian Splatting Faces With Gaussian Curvature
CaricatureGS: 基于高斯曲率夸张化3D高斯泼溅人脸
本文提出了一种用于人脸的照片级真实感、可控3D漫画化框架。我们首先采用一种基于内在高斯曲率的表面夸张技术，但当其与纹理结合时，渲染结果往往过于平滑。为解决此问题，我们求助于3D高斯泼溅 (3D Gaussian Splatting, 3DGS)，该技术近期已被证明能生成逼真的自由视点化身。给定一个多视角图像序列，我们提取FLAME网格，求解曲率加权的泊松方程，从而得到其夸张形式。然而，直接对3DGS中的高斯泼溅进行变形效果不佳，因此需要通过局部仿射变换将每一帧图像扭曲为其对应的夸张2D表示，以合成伪真值漫画图像。随后，我们设计了一种交替使用真实图像和合成图像进行监督的训练方案，使得单个高斯泼溅集合能够同时表征自然状态和夸张状态的化身。该方案提升了保真度，支持局部编辑，并允许对漫画夸张程度进行连续控制。为实现实时变形，我们引入了原始表面与夸张表面之间的高效插值方法，并进一步分析表明，该方法与闭式解之间的偏差是有界的。在定量与定性评估中，我们的方法均优于现有工作，能够生成几何可控、具有照片级真实感的漫画化身。

ArenaRL: Scaling RL for Open-Ended Agents via Tournament-based Relative Ranking
ArenaRL: 通过基于锦标赛的相对排名实现开放式智能体的强化学习规模化
强化学习已显著提升了大语言模型智能体在结果可验证任务上的性能，但在解空间广阔的开放式智能体任务（例如复杂旅行规划）上仍举步维艰。由于此类任务缺乏客观的真值，当前的强化学习算法主要依赖于为单个响应分配标量分数的奖励模型。我们认为，这种逐点评分法存在固有的区分度崩溃问题：奖励模型难以辨别不同轨迹间的细微优势，导致组内分数被压缩至一个狭窄区间。因此，有效的奖励信号被奖励模型本身的噪声所主导，进而引发优化停滞。为解决此问题，我们提出了 ArenaRL，这是一种将评估方式从逐点标量评分转变为组内相对排名的强化学习范式。ArenaRL 引入了一种感知任务过程的成对评估机制，采用多级评分标准为轨迹分配细粒度的相对分数。此外，我们构建了一个组内对抗竞技场，并设计了一套基于锦标赛的排名方案，以获取稳定的优势信号。实证结果表明，所构建的采用种子排位的单败淘汰制，在仅需 O(N) 复杂度的情况下，其优势估计精度与需要 O(N^2) 复杂度的完全成对比较几乎相当，从而在效率与精度之间达到了最优平衡。再者，为弥补开放式智能体缺乏全流程评测基准的不足，我们构建了 Open-Travel 和 Open-DeepResearch 两个高质量基准，它们具备覆盖监督微调、强化训练及多维评估的完整流程。大量实验表明，ArenaRL 显著优于标准强化学习基线，能够使大语言模型智能体为复杂的现实世界任务生成更为稳健的解决方案。

The Molecular Structure of Thought: Mapping the Topology of Long Chain-of-Thought Reasoning
思想的分子结构：映射长链思维推理的拓扑结构
大语言模型 (LLMs) 常常难以通过模仿人类或非长链思维 (Long CoT) 大语言模型来学习有效的长链思维 (Long CoT) 推理。为探究其原因，我们提出，在统一视角下，有效且可学习的长链思维轨迹具有类似分子的稳定结构，这些结构由三种相互作用构成：深度推理 (类共价键) 、自我反思 (类氢键) 和自我探索 (类范德华力) 。对蒸馏轨迹的分析表明，这些结构源自长链思维微调过程，而非对关键词的简单模仿。我们引入了有效语义异构体的概念，并证明只有那些能促进快速熵收敛的化学键才能支持稳定的长链思维学习，而不同结构之间的竞争则会损害训练效果。基于这些发现，我们提出了 Mole-Syn，一种基于分布转移图的方法，用于指导合成有效的长链思维结构，从而在多个基准测试中提升模型性能并增强强化学习的稳定性。

User-Oriented Multi-Turn Dialogue Generation with Tool Use at scale
面向用户的大规模多轮对话生成与工具使用
近期，将大型推理模型 (Large Reasoning Models, LRMs) 作为自主智能体的范式转变，极大地提升了对复杂多轮工具使用能力的需求。然而，现有数据集与数据生成方法受限于静态、预定义的工具集，难以应对开放式人机协作场景的复杂性。为此，我们首先构建了一个框架，用于大规模自动化生成面向任务的多轮对话。该框架利用基于 LRM 的模拟器动态生成高价值、领域特定的工具，以解决指定任务。但我们发现，纯粹面向任务的设计往往导致"仅限任务解决"的轨迹，即智能体以最少的交互完成目标，无法生成现实场景中常见的多轮次对话。为弥补这一不足，我们转向了面向用户的模拟范式。通过将任务生成与一个专用的用户模拟器解耦——该模拟器模仿人类行为规则，如增量式提出请求和逐轮提供反馈——我们能够促成更真实、更扩展的多轮对话，从而反映现实世界问题解决的迭代特性。我们的生成流水线作为一个多功能、即插即用的模块运行，可从任意状态启动生成，确保了在产出扩展工具使用数据时的高可扩展性。此外，通过支持在单条轨迹内完成多个任务，该流程能够生成高密度数据集，以反映现实世界人机交互的多方面需求。

Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning
Fast-ThinkAct: 基于可语言化潜在规划的高效视觉-语言-动作推理
视觉-语言-动作 (Vision-Language-Action, VLA) 任务要求对复杂视觉场景进行推理，并在动态环境中执行自适应的动作。尽管近期关于推理型 VLA 的研究表明，显式的思维链 (Chain-of-Thought, CoT) 能够提升泛化能力，但其冗长的推理轨迹导致了较高的推理延迟。我们提出了 Fast-ThinkAct，一个高效的推理框架，它通过可语言化的潜在推理，实现了紧凑且高性能的规划。Fast-ThinkAct 通过从教师模型进行知识蒸馏，学习利用潜在 CoT 进行高效推理。该方法由一个偏好引导的目标驱动，旨在对齐操作轨迹，从而迁移用于具身控制的语言和视觉规划能力。这实现了推理增强的策略学习，能够有效地将紧凑的推理与动作执行相衔接。在多种具身操作与推理基准上进行的大量实验表明，Fast-ThinkAct 取得了优异的性能，与最先进的推理型 VLA 相比，推理延迟最高可降低 89.3%，同时仍能有效进行长时程规划、少样本适应和故障恢复

## 每周AI论文速递（260119-260123）
Agentic Reasoning for Large Language Models
面向大语言模型的智能体推理
推理是支撑推断、问题解决与决策制定的基本认知过程。尽管大语言模型 (LLMs) 在封闭环境设定下展现出强大的推理能力，但在开放、动态的环境中却表现欠佳。智能体推理 (Agentic Reasoning) 标志着一种范式转变，它将大语言模型重构为能够通过持续交互进行规划、行动和学习的自主智能体。本综述从三个互补的维度来梳理智能体推理。首先，我们通过三个层级来刻画环境动态：基础智能体推理，它在稳定环境中建立核心的单智能体能力，包括规划、工具使用和搜索；自我进化智能体推理，它研究智能体如何通过反馈、记忆和适应来完善这些能力；以及集体多智能体推理，它将智能延伸至涉及协调、知识共享和共同目标的协作场景。在这些层级中，我们区分了上下文推理（通过结构化编排来扩展测试时的交互）与训练后推理（通过强化学习和监督微调来优化行为）。我们进一步回顾了跨越现实世界应用与基准测试的代表性智能体推理框架，涵盖科学、机器人、医疗保健、自主研究与数学等领域。本综述将各类智能体推理方法综合成一个连接思维与行动的统一路线图，并概述了开放的挑战与未来方向，包括个性化、长周期交互、世界模型建模、可扩展的多智能体训练以及实际部署的治理机制。

Your Group-Relative Advantage Is Biased
群体相对优势估计存在偏差
基于验证器奖励的强化学习 (Reinforcement Learning from Verifier Rewards, RLVR) 已成为对大语言模型进行推理任务后训练的一种广泛应用方法，其中基于群体的方法，如 GRPO 及其变体，得到了广泛采用。这些方法依赖于群体相对优势估计 (group-relative advantage estimation) 来避免使用学习到的评论家，但其理论性质仍不明确。
本工作揭示了基于群体的强化学习的一个根本问题：群体相对优势估计量相对于真实（期望）优势存在固有偏差。我们首次进行了理论分析，证明该估计量会系统性地低估困难提示的优势，同时高估简单提示的优势，从而导致探索与利用的失衡。为解决此问题，我们提出了历史感知自适应难度加权 (History-Aware Adaptive Difficulty Weighting, HA-DW)，这是一种自适应重加权方案，能够根据一个动态变化的难度锚点和训练过程动态来调整优势估计。在五个数学推理基准测试上的理论分析与实验均表明，将 HA-DW 集成到 GRPO 及其变体中能持续提升性能。我们的结果表明，纠正有偏差的优势估计对于实现稳健、高效的 RLVR 训练至关重要。

Being-H0.5: Scaling Human-Centric Robot Learning for Cross-Embodiment Generalization
Being-H0.5: 面向跨形态泛化的以人为中心机器人学习规模化
我们提出了 Being-H0.5，这是一个基础视觉-语言-动作（Vision-Language-Action, VLA）模型，旨在实现跨多样化机器人平台的鲁棒跨形态泛化。针对现有 VLA 模型常受限于形态异构性与数据稀缺的问题，我们提出了一种以人为中心的学习范式，将人类交互轨迹视为物理交互的通用“母语”。为此，我们推出了 UniHand-2.0，这是迄今为止规模最大的具身预训练方案，包含了跨越 30 种不同机器人形态的超过 35,000 小时多模态数据。我们的方法引入了一个统一动作空间，将异构的机器人控制映射到语义对齐的槽位，从而使低资源机器人能够从人类数据和高资源平台中自举学习技能。基于此以人为中心的基础，我们设计了一个统一的序列建模与多任务预训练范式，以弥合人类演示与机器人执行之间的差距。在架构上，Being-H0.5 采用了一种混合 Transformer（Mixture-of-Transformers）设计，其核心是新颖的混合流（Mixture-of-Flow, MoF）框架，用于将共享的运动基元与专门的形态特定专家解耦。最后，为确保跨形态策略在现实世界中的稳定性，我们引入了流形保持门控（Manifold-Preserving Gating）以应对感知变化下的鲁棒性挑战，以及通用异步分块（Universal Async Chunking）以实现跨不同延迟与控制特性的机器人形态的通用分块控制。实验结果表明，Being-H0.5 在模拟基准测试（如 LIBERO (98.9%) 和 RoboCasa (53.9%)）上取得了最先进的性能，同时在五个机器人平台上展现出强大的跨形态能力。

EvoCUA: Evolving Computer Use Agents via Learning from Scalable Synthetic Experience
EvoCUA: 通过从可扩展合成经验中学习演进计算机使用智能体
原生计算机使用智能体 (CUA) 的发展是多模态 AI 领域的一次重大飞跃。然而，其潜力目前受限于静态数据扩展的瓶颈。主要依赖对静态数据集进行被动模仿的现有范式，难以捕捉长程计算机任务中固有的复杂因果动态。本文中，我们提出了 EvoCUA，一个原生计算机使用智能体模型。与静态模仿不同，EvoCUA 将数据生成与策略优化整合为一个自我维持的演进循环。为缓解数据稀缺问题，我们开发了一个可验证的合成引擎，能自主生成多样化任务并附带可执行的验证器。为实现大规模经验获取，我们设计了一个可扩展的基础设施，可协调数万个异步沙盒模拟运行。基于这些大规模轨迹，我们提出了一种迭代演进学习策略，以高效吸收这些经验。该机制通过识别能力边界来动态调节策略更新——强化成功的行为模式，同时通过错误分析与自我纠正将失败轨迹转化为丰富的监督信号。在 OSWorld 基准测试上的实证评估表明，EvoCUA 实现了 56.7% 的成功率，创造了新的开源模型最佳性能。值得注意的是，EvoCUA 显著优于此前最佳的开源模型 OpenCUA-72B (45.0%)，并且超越了领先的闭源权重模型，如 UI-TARS-2 (53.1%)。关键的是，我们的结果证明了该方法的泛化能力：这种由经验学习驱动的演进范式，在不同规模的基础模型上均能实现一致的性能提升，从而为增强原生智能体能力开辟了一条稳健且可扩展的路径。

ABC-Bench: Benchmarking Agentic Backend Coding in Real-World Development
ABC-Bench: 面向真实世界开发环境的智能体后端编码基准测试
大语言模型 (LLMs) 向自主 AI 智能体 (AI Agent) 的演进，已将人工智能 (AI) 编码的范畴从局部代码生成，扩展至复杂的、仓库级别的、由执行驱动的问题求解。然而，现有的基准测试主要评估静态上下文中的代码逻辑，忽视了真实世界工程项目中动态的、全流程的需求，尤其是在需要严格环境配置与服务部署的后端开发领域。为弥补这一不足，我们提出了 ABC-Bench，这是一个专为在真实、可执行的工作流中评估智能体后端编码能力而设计的基准测试。通过一个可扩展的自动化流水线，我们从开源仓库中构建了 224 个实际任务，涵盖 8 种编程语言和 19 个框架。与以往的评估不同，ABC-Bench 规定智能体必须管理从仓库探索到部署容器化服务的完整开发生命周期，并且要通过外部的端到端 API 测试。我们的大量评估结果表明，即便是最先进的模型，在面对这些综合性任务时也难以提供稳定可靠的性能，这凸显了当前模型能力与实际后端工程需求之间存在的显著差距。我们的代码开源在 github.com/OpenMOSS/AB…

HERMES: KV Cache as Hierarchical Memory for Efficient Streaming Video Understanding
HERMES: 将 KV 缓存作为分层内存以实现高效流式视频理解
多模态大语言模型 (Multimodal Large Language Models, MLLMs) 的最新进展，在离线视频理解任务上取得了显著进步。然而，将其能力扩展至流式视频输入仍面临挑战，因为现有模型难以在保持稳定理解性能的同时，兼顾实时响应与较低的 GPU 内存开销。为应对这一挑战，我们提出了 HERMES，一种新颖的免训练架构，旨在实现对视频流的实时、准确理解。基于对注意力机制的机理探究，我们将 KV 缓存 (KV Cache) 概念化为一个分层内存框架，该框架能以多种粒度封装视频信息。在推理过程中，HERMES 通过重用紧凑的 KV 缓存，在有限资源下实现了高效的流式理解。值得注意的是，HERMES 在用户查询到达时无需任何辅助计算，从而确保了连续视频流交互的实时响应能力，其首次令牌生成时间 (Time To First Token, TTFT) 比之前的 SOTA 方法快 10 倍。即使与均匀采样相比，视频令牌数量减少了高达 68%，HERMES 在所有基准测试中仍取得了相当或更优的准确率，在流式数据集上的性能提升最高达 11.4%。

Advances and Frontiers of LLM-based Issue Resolution in Software Engineering: A Comprehensive Survey
基于大语言模型的软件工程问题解决：进展与前沿综述
问题解决是现实软件开发中一项不可或缺的复杂软件工程任务，现已成为人工智能面临的一项重大挑战。SWE-bench等基准测试的建立表明，此项任务对大语言模型而言极具难度，从而极大地推动了自主编码智能体的演进。本文对这一新兴领域进行了系统性综述。首先，我们考察了数据构建流程，包括自动收集与合成方法。接着，我们全面分析了相关方法，范围从具备模块化组件的免训练框架，到基于训练的技术（如监督微调和强化学习）。随后，我们对数据质量和智能体行为进行了批判性分析，并探讨了实际应用。最后，我们指出了当前面临的关键挑战，并展望了未来有前景的研究方向。我们在 github.com/DeepSoftwar… 维护了一个开源仓库，作为该领域的动态资源。

The Flexibility Trap: Why Arbitrary Order Limits Reasoning Potential in Diffusion Language Models
灵活性陷阱：为何任意顺序会限制扩散语言模型的推理潜力
扩散大语言模型 (Diffusion Large Language Models, dLLMs) 打破了传统大语言模型严格的从左到右约束，允许以任意顺序生成 Token。直观上看，这种灵活性意味着其解空间严格包含了固定的自回归轨迹，理论上能为数学和编码等通用任务释放更强大的推理潜力。因此，许多研究都利用强化学习 (Reinforcement Learning, RL) 来挖掘 dLLMs 的推理能力。本文揭示了一个反直觉的事实：在当前形式下，任意顺序生成非但没有扩大，反而缩小了 dLLMs 的推理边界。我们发现，dLLMs 倾向于利用这种顺序灵活性来规避对探索至关重要的高不确定性 Token，从而导致解空间过早坍缩。这一发现挑战了现有 dLLMs 强化学习方法的前提，这些方法通常为了保持这种灵活性而引入了相当大的复杂性，例如处理组合轨迹和难解的似然问题。我们证明，通过有意放弃任意顺序，转而应用标准的组相对策略优化 (Group Relative Policy Optimization, GRPO)，可以更有效地激发推理能力。我们的方法 JustGRPO 设计极其简洁，却效果惊人（例如，在 GSM8K 上达到 89.1% 的准确率），同时完全保留了 dLLMs 的并行解码能力。项目页面：nzl-thu.github.io/the-flexibi…

RubricHub: A Comprehensive and Highly Discriminative Rubric Dataset via Automated Coarse-to-Fine Generation
RubricHub: 通过自动化由粗到细生成构建的全面高区分度评分标准数据集
具有可验证奖励的强化学习 (Reinforcement Learning with Verifiable Rewards, RLVR) 在数学等推理密集型领域已取得重大进展。然而，由于缺乏真实标签，优化开放式生成任务仍面临挑战。基于评分标准的评估虽为验证提供了一种结构化替代方案，但现有方法受限于可扩展性瓶颈和粗糙的评判标准，导致了监督性能瓶颈。为解决此问题，我们提出了一种自动化的由粗到细评分标准生成框架。该框架协同利用原则引导的合成、多模型聚合与难度演化，能够生成全面且高区分度的评判标准，从而捕捉生成内容中的细微差别。基于此框架，我们发布了 RubricHub，这是一个大规模（约 11 万条）且覆盖多领域的数据集。我们通过一个两阶段的后训练流程验证了其有效性，该流程包含基于评分标准的拒绝采样微调 (Rubric-based Rejection Sampling Fine-Tuning, RuFT) 和强化学习 (Rubric-based Reinforcement Learning, RuRL)。实验结果表明，RubricHub 能显著提升模型性能：经后训练的 Qwen3-14B 模型在 HealthBench 基准上取得了最先进 (state-of-the-art, SOTA) 的性能（69.3 分），超越了 GPT-5 等专有的前沿模型。相关代码与数据即将发布。

LLM-in-Sandbox Elicits General Agentic Intelligence
LLM-in-Sandbox 激发通用智能体能力
我们提出了 LLM-in-Sandbox 方法，使大语言模型能够在代码沙盒（即虚拟计算机）内进行探索，从而在非代码领域激发通用智能。我们首先证明，强大的大语言模型无需额外训练，即可展现出利用代码沙盒处理非代码任务的泛化能力。例如，大语言模型能够自主访问外部资源以获取新知识，利用文件系统处理长上下文，并执行脚本来满足特定格式要求。我们进一步表明，这些 AI 智能体能力可以通过 LLM-in-Sandbox 强化学习（LLM-in-Sandbox-RL）得到增强，该方法仅使用非智能体行为数据来训练模型进行沙盒探索。实验表明，LLM-in-Sandbox 在免训练和训练后两种设置下，均能实现稳健的泛化，其能力覆盖数学、物理、化学、生物医学、长上下文理解及指令遵循等多个领域。最后，我们从计算和系统两个角度分析了 LLM-in-Sandbox 的效率，并将其开源为一个 Python 软件包，以促进实际应用部署。

BayesianVLA: Bayesian Decomposition of Vision Language Action Models via Latent Action Queries
BayesianVLA: 基于潜在动作查询的视觉-语言-动作模型贝叶斯分解
视觉-语言-动作 (Vision-Language-Action, VLA) 模型在机器人操作任务中展现出潜力，但其泛化能力常受限于新指令或复杂的多任务场景。我们指出当前训练范式存在一个关键缺陷：目标驱动的数据收集导致了数据集偏差。在此类数据集中，仅凭视觉观察就足以高度预测出语言指令，致使指令与动作之间的条件互信息趋于零，我们将此现象称为信息坍缩 (Information Collapse)。其结果是，模型退化为仅依赖视觉的策略，忽略了语言约束，从而在分布外 (Out-of-Distribution, OOD) 场景中失效。为解决此问题，我们提出了 BayesianVLA，这是一个通过贝叶斯分解来确保模型遵循指令的新框架。通过引入可学习的潜在动作查询 (Latent Action Queries)，我们构建了一个双分支架构，分别估计仅视觉先验 p(a∣v)p(a \mid v)p(a∣v) 和语言条件后验 π(a∣v,ℓ)π(a \mid v, \ell)π(a∣v,ℓ)。随后，我们优化策略以最大化动作与指令之间的条件点互信息 (Pointwise Mutual Information, PMI)。该目标有效地抑制了视觉捷径，并奖励那些能明确体现语言指令的动作。BayesianVLA 无需额外数据即可显著提升泛化性能。在 SimplerEnv 和 RoboCasa 上进行的大量实验证明了其显著的性能提升，其中在极具挑战性的 OOD SimplerEnv 基准测试上实现了 11.3% 的性能增益，验证了我们的方法能够稳健地将语言关联到动作。

Toward Efficient Agents: Memory, Tool learning, and Planning
迈向高效智能体：记忆、工具学习与规划
近年来，将大语言模型扩展为智能体 (AI Agent) 系统的研究兴趣日益浓厚。尽管智能体的有效性在持续提升，但对于实际部署至关重要的效率却常被忽视。因此，本文从智能体的三个核心组件——记忆、工具学习和规划——出发，研究其效率问题，并综合考虑延迟、Token 消耗、步骤数等成本。为了对智能体系统本身的效率进行全面研究，我们回顾了近期的一系列方法。这些方法在具体实现上各异，但在高级设计原则上往往趋同，包括但不限于：通过压缩和管理来限制上下文、设计强化学习奖励以最小化工具调用，以及采用受控搜索机制来提升效率。我们将对这些原则进行详细讨论。
相应地，我们从两个互补的维度来刻画效率：一是在固定成本预算下比较其有效性；二是在达到可比有效性水平时比较其成本消耗。这种权衡关系也可以从有效性与成本之间的帕累托前沿 (Pareto frontier) 来理解。基于此视角，我们还审视了面向效率的基准评测：通过总结针对上述组件的评估方案，并整合来自基准研究和方法论文献中常报告的各项效率指标。
此外，我们讨论了该领域面临的关键挑战与未来研究方向，旨在为相关研究提供有价值的见解。

MMDeepResearch-Bench: A Benchmark for Multimodal Deep Research Agents
MMDeepResearch-Bench：多模态深度研究智能体基准
深度研究智能体 (Deep Research Agents, DRAs) 通过多步骤搜索与信息合成来生成包含丰富引用的报告。然而，现有基准主要面向纯文本场景或短格式多模态问答，缺乏对端到端多模态证据使用的评估。为此，我们提出了 MMDeepResearch-Bench (MMDR-Bench)，这是一个包含 21 个领域、共计 140 项由专家精心设计任务的基准。每项任务提供一个图文数据包 (image-text bundle)，用于评估模型的多模态理解能力以及基于引用的报告生成能力。与以往的设置相比，MMDR-Bench 强调具备明确证据使用的报告式合成，要求模型必须将视觉内容与有来源支撑的论断相关联，并在叙述、引用和视觉参考之间保持一致性。我们进一步提出了一套统一且可解释的评估流程：用于评估报告质量的公式化-LLM自适应评估 (Formula-LLM Adaptive Evaluation, FLAE)，用于评估引用与证据对齐的可信检索对齐引用评估 (Trustworthy Retrieval-Aligned Citation Evaluation, TRACE)，以及用于检查文本-视觉一致性的多模态支持对齐完整性检查 (Multimodal Support-Aligned Integrity Check, MOSAIC)。每个评估环节都能产生细粒度的指标，支持进行超越单一总分的精细化错误诊断。我们在 25 个前沿模型上进行了实验，结果揭示了生成质量、引用规范性与多模态基础之间的系统性权衡。这些发现突出表明，仅能生成流畅的文本并不能保证对证据的忠实使用，并且多模态一致性仍然是深度研究智能体面临的一个关键瓶颈。

The Poisoned Apple Effect: Strategic Manipulation of Mediated Markets via Technology Expansion of AI Agents
毒苹果效应：通过 AI 智能体技术扩张对中介市场进行战略操纵
AI 智能体 (AI Agents) 融入经济市场，从根本上改变了战略互动的格局。我们在三个经典的博弈论场景中，研究了扩展可用技术集合所带来的经济影响，这些场景包括：议价 (资源分配)、谈判 (非对称信息交易) 以及说服 (战略信息传递)。研究发现，仅仅增加可供选择的 AI 智能体，就能显著改变均衡收益和监管结果，这常常会激励监管机构主动开发和发布新技术。与之相对，我们识别出一种被称为“毒苹果”效应的战略现象：某个智能体可能会发布一项新技术，而这项技术最终既不会被其自身采用，也不会被其对手采用，其唯一目的在于操纵监管机构，使其选择有利于该智能体的市场设计方案。这种战略性发布行为，以牺牲对手利益和违背监管机构公平目标为代价，提升了发布者自身的福利。我们的研究结果表明，静态的监管框架易受技术扩张的操纵，因此需要能够适应 AI 能力动态发展的市场设计。



